{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Roboflow-tensorflow-object-detection-mobilenet-colab-quantized.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cessnaw/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/Copy_of_Roboflow_tensorflow_object_detection_mobilenet_colab_quantized.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glHZ94aDihTX"
      },
      "source": [
        "Note! For a most up to date version of this notebook, make sure you copy from:\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1wTMIrJhYsQdq_u7ROOkf0Lu_fsX5Mu8a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwBP2Hkk8i1-"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQCnYPVDrsgx"
      },
      "source": [
        "## **Training MobileNetSSD Object Detection on a Custom Dataset**\n",
        "\n",
        "ðŸ’¡ Recommendation: [Open this blog post](https://blog.roboflow.ai/training-a-tensorflow-object-detection-model-with-a-custom-dataset/) to continue.\n",
        "\n",
        "### **Overview**\n",
        "\n",
        "This notebook walks through how to train a MobileNet object detection model using the TensorFlow 1.5 Object Detection API.\n",
        "\n",
        "In this specific example, we'll training an object detection model to recognize cells types: white blood cells, red blood cells and platelets. **To adapt this example to train on your own dataset, you only need to change two lines of code in this notebook.**\n",
        "\n",
        "Everything in this notebook is also hosted on this [GitHub repo](https://github.com/josephofiowa/tensorflow-object-detection).\n",
        "\n",
        "![Blood Cell Example](https://i.imgur.com/QwyX2aD.png)\n",
        "\n",
        "**Credit to [DLology](https://www.dlology.com/blog/how-to-train-an-object-detection-model-easy-for-free/) and [Tony607](https://github.com/Tony607)**, whom wrote the first notebook on which much of this is example is based. \n",
        "\n",
        "### **Our Data**\n",
        "\n",
        "We'll be using an open source cell dataset called BCCD (Blood Cell Count and Detection). Our dataset contains 364 images (and 4888 annotations!) is hosted publicly on Roboflow [here](https://public.roboflow.ai/object-detection/bccd).\n",
        "\n",
        "When adapting this example to your own data, create two datasets in Roboflow: `train` and `test`. Use Roboflow to generate TFRecords for each, replace their URLs in this notebook, and you're able to train on your own custom dataset.\n",
        "\n",
        "### **Our Model**\n",
        "\n",
        "We'll be training a MobileNetSSDv2 (single shot detector). This specific model is a one-short learner, meaning each image only passes through the network once to make a prediction, which allows the architecture to be very performant for mobile hardware.\n",
        "\n",
        "The model arechitecture is one of many available via TensorFlow's [model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models).\n",
        "\n",
        "As a note, this notebook presumes TensorFlow 1.5 as TensorFlow 2.0 has yet to fully support the object detection API.\n",
        "\n",
        "### **Training**\n",
        "\n",
        "Google Colab provides free GPU resources. Click \"Runtime\" â†’ \"Change runtime type\" â†’ Hardware Accelerator dropdown to \"GPU.\"\n",
        "\n",
        "Colab does have memory limitations, and notebooks must be open in your browser to run. Sessions automatically clear themselves after 12 hours.\n",
        "\n",
        "### **Inference**\n",
        "\n",
        "We'll run inference directly in this notebook, and on three test images contained in the \"test\" folder from our GitHub repo. \n",
        "\n",
        "When adapting to your own dataset, you'll need to add test images to the `test` folder located at `tensorflow-object-detection/test`.\n",
        "\n",
        "### **About**\n",
        "\n",
        "[Roboflow](https://roboflow.ai) makes managing, preprocessing, augmenting, and versioning datasets for computer vision seamless.\n",
        "\n",
        "Developers reduce 50% of their boilerplate code when using Roboflow's workflow, automate labelling quality assurance, save training time, and increase model reproducibility.\n",
        "\n",
        "#### ![Roboflow Workmark](https://i.imgur.com/WHFqYSJ.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhzxsJb3dpWq"
      },
      "source": [
        "## Configs and Hyperparameters\n",
        "\n",
        "Support a variety of models, you can find more pretrained model from [Tensorflow detection model zoo: COCO-trained models](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models), as well as their pipline config files in [object_detection/samples/configs/](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnNXNQCjdniL"
      },
      "source": [
        "# If you forked the repo, you can replace the link.\n",
        "repo_url = 'https://github.com/Cessnaw/tensorflow-object-detection-faster-rcnn'\n",
        "\n",
        "# Number of training steps - 1000 will train very quickly, but more steps will increase accuracy.\n",
        "num_steps = 20000  # 200000 to improve\n",
        "\n",
        "# Number of evaluation steps.\n",
        "num_eval_steps = 50\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
        "        'batch_size': 8\n",
        "    },    \n",
        "}\n",
        "\n",
        "# Pick the model you want to use\n",
        "# Select a model in `MODELS_CONFIG`.\n",
        "selected_model = 'ssd_mobilenet_v2'\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL8oRGC5UgMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0766988f-5e44-4e5a-ebcf-999022f31781"
      },
      "source": [
        "# use TF 1.x for Object Detection APIs as they are not ported to TF 2.0 yet\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4V-XE6kbkc1"
      },
      "source": [
        "## Clone the `tensorflow-object-detection` repository or your fork."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxc3DmvLQF3z",
        "outputId": "59ae2128-945b-4a54-be72-712666dc252b"
      },
      "source": [
        "import os\n",
        "\n",
        "%cd /content\n",
        "\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "!git pull"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'tensorflow-object-detection-faster-rcnn'...\n",
            "remote: Enumerating objects: 885, done.\u001b[K\n",
            "remote: Total 885 (delta 0), reused 0 (delta 0), pack-reused 885\u001b[K\n",
            "Receiving objects: 100% (885/885), 24.83 MiB | 25.97 MiB/s, done.\n",
            "Resolving deltas: 100% (428/428), done.\n",
            "/content/tensorflow-object-detection-faster-rcnn\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI8__uNS8-ns"
      },
      "source": [
        "## Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecpHEnka8Kix",
        "outputId": "37b85ee1-5850-4718-810a-ac478fa283fc"
      },
      "source": [
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "!pip install tf_slim\n",
        "\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!pip install -q pycocotools\n",
        "\n",
        "!pip install lvis\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Collecting tf_slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 352 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n",
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 155222 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.4_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.4) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.6_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.6) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.4) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.6) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.19.5)\n",
            "Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.29.24)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.3.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.15.0)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.11.0)\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from lvis) (3.2.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis) (4.1.2.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (3.0.6)\n",
            "Installing collected packages: lvis\n",
            "Successfully installed lvis-0.5.3\n",
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-k7uGThXlny"
      },
      "source": [
        "## Prepare `tfrecord` files\n",
        "\n",
        "Roboflow automatically creates our TFRecord and label_map files that we need!\n",
        "\n",
        "**Generating your own TFRecords the only step you need to change for your own custom dataset.**\n",
        "\n",
        "Because we need one TFRecord file for our training data, and one TFRecord file for our test data, we'll create two separate datasets in Roboflow and generate one set of TFRecords for each.\n",
        "\n",
        "To create a dataset in Roboflow and generate TFRecords, follow [this step-by-step guide](https://blog.roboflow.ai/getting-started-with-roboflow/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNfIPc5yxDOv",
        "outputId": "8dee420c-96da-4ce5-91fd-1a9ce35876ef"
      },
      "source": [
        "%cd /content/tensorflow-object-detection-faster-rcnn/data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tensorflow-object-detection-faster-rcnn/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg1rceVtTFaA",
        "outputId": "5860e480-9ca7-411f-dbc3-1927dcd822f7"
      },
      "source": [
        "!curl -L \"https://app.roboflow.com/ds/LmuQgTdqqB?key=CT6rSnweKk\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   883  100   883    0     0   2213      0 --:--:-- --:--:-- --:--:--  2213\n",
            "100 10.7M  100 10.7M    0     0  11.7M      0 --:--:-- --:--:-- --:--:-- 34.9M\n",
            "Archive:  roboflow.zip\n",
            " extracting: README.roboflow.txt     \n",
            "   creating: test/\n",
            " extracting: test/cysts.tfrecord     \n",
            " extracting: test/cysts_label_map.pbtxt  \n",
            "   creating: train/\n",
            " extracting: train/cysts.tfrecord    \n",
            " extracting: train/cysts_label_map.pbtxt  \n",
            "   creating: valid/\n",
            " extracting: valid/cysts.tfrecord    \n",
            " extracting: valid/cysts_label_map.pbtxt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6qI1uVamksZ",
        "outputId": "e8b448c3-c701-4052-d8cd-529a9ef57676"
      },
      "source": [
        "# training set\n",
        "%ls train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cysts_label_map.pbtxt  cysts.tfrecord\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEKOjMejmm9U",
        "outputId": "888c29b3-7fb5-4960-d3fb-06d19c06b08b"
      },
      "source": [
        "# test set\n",
        "%ls test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cysts_label_map.pbtxt  cysts.tfrecord\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgd-fzAIkZlV"
      },
      "source": [
        "# NOTE: Update these TFRecord names from \"cells\" and \"cells_label_map\" to your files!\n",
        "test_record_fname = '/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord'\n",
        "train_record_fname = '/content/tensorflow-object-detection-faster-rcnn/data/train/cysts.tfrecord'\n",
        "label_map_pbtxt_fname = '/content/tensorflow-object-detection-faster-rcnn/data/train/cysts_label_map.pbtxt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCNYAaC7w6N8"
      },
      "source": [
        "## Download base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orDCj6ihgUMR",
        "outputId": "2b4ce14d-49cd-42cf-cb01-2e6c67387ff0"
      },
      "source": [
        "%cd /content/models/research\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGhvAObeiIix",
        "outputId": "042159fd-f689-40b6-9fd6-1714a03d39a0"
      },
      "source": [
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/pretrained_model\n",
            "total 135M\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 .\n",
            "drwxr-xr-x 23 root   root  4.0K Dec  1 04:54 ..\n",
            "-rw-r--r--  1 345018 89939   77 Mar 30  2018 checkpoint\n",
            "-rw-r--r--  1 345018 89939  67M Mar 30  2018 frozen_inference_graph.pb\n",
            "-rw-r--r--  1 345018 89939  65M Mar 30  2018 model.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 345018 89939  15K Mar 30  2018 model.ckpt.index\n",
            "-rw-r--r--  1 345018 89939 3.4M Mar 30  2018 model.ckpt.meta\n",
            "-rw-r--r--  1 345018 89939 4.2K Mar 30  2018 pipeline.config\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 saved_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UHnxlfRznPP3",
        "outputId": "ab68bfc1-1331-4a38-8f38-dcfbd4d96abc"
      },
      "source": [
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/models/research/pretrained_model/model.ckpt'"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvwtHlLOeRJD"
      },
      "source": [
        "## Configuring a Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIhw7IdpLuiU"
      },
      "source": [
        "import os\n",
        "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG1nCNpUXcRU"
      },
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjtCbLF2i0wI"
      },
      "source": [
        "import re\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    f.write(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GH0MEEanocn6",
        "outputId": "fcf2a741-fd2d-426c-ca78-cfe383909feb"
      },
      "source": [
        "!cat {pipeline_fname}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# SSD with Mobilenet v2 configuration for MSCOCO Dataset.\n",
            "# Users should configure the fine_tune_checkpoint field in the train config as\n",
            "# well as the label_map_path and input_path fields in the train_input_reader and\n",
            "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
            "# should be configured.\n",
            "\n",
            "model {\n",
            "  ssd {\n",
            "    num_classes: 2\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    anchor_generator {\n",
            "      ssd_anchor_generator {\n",
            "        num_layers: 6\n",
            "        min_scale: 0.2\n",
            "        max_scale: 0.95\n",
            "        aspect_ratios: 1.0\n",
            "        aspect_ratios: 2.0\n",
            "        aspect_ratios: 0.5\n",
            "        aspect_ratios: 3.0\n",
            "        aspect_ratios: 0.3333\n",
            "      }\n",
            "    }\n",
            "    image_resizer {\n",
            "      fixed_shape_resizer {\n",
            "        height: 300\n",
            "        width: 300\n",
            "      }\n",
            "    }\n",
            "    box_predictor {\n",
            "      convolutional_box_predictor {\n",
            "        min_depth: 0\n",
            "        max_depth: 0\n",
            "        num_layers_before_predictor: 0\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 0.8\n",
            "        kernel_size: 1\n",
            "        box_code_size: 4\n",
            "        apply_sigmoid_to_scores: false\n",
            "        conv_hyperparams {\n",
            "          activation: RELU_6,\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.00004\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            truncated_normal_initializer {\n",
            "              stddev: 0.03\n",
            "              mean: 0.0\n",
            "            }\n",
            "          }\n",
            "          batch_norm {\n",
            "            train: true,\n",
            "            scale: true,\n",
            "            center: true,\n",
            "            decay: 0.9997,\n",
            "            epsilon: 0.001,\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'ssd_mobilenet_v2'\n",
            "      min_depth: 16\n",
            "      depth_multiplier: 1.0\n",
            "      conv_hyperparams {\n",
            "        activation: RELU_6,\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 0.00004\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          truncated_normal_initializer {\n",
            "            stddev: 0.03\n",
            "            mean: 0.0\n",
            "          }\n",
            "        }\n",
            "        batch_norm {\n",
            "          train: true,\n",
            "          scale: true,\n",
            "          center: true,\n",
            "          decay: 0.9997,\n",
            "          epsilon: 0.001,\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    loss {\n",
            "      classification_loss {\n",
            "        weighted_sigmoid {\n",
            "        }\n",
            "      }\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "        }\n",
            "      }\n",
            "      hard_example_miner {\n",
            "        num_hard_examples: 3000\n",
            "        iou_threshold: 0.99\n",
            "        loss_type: CLASSIFICATION\n",
            "        max_negatives_per_positive: 3\n",
            "        min_negatives_per_image: 3\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-8\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  batch_size: 12\n",
            "  optimizer {\n",
            "    rms_prop_optimizer: {\n",
            "      learning_rate: {\n",
            "        exponential_decay_learning_rate {\n",
            "          initial_learning_rate: 0.004\n",
            "          decay_steps: 800720\n",
            "          decay_factor: 0.95\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "      decay: 0.9\n",
            "      epsilon: 1.0\n",
            "    }\n",
            "  }\n",
            "  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
            "  fine_tune_checkpoint_type:  \"detection\"\n",
            "  # Note: The below line limits the training process to 200K steps, which we\n",
            "  # empirically found to be sufficient enough to train the pets dataset. This\n",
            "  # effectively bypasses the learning rate schedule (the learning rate will\n",
            "  # never decay). Remove the below line to train indefinitely.\n",
            "  num_steps: 20000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    ssd_random_crop {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/cysts.tfrecord\"\n",
            "  }\n",
            "  label_map_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/cysts_label_map.pbtxt\"\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  num_examples: 8000\n",
            "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
            "  # Remove the below line to evaluate indefinitely.\n",
            "  max_evals: 10\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord\"\n",
            "  }\n",
            "  label_map_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/cysts_label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_readers: 1\n",
            "}\n",
            "\n",
            "graph_rewriter {\n",
            "  quantization {\n",
            "    delay: 400\n",
            "    weight_bits: 8\n",
            "    activation_bits: 8\n",
            "  }\n",
            "}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f11w0uO3jFCB"
      },
      "source": [
        "model_dir = 'training/'\n",
        "# Optionally remove content in output model directory to fresh start.\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23TECXvNezIF"
      },
      "source": [
        "## Run Tensorboard(Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0H2PZs-mSCmO",
        "outputId": "175c7628-5863-47db-80de-3fd555e14c8c"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-01 04:57:14--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 18.205.222.128, 54.161.241.46, 52.202.168.65, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|18.205.222.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: â€˜ngrok-stable-linux-amd64.zipâ€™\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  31.1MB/s    in 0.4s    \n",
            "\n",
            "2021-12-01 04:57:14 (31.1 MB/s) - â€˜ngrok-stable-linux-amd64.zipâ€™ saved [13832437/13832437]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8o6r1o5SC5M"
      },
      "source": [
        "LOG_DIR = model_dir\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge1OX7gcSC7S"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5GSGxZNh8rp"
      },
      "source": [
        "### Get Tensorboard link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjhPT9iPSJ6T",
        "outputId": "f7d4ab4b-a0e3-4d14-d433-edcab14a9385"
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://387a-104-197-22-221.ngrok.io\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDddx2rPfex9"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjDHjhKQofT5",
        "outputId": "7ab4c5bd-6c41-4bcf-b811-f14fbffdb334"
      },
      "source": [
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "INFO:tensorflow:global_step/sec: 1.23909\n",
            "I1130 08:27:13.811398 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23909\n",
            "INFO:tensorflow:loss = 5.714007, step = 3100 (80.704 sec)\n",
            "I1130 08:27:13.812527 140184336205696 basic_session_run_hooks.py:260] loss = 5.714007, step = 3100 (80.704 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23712\n",
            "I1130 08:28:34.644165 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23712\n",
            "INFO:tensorflow:loss = 4.635526, step = 3200 (80.833 sec)\n",
            "I1130 08:28:34.645570 140184336205696 basic_session_run_hooks.py:260] loss = 4.635526, step = 3200 (80.833 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23934\n",
            "I1130 08:29:55.332228 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23934\n",
            "INFO:tensorflow:loss = 4.516806, step = 3300 (80.688 sec)\n",
            "I1130 08:29:55.333593 140184336205696 basic_session_run_hooks.py:260] loss = 4.516806, step = 3300 (80.688 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23017\n",
            "I1130 08:31:16.622059 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23017\n",
            "INFO:tensorflow:loss = 3.9729152, step = 3400 (81.290 sec)\n",
            "I1130 08:31:16.623305 140184336205696 basic_session_run_hooks.py:260] loss = 3.9729152, step = 3400 (81.290 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.22242\n",
            "I1130 08:32:38.427256 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.22242\n",
            "INFO:tensorflow:loss = 4.373691, step = 3500 (81.806 sec)\n",
            "I1130 08:32:38.428932 140184336205696 basic_session_run_hooks.py:260] loss = 4.373691, step = 3500 (81.806 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 3518 into training/model.ckpt.\n",
            "I1130 08:32:52.183862 140184336205696 basic_session_run_hooks.py:606] Saving checkpoints for 3518 into training/model.ckpt.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W1130 08:32:52.329032 140184336205696 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 08:32:54.743935 140184336205696 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 08:32:54.744655 140184336205696 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1130 08:32:54.744826 140184336205696 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e45c21f90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W1130 08:32:54.808037 140184336205696 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e45c21f90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e423959e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1130 08:32:55.033677 140184336205696 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e423959e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1130 08:32:55.712032 140184336205696 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 08:32:58.322320 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 08:32:58.356427 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 08:32:58.391027 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 08:32:58.424744 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 08:32:58.458997 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 08:32:58.493000 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "I1130 08:33:01.169600 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "I1130 08:33:01.170034 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "I1130 08:33:01.170458 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "I1130 08:33:01.170731 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "I1130 08:33:01.171147 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "I1130 08:33:01.171412 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "I1130 08:33:01.171748 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "I1130 08:33:01.172028 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "I1130 08:33:01.172403 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "I1130 08:33:01.172672 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "I1130 08:33:01.173087 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "I1130 08:33:01.173359 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "I1130 08:33:01.173693 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "I1130 08:33:01.174010 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "I1130 08:33:01.174378 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "I1130 08:33:01.174662 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "I1130 08:33:01.175061 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "I1130 08:33:01.175331 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "I1130 08:33:01.175711 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "I1130 08:33:01.176034 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "I1130 08:33:01.176411 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "I1130 08:33:01.176665 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "I1130 08:33:01.177064 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "I1130 08:33:01.177334 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "I1130 08:33:01.177680 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "I1130 08:33:01.177979 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "I1130 08:33:01.178314 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "I1130 08:33:01.178580 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "I1130 08:33:01.178995 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "I1130 08:33:01.179269 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "I1130 08:33:01.179632 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "I1130 08:33:01.179905 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "I1130 08:33:01.180277 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "I1130 08:33:01.180515 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "I1130 08:33:01.180856 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "I1130 08:33:01.181116 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1130 08:33:01.181368 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "I1130 08:33:01.181617 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1130 08:33:01.181867 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "I1130 08:33:01.182148 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1130 08:33:01.182400 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "I1130 08:33:01.182637 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1130 08:33:01.182895 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1130 08:33:02.889900 140184336205696 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-11-30T08:33:02Z\n",
            "I1130 08:33:02.919384 140184336205696 evaluation.py:255] Starting evaluation at 2021-11-30T08:33:02Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1130 08:33:04.020835 140184336205696 monitored_session.py:240] Graph was finalized.\n",
            "2021-11-30 08:33:04.021740: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 08:33:04.022263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 08:33:04.022372: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 08:33:04.022431: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 08:33:04.022509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 08:33:04.022570: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 08:33:04.022629: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 08:33:04.022684: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 08:33:04.022739: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 08:33:04.022854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 08:33:04.023339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 08:33:04.023732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 08:33:04.023836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-30 08:33:04.023864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-30 08:33:04.023908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-30 08:33:04.024079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 08:33:04.024545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 08:33:04.025016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-3518\n",
            "I1130 08:33:04.026456 140184336205696 saver.py:1284] Restoring parameters from training/model.ckpt-3518\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1130 08:33:05.845508 140184336205696 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1130 08:33:06.063476 140184336205696 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 147 images.\n",
            "I1130 08:33:19.473172 140181839787776 coco_evaluation.py:293] Performing evaluation on 147 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1130 08:33:19.473901 140181839787776 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I1130 08:33:19.487511 140181839787776 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.90s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.13s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.006\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.010\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.021\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.433\n",
            "INFO:tensorflow:Finished evaluation at 2021-11-30-08:33:20\n",
            "I1130 08:33:20.706301 140184336205696 evaluation.py:275] Finished evaluation at 2021-11-30-08:33:20\n",
            "INFO:tensorflow:Saving dict for global step 3518: DetectionBoxes_Precision/mAP = 0.00029764, DetectionBoxes_Precision/mAP (large) = 0.0057503716, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0012903572, DetectionBoxes_Precision/mAP@.75IOU = 3.3890092e-06, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.009935898, DetectionBoxes_Recall/AR@100 = 0.020833334, DetectionBoxes_Recall/AR@100 (large) = 0.43333334, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 9.978497, Loss/localization_loss = 2.5702865, Loss/regularization_loss = 0.3150736, Loss/total_loss = 12.8638525, global_step = 3518, learning_rate = 0.004, loss = 12.8638525\n",
            "I1130 08:33:20.706681 140184336205696 estimator.py:2049] Saving dict for global step 3518: DetectionBoxes_Precision/mAP = 0.00029764, DetectionBoxes_Precision/mAP (large) = 0.0057503716, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0012903572, DetectionBoxes_Precision/mAP@.75IOU = 3.3890092e-06, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.009935898, DetectionBoxes_Recall/AR@100 = 0.020833334, DetectionBoxes_Recall/AR@100 (large) = 0.43333334, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 9.978497, Loss/localization_loss = 2.5702865, Loss/regularization_loss = 0.3150736, Loss/total_loss = 12.8638525, global_step = 3518, learning_rate = 0.004, loss = 12.8638525\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3518: training/model.ckpt-3518\n",
            "I1130 08:33:20.708293 140184336205696 estimator.py:2109] Saving 'checkpoint_path' summary for global step 3518: training/model.ckpt-3518\n",
            "INFO:tensorflow:global_step/sec: 0.906941\n",
            "I1130 08:34:28.688069 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 0.906941\n",
            "INFO:tensorflow:loss = 3.4183817, step = 3600 (110.260 sec)\n",
            "I1130 08:34:28.689415 140184336205696 basic_session_run_hooks.py:260] loss = 3.4183817, step = 3600 (110.260 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.2283\n",
            "I1130 08:35:50.101281 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.2283\n",
            "INFO:tensorflow:loss = 4.2170053, step = 3700 (81.414 sec)\n",
            "I1130 08:35:50.102909 140184336205696 basic_session_run_hooks.py:260] loss = 4.2170053, step = 3700 (81.414 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.22976\n",
            "I1130 08:37:11.417935 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.22976\n",
            "INFO:tensorflow:loss = 3.2328658, step = 3800 (81.316 sec)\n",
            "I1130 08:37:11.419145 140184336205696 basic_session_run_hooks.py:260] loss = 3.2328658, step = 3800 (81.316 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23455\n",
            "I1130 08:38:32.418962 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23455\n",
            "INFO:tensorflow:loss = 3.7588527, step = 3900 (81.001 sec)\n",
            "I1130 08:38:32.420551 140184336205696 basic_session_run_hooks.py:260] loss = 3.7588527, step = 3900 (81.001 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23925\n",
            "I1130 08:39:53.112604 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23925\n",
            "INFO:tensorflow:loss = 3.457284, step = 4000 (80.693 sec)\n",
            "I1130 08:39:53.113900 140184336205696 basic_session_run_hooks.py:260] loss = 3.457284, step = 4000 (80.693 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23822\n",
            "I1130 08:41:13.873777 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23822\n",
            "INFO:tensorflow:loss = 4.2265835, step = 4100 (80.761 sec)\n",
            "I1130 08:41:13.875167 140184336205696 basic_session_run_hooks.py:260] loss = 4.2265835, step = 4100 (80.761 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23661\n",
            "I1130 08:42:34.739760 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23661\n",
            "INFO:tensorflow:loss = 4.062128, step = 4200 (80.866 sec)\n",
            "I1130 08:42:34.741257 140184336205696 basic_session_run_hooks.py:260] loss = 4.062128, step = 4200 (80.866 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 4223 into training/model.ckpt.\n",
            "I1130 08:42:52.680885 140184336205696 basic_session_run_hooks.py:606] Saving checkpoints for 4223 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 08:42:55.459712 140184336205696 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 08:42:55.460478 140184336205696 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1130 08:42:55.460630 140184336205696 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7ea0198050>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W1130 08:42:55.528011 140184336205696 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7ea0198050>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e489819e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1130 08:42:55.776982 140184336205696 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e489819e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1130 08:42:56.455056 140184336205696 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 08:42:59.273023 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 08:42:59.311217 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 08:42:59.347781 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 08:42:59.385283 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 08:42:59.424181 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 08:42:59.462038 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "I1130 08:43:02.237917 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "I1130 08:43:02.238369 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "I1130 08:43:02.238726 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "I1130 08:43:02.239070 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "I1130 08:43:02.239488 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "I1130 08:43:02.239814 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "I1130 08:43:02.240254 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "I1130 08:43:02.240514 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "I1130 08:43:02.240901 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "I1130 08:43:02.241240 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "I1130 08:43:02.241580 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "I1130 08:43:02.241837 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "I1130 08:43:02.242280 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "I1130 08:43:02.242545 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "I1130 08:43:02.242959 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "I1130 08:43:02.243253 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "I1130 08:43:02.243600 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "I1130 08:43:02.243875 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "I1130 08:43:02.244295 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "I1130 08:43:02.244571 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "I1130 08:43:02.244993 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "I1130 08:43:02.245282 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "I1130 08:43:02.245644 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "I1130 08:43:02.245985 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "I1130 08:43:02.246375 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "I1130 08:43:02.246658 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "I1130 08:43:02.247090 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "I1130 08:43:02.247367 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "I1130 08:43:02.247763 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "I1130 08:43:02.248080 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "I1130 08:43:02.248491 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "I1130 08:43:02.248783 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "I1130 08:43:02.249188 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "I1130 08:43:02.249451 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "I1130 08:43:02.249803 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "I1130 08:43:02.250069 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1130 08:43:02.250351 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "I1130 08:43:02.250674 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1130 08:43:02.250976 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "I1130 08:43:02.251245 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1130 08:43:02.251501 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "I1130 08:43:02.251756 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1130 08:43:02.252045 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1130 08:43:03.561310 140184336205696 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-11-30T08:43:03Z\n",
            "I1130 08:43:03.582666 140184336205696 evaluation.py:255] Starting evaluation at 2021-11-30T08:43:03Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1130 08:43:04.618620 140184336205696 monitored_session.py:240] Graph was finalized.\n",
            "2021-11-30 08:43:04.619523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 08:43:04.620300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 08:43:04.620415: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 08:43:04.620477: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 08:43:04.620534: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 08:43:04.620588: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 08:43:04.620642: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 08:43:04.620707: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 08:43:04.620782: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 08:43:04.620940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 08:43:04.621412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 08:43:04.621782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 08:43:04.621844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-30 08:43:04.621872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-30 08:43:04.621889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-30 08:43:04.622066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 08:43:04.622527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 08:43:04.622943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-4223\n",
            "I1130 08:43:04.624243 140184336205696 saver.py:1284] Restoring parameters from training/model.ckpt-4223\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1130 08:43:06.299772 140184336205696 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1130 08:43:06.494348 140184336205696 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 147 images.\n",
            "I1130 08:43:19.813613 140181839787776 coco_evaluation.py:293] Performing evaluation on 147 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1130 08:43:19.814544 140181839787776 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.02s)\n",
            "I1130 08:43:19.829965 140181839787776 coco_tools.py:138] DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.98s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.14s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.006\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.013\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.020\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.380\n",
            "INFO:tensorflow:Finished evaluation at 2021-11-30-08:43:21\n",
            "I1130 08:43:21.116363 140184336205696 evaluation.py:275] Finished evaluation at 2021-11-30-08:43:21\n",
            "INFO:tensorflow:Saving dict for global step 4223: DetectionBoxes_Precision/mAP = 0.00030246604, DetectionBoxes_Precision/mAP (large) = 0.0058777, DetectionBoxes_Precision/mAP (medium) = 0.0019851183, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0012906941, DetectionBoxes_Precision/mAP@.75IOU = 3.1801897e-06, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.012820513, DetectionBoxes_Recall/AR@100 = 0.019551283, DetectionBoxes_Recall/AR@100 (large) = 0.38, DetectionBoxes_Recall/AR@100 (medium) = 0.0054054055, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 10.523582, Loss/localization_loss = 2.5214288, Loss/regularization_loss = 0.31591928, Loss/total_loss = 13.360931, global_step = 4223, learning_rate = 0.004, loss = 13.360931\n",
            "I1130 08:43:21.116676 140184336205696 estimator.py:2049] Saving dict for global step 4223: DetectionBoxes_Precision/mAP = 0.00030246604, DetectionBoxes_Precision/mAP (large) = 0.0058777, DetectionBoxes_Precision/mAP (medium) = 0.0019851183, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0012906941, DetectionBoxes_Precision/mAP@.75IOU = 3.1801897e-06, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.012820513, DetectionBoxes_Recall/AR@100 = 0.019551283, DetectionBoxes_Recall/AR@100 (large) = 0.38, DetectionBoxes_Recall/AR@100 (medium) = 0.0054054055, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 10.523582, Loss/localization_loss = 2.5214288, Loss/regularization_loss = 0.31591928, Loss/total_loss = 13.360931, global_step = 4223, learning_rate = 0.004, loss = 13.360931\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4223: training/model.ckpt-4223\n",
            "I1130 08:43:21.118185 140184336205696 estimator.py:2109] Saving 'checkpoint_path' summary for global step 4223: training/model.ckpt-4223\n",
            "INFO:tensorflow:global_step/sec: 0.913197\n",
            "I1130 08:44:24.245137 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 0.913197\n",
            "INFO:tensorflow:loss = 5.5553827, step = 4300 (109.505 sec)\n",
            "I1130 08:44:24.246478 140184336205696 basic_session_run_hooks.py:260] loss = 5.5553827, step = 4300 (109.505 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23698\n",
            "I1130 08:45:45.086870 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23698\n",
            "INFO:tensorflow:loss = 5.486841, step = 4400 (80.842 sec)\n",
            "I1130 08:45:45.088150 140184336205696 basic_session_run_hooks.py:260] loss = 5.486841, step = 4400 (80.842 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.22396\n",
            "I1130 08:47:06.789072 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.22396\n",
            "INFO:tensorflow:loss = 3.9439778, step = 4500 (81.702 sec)\n",
            "I1130 08:47:06.790527 140184336205696 basic_session_run_hooks.py:260] loss = 3.9439778, step = 4500 (81.702 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23453\n",
            "I1130 08:48:27.791774 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23453\n",
            "INFO:tensorflow:loss = 3.9970584, step = 4600 (81.002 sec)\n",
            "I1130 08:48:27.793007 140184336205696 basic_session_run_hooks.py:260] loss = 3.9970584, step = 4600 (81.002 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24099\n",
            "I1130 08:49:48.372517 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24099\n",
            "INFO:tensorflow:loss = 2.7989686, step = 4700 (80.581 sec)\n",
            "I1130 08:49:48.373949 140184336205696 basic_session_run_hooks.py:260] loss = 2.7989686, step = 4700 (80.581 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23864\n",
            "I1130 08:51:09.106296 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23864\n",
            "INFO:tensorflow:loss = 3.5346951, step = 4800 (80.737 sec)\n",
            "I1130 08:51:09.110490 140184336205696 basic_session_run_hooks.py:260] loss = 3.5346951, step = 4800 (80.737 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24182\n",
            "I1130 08:52:29.633066 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24182\n",
            "INFO:tensorflow:loss = 3.9499698, step = 4900 (80.524 sec)\n",
            "I1130 08:52:29.634160 140184336205696 basic_session_run_hooks.py:260] loss = 3.9499698, step = 4900 (80.524 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 4930 into training/model.ckpt.\n",
            "I1130 08:52:52.935374 140184336205696 basic_session_run_hooks.py:606] Saving checkpoints for 4930 into training/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I1130 08:52:55.364641 140184336205696 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 1.20586\n",
            "I1130 08:53:52.561549 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.20586\n",
            "INFO:tensorflow:loss = 3.4463043, step = 5000 (82.929 sec)\n",
            "I1130 08:53:52.562688 140184336205696 basic_session_run_hooks.py:260] loss = 3.4463043, step = 5000 (82.929 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23877\n",
            "I1130 08:55:13.286704 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23877\n",
            "INFO:tensorflow:loss = 2.5144434, step = 5100 (80.725 sec)\n",
            "I1130 08:55:13.287961 140184336205696 basic_session_run_hooks.py:260] loss = 2.5144434, step = 5100 (80.725 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23484\n",
            "I1130 08:56:34.268801 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23484\n",
            "INFO:tensorflow:loss = 4.1655936, step = 5200 (80.982 sec)\n",
            "I1130 08:56:34.270325 140184336205696 basic_session_run_hooks.py:260] loss = 4.1655936, step = 5200 (80.982 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23968\n",
            "I1130 08:57:54.935040 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23968\n",
            "INFO:tensorflow:loss = 3.1299672, step = 5300 (80.666 sec)\n",
            "I1130 08:57:54.936203 140184336205696 basic_session_run_hooks.py:260] loss = 3.1299672, step = 5300 (80.666 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24179\n",
            "I1130 08:59:15.464094 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24179\n",
            "INFO:tensorflow:loss = 4.3585415, step = 5400 (80.529 sec)\n",
            "I1130 08:59:15.465663 140184336205696 basic_session_run_hooks.py:260] loss = 4.3585415, step = 5400 (80.529 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23709\n",
            "I1130 09:00:36.298943 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23709\n",
            "INFO:tensorflow:loss = 2.6340258, step = 5500 (80.834 sec)\n",
            "I1130 09:00:36.299997 140184336205696 basic_session_run_hooks.py:260] loss = 2.6340258, step = 5500 (80.834 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23426\n",
            "I1130 09:01:57.319243 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23426\n",
            "INFO:tensorflow:loss = 3.6598184, step = 5600 (81.021 sec)\n",
            "I1130 09:01:57.320502 140184336205696 basic_session_run_hooks.py:260] loss = 3.6598184, step = 5600 (81.021 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 5670 into training/model.ckpt.\n",
            "I1130 09:02:53.239578 140184336205696 basic_session_run_hooks.py:606] Saving checkpoints for 5670 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 09:02:55.669573 140184336205696 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 09:02:55.670642 140184336205696 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1130 09:02:55.670794 140184336205696 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e45948510>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W1130 09:02:55.730689 140184336205696 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e45948510>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e45e9d830> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1130 09:02:55.943729 140184336205696 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e45e9d830> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1130 09:02:56.565853 140184336205696 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:02:59.584293 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:02:59.620810 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:02:59.657491 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:02:59.693044 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:02:59.729279 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:02:59.765175 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "I1130 09:03:02.372552 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "I1130 09:03:02.372953 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "I1130 09:03:02.373278 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "I1130 09:03:02.373517 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "I1130 09:03:02.373850 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "I1130 09:03:02.374113 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "I1130 09:03:02.374434 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "I1130 09:03:02.374696 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "I1130 09:03:02.375052 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "I1130 09:03:02.375289 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "I1130 09:03:02.375609 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "I1130 09:03:02.375937 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "I1130 09:03:02.376295 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "I1130 09:03:02.376578 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "I1130 09:03:02.376899 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "I1130 09:03:02.377146 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "I1130 09:03:02.377460 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "I1130 09:03:02.377738 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "I1130 09:03:02.378186 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "I1130 09:03:02.378449 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "I1130 09:03:02.378796 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "I1130 09:03:02.379126 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "I1130 09:03:02.379493 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "I1130 09:03:02.379733 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "I1130 09:03:02.380196 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "I1130 09:03:02.380507 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "I1130 09:03:02.380978 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "I1130 09:03:02.381272 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "I1130 09:03:02.381615 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "I1130 09:03:02.381883 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "I1130 09:03:02.382255 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "I1130 09:03:02.382557 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "I1130 09:03:02.382998 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "I1130 09:03:02.383292 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "I1130 09:03:02.383653 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "I1130 09:03:02.383975 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1130 09:03:02.384272 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "I1130 09:03:02.384586 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1130 09:03:02.384906 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "I1130 09:03:02.385181 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1130 09:03:02.385451 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "I1130 09:03:02.385732 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1130 09:03:02.386025 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1130 09:03:03.592875 140184336205696 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-11-30T09:03:03Z\n",
            "I1130 09:03:03.621291 140184336205696 evaluation.py:255] Starting evaluation at 2021-11-30T09:03:03Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1130 09:03:04.601626 140184336205696 monitored_session.py:240] Graph was finalized.\n",
            "2021-11-30 09:03:04.602453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:03:04.602978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 09:03:04.603083: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 09:03:04.603141: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 09:03:04.603242: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 09:03:04.603300: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 09:03:04.603363: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 09:03:04.603416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 09:03:04.603469: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 09:03:04.603575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:03:04.604029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:03:04.604409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 09:03:04.604505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-30 09:03:04.604530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-30 09:03:04.604550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-30 09:03:04.604694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:03:04.605248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:03:04.605709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-5670\n",
            "I1130 09:03:04.606984 140184336205696 saver.py:1284] Restoring parameters from training/model.ckpt-5670\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1130 09:03:06.325506 140184336205696 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1130 09:03:06.518675 140184336205696 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 147 images.\n",
            "I1130 09:03:19.625200 140181839787776 coco_evaluation.py:293] Performing evaluation on 147 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1130 09:03:19.625828 140181839787776 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I1130 09:03:19.636523 140181839787776 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.82s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.13s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.019\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.007\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.015\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.460\n",
            "INFO:tensorflow:Finished evaluation at 2021-11-30-09:03:20\n",
            "I1130 09:03:20.735984 140184336205696 evaluation.py:275] Finished evaluation at 2021-11-30-09:03:20\n",
            "INFO:tensorflow:Saving dict for global step 5670: DetectionBoxes_Precision/mAP = 0.00043624514, DetectionBoxes_Precision/mAP (large) = 0.00704611, DetectionBoxes_Precision/mAP (medium) = 0.003966153, DetectionBoxes_Precision/mAP (small) = 0.01940594, DetectionBoxes_Precision/mAP@.50IOU = 0.0016201092, DetectionBoxes_Precision/mAP@.75IOU = 1.7195189e-05, DetectionBoxes_Recall/AR@1 = 0.0019230769, DetectionBoxes_Recall/AR@10 = 0.01474359, DetectionBoxes_Recall/AR@100 = 0.044871796, DetectionBoxes_Recall/AR@100 (large) = 0.46, DetectionBoxes_Recall/AR@100 (medium) = 0.008108108, DetectionBoxes_Recall/AR@100 (small) = 0.020833334, Loss/classification_loss = 10.893135, Loss/localization_loss = 2.0282516, Loss/regularization_loss = 0.3176831, Loss/total_loss = 13.239072, global_step = 5670, learning_rate = 0.004, loss = 13.239072\n",
            "I1130 09:03:20.736358 140184336205696 estimator.py:2049] Saving dict for global step 5670: DetectionBoxes_Precision/mAP = 0.00043624514, DetectionBoxes_Precision/mAP (large) = 0.00704611, DetectionBoxes_Precision/mAP (medium) = 0.003966153, DetectionBoxes_Precision/mAP (small) = 0.01940594, DetectionBoxes_Precision/mAP@.50IOU = 0.0016201092, DetectionBoxes_Precision/mAP@.75IOU = 1.7195189e-05, DetectionBoxes_Recall/AR@1 = 0.0019230769, DetectionBoxes_Recall/AR@10 = 0.01474359, DetectionBoxes_Recall/AR@100 = 0.044871796, DetectionBoxes_Recall/AR@100 (large) = 0.46, DetectionBoxes_Recall/AR@100 (medium) = 0.008108108, DetectionBoxes_Recall/AR@100 (small) = 0.020833334, Loss/classification_loss = 10.893135, Loss/localization_loss = 2.0282516, Loss/regularization_loss = 0.3176831, Loss/total_loss = 13.239072, global_step = 5670, learning_rate = 0.004, loss = 13.239072\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5670: training/model.ckpt-5670\n",
            "I1130 09:03:20.737800 140184336205696 estimator.py:2109] Saving 'checkpoint_path' summary for global step 5670: training/model.ckpt-5670\n",
            "INFO:tensorflow:global_step/sec: 0.920036\n",
            "I1130 09:03:46.010645 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 0.920036\n",
            "INFO:tensorflow:loss = 4.0113893, step = 5700 (108.691 sec)\n",
            "I1130 09:03:46.011744 140184336205696 basic_session_run_hooks.py:260] loss = 4.0113893, step = 5700 (108.691 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23197\n",
            "I1130 09:05:07.181689 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23197\n",
            "INFO:tensorflow:loss = 3.8733375, step = 5800 (81.171 sec)\n",
            "I1130 09:05:07.183034 140184336205696 basic_session_run_hooks.py:260] loss = 3.8733375, step = 5800 (81.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23064\n",
            "I1130 09:06:28.440402 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23064\n",
            "INFO:tensorflow:loss = 7.0948515, step = 5900 (81.259 sec)\n",
            "I1130 09:06:28.441621 140184336205696 basic_session_run_hooks.py:260] loss = 7.0948515, step = 5900 (81.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.2343\n",
            "I1130 09:07:49.458134 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.2343\n",
            "INFO:tensorflow:loss = 4.351832, step = 6000 (81.018 sec)\n",
            "I1130 09:07:49.459425 140184336205696 basic_session_run_hooks.py:260] loss = 4.351832, step = 6000 (81.018 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23359\n",
            "I1130 09:09:10.522052 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23359\n",
            "INFO:tensorflow:loss = 3.113902, step = 6100 (81.064 sec)\n",
            "I1130 09:09:10.523308 140184336205696 basic_session_run_hooks.py:260] loss = 3.113902, step = 6100 (81.064 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23263\n",
            "I1130 09:10:31.649081 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23263\n",
            "INFO:tensorflow:loss = 3.505719, step = 6200 (81.127 sec)\n",
            "I1130 09:10:31.650256 140184336205696 basic_session_run_hooks.py:260] loss = 3.505719, step = 6200 (81.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23342\n",
            "I1130 09:11:52.724189 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23342\n",
            "INFO:tensorflow:loss = 3.3535764, step = 6300 (81.075 sec)\n",
            "I1130 09:11:52.725504 140184336205696 basic_session_run_hooks.py:260] loss = 3.3535764, step = 6300 (81.075 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 6377 into training/model.ckpt.\n",
            "I1130 09:12:53.674652 140184336205696 basic_session_run_hooks.py:606] Saving checkpoints for 6377 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 09:12:56.184882 140184336205696 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 09:12:56.185625 140184336205696 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1130 09:12:56.185770 140184336205696 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e48ae8e50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W1130 09:12:56.246959 140184336205696 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e48ae8e50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e47f968c0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1130 09:12:56.457250 140184336205696 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e47f968c0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1130 09:12:57.092488 140184336205696 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:12:59.617190 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:12:59.653772 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:12:59.689354 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:12:59.724395 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:12:59.766641 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:12:59.800702 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "I1130 09:13:02.759745 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "I1130 09:13:02.760111 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "I1130 09:13:02.760446 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "I1130 09:13:02.760671 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "I1130 09:13:02.761152 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "I1130 09:13:02.761428 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "I1130 09:13:02.761741 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "I1130 09:13:02.761992 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "I1130 09:13:02.762307 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "I1130 09:13:02.762545 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "I1130 09:13:02.762845 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "I1130 09:13:02.763099 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "I1130 09:13:02.763413 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "I1130 09:13:02.763631 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "I1130 09:13:02.764008 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "I1130 09:13:02.764266 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "I1130 09:13:02.764564 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "I1130 09:13:02.764781 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "I1130 09:13:02.765188 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "I1130 09:13:02.765428 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "I1130 09:13:02.765734 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "I1130 09:13:02.766062 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "I1130 09:13:02.766431 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "I1130 09:13:02.766659 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "I1130 09:13:02.767023 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "I1130 09:13:02.767273 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "I1130 09:13:02.767593 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "I1130 09:13:02.767821 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "I1130 09:13:02.768150 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "I1130 09:13:02.768372 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "I1130 09:13:02.768687 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "I1130 09:13:02.768905 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "I1130 09:13:02.769275 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "I1130 09:13:02.769505 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "I1130 09:13:02.769817 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "I1130 09:13:02.770065 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1130 09:13:02.770308 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "I1130 09:13:02.770538 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1130 09:13:02.770771 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "I1130 09:13:02.771038 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1130 09:13:02.771276 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "I1130 09:13:02.771500 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1130 09:13:02.771723 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1130 09:13:03.936529 140184336205696 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-11-30T09:13:03Z\n",
            "I1130 09:13:03.957262 140184336205696 evaluation.py:255] Starting evaluation at 2021-11-30T09:13:03Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1130 09:13:04.931250 140184336205696 monitored_session.py:240] Graph was finalized.\n",
            "2021-11-30 09:13:04.932067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:13:04.932497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 09:13:04.932610: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 09:13:04.932670: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 09:13:04.932737: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 09:13:04.932798: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 09:13:04.932876: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 09:13:04.932971: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 09:13:04.933039: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 09:13:04.933171: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:13:04.933629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:13:04.934120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 09:13:04.934183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-30 09:13:04.934227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-30 09:13:04.934249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-30 09:13:04.934388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:13:04.934795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:13:04.935243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-6377\n",
            "I1130 09:13:04.936537 140184336205696 saver.py:1284] Restoring parameters from training/model.ckpt-6377\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1130 09:13:06.543607 140184336205696 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1130 09:13:06.728276 140184336205696 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 147 images.\n",
            "I1130 09:13:19.377911 140181839787776 coco_evaluation.py:293] Performing evaluation on 147 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1130 09:13:19.378786 140181839787776 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I1130 09:13:19.391018 140181839787776 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.80s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.13s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.072\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.077\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.006\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.046\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.179\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.136\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.323\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.473\n",
            "INFO:tensorflow:Finished evaluation at 2021-11-30-09:13:20\n",
            "I1130 09:13:20.470170 140184336205696 evaluation.py:275] Finished evaluation at 2021-11-30-09:13:20\n",
            "INFO:tensorflow:Saving dict for global step 6377: DetectionBoxes_Precision/mAP = 0.0020665724, DetectionBoxes_Precision/mAP (large) = 0.0057992735, DetectionBoxes_Precision/mAP (medium) = 0.07716202, DetectionBoxes_Precision/mAP (small) = 0.07233365, DetectionBoxes_Precision/mAP@.50IOU = 0.005828851, DetectionBoxes_Precision/mAP@.75IOU = 0.0005286223, DetectionBoxes_Recall/AR@1 = 0.0019230769, DetectionBoxes_Recall/AR@10 = 0.046153847, DetectionBoxes_Recall/AR@100 = 0.17916666, DetectionBoxes_Recall/AR@100 (large) = 0.47333333, DetectionBoxes_Recall/AR@100 (medium) = 0.32297298, DetectionBoxes_Recall/AR@100 (small) = 0.13600746, Loss/classification_loss = 9.659708, Loss/localization_loss = 1.6205716, Loss/regularization_loss = 0.31851473, Loss/total_loss = 11.598792, global_step = 6377, learning_rate = 0.004, loss = 11.598792\n",
            "I1130 09:13:20.470462 140184336205696 estimator.py:2049] Saving dict for global step 6377: DetectionBoxes_Precision/mAP = 0.0020665724, DetectionBoxes_Precision/mAP (large) = 0.0057992735, DetectionBoxes_Precision/mAP (medium) = 0.07716202, DetectionBoxes_Precision/mAP (small) = 0.07233365, DetectionBoxes_Precision/mAP@.50IOU = 0.005828851, DetectionBoxes_Precision/mAP@.75IOU = 0.0005286223, DetectionBoxes_Recall/AR@1 = 0.0019230769, DetectionBoxes_Recall/AR@10 = 0.046153847, DetectionBoxes_Recall/AR@100 = 0.17916666, DetectionBoxes_Recall/AR@100 (large) = 0.47333333, DetectionBoxes_Recall/AR@100 (medium) = 0.32297298, DetectionBoxes_Recall/AR@100 (small) = 0.13600746, Loss/classification_loss = 9.659708, Loss/localization_loss = 1.6205716, Loss/regularization_loss = 0.31851473, Loss/total_loss = 11.598792, global_step = 6377, learning_rate = 0.004, loss = 11.598792\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6377: training/model.ckpt-6377\n",
            "I1130 09:13:20.471825 140184336205696 estimator.py:2109] Saving 'checkpoint_path' summary for global step 6377: training/model.ckpt-6377\n",
            "INFO:tensorflow:global_step/sec: 0.932277\n",
            "I1130 09:13:39.988456 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 0.932277\n",
            "INFO:tensorflow:loss = 3.1249232, step = 6400 (107.264 sec)\n",
            "I1130 09:13:39.989537 140184336205696 basic_session_run_hooks.py:260] loss = 3.1249232, step = 6400 (107.264 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24677\n",
            "I1130 09:15:00.195850 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24677\n",
            "INFO:tensorflow:loss = 2.97957, step = 6500 (80.207 sec)\n",
            "I1130 09:15:00.196982 140184336205696 basic_session_run_hooks.py:260] loss = 2.97957, step = 6500 (80.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.2427\n",
            "I1130 09:16:20.665749 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.2427\n",
            "INFO:tensorflow:loss = 3.2685905, step = 6600 (80.470 sec)\n",
            "I1130 09:16:20.667194 140184336205696 basic_session_run_hooks.py:260] loss = 3.2685905, step = 6600 (80.470 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24467\n",
            "I1130 09:17:41.008353 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24467\n",
            "INFO:tensorflow:loss = 2.7128673, step = 6700 (80.342 sec)\n",
            "I1130 09:17:41.009525 140184336205696 basic_session_run_hooks.py:260] loss = 2.7128673, step = 6700 (80.342 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24529\n",
            "I1130 09:19:01.310975 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24529\n",
            "INFO:tensorflow:loss = 3.561534, step = 6800 (80.302 sec)\n",
            "I1130 09:19:01.311952 140184336205696 basic_session_run_hooks.py:260] loss = 3.561534, step = 6800 (80.302 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24485\n",
            "I1130 09:20:21.642053 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24485\n",
            "INFO:tensorflow:loss = 2.744369, step = 6900 (80.332 sec)\n",
            "I1130 09:20:21.643997 140184336205696 basic_session_run_hooks.py:260] loss = 2.744369, step = 6900 (80.332 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.2447\n",
            "I1130 09:21:41.982934 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.2447\n",
            "INFO:tensorflow:loss = 4.6865344, step = 7000 (80.340 sec)\n",
            "I1130 09:21:41.984415 140184336205696 basic_session_run_hooks.py:260] loss = 4.6865344, step = 7000 (80.340 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 7091 into training/model.ckpt.\n",
            "I1130 09:22:54.160792 140184336205696 basic_session_run_hooks.py:606] Saving checkpoints for 7091 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 09:22:56.725251 140184336205696 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 09:22:56.725888 140184336205696 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1130 09:22:56.726062 140184336205696 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e45857f90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W1130 09:22:56.793691 140184336205696 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e45857f90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e45eba9e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1130 09:22:57.025072 140184336205696 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e45eba9e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1130 09:22:57.674373 140184336205696 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:23:00.283675 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:23:00.320711 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:23:00.356903 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:23:00.392986 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:23:00.430016 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:23:00.467468 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "I1130 09:23:03.095337 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "I1130 09:23:03.095690 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "I1130 09:23:03.096064 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "I1130 09:23:03.096328 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "I1130 09:23:03.096684 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "I1130 09:23:03.097030 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "I1130 09:23:03.097465 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "I1130 09:23:03.097740 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "I1130 09:23:03.098114 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "I1130 09:23:03.098356 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "I1130 09:23:03.098754 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "I1130 09:23:03.099048 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "I1130 09:23:03.099429 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "I1130 09:23:03.099701 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "I1130 09:23:03.100057 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "I1130 09:23:03.100368 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "I1130 09:23:03.100701 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "I1130 09:23:03.100982 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "I1130 09:23:03.101343 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "I1130 09:23:03.101627 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "I1130 09:23:03.102040 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "I1130 09:23:03.102324 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "I1130 09:23:03.102688 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "I1130 09:23:03.103022 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "I1130 09:23:03.103465 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "I1130 09:23:03.103724 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "I1130 09:23:03.104116 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "I1130 09:23:03.104372 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "I1130 09:23:03.104706 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "I1130 09:23:03.105003 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "I1130 09:23:03.105339 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "I1130 09:23:03.105600 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "I1130 09:23:03.106035 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "I1130 09:23:03.106358 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "I1130 09:23:03.106703 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "I1130 09:23:03.106998 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1130 09:23:03.107272 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "I1130 09:23:03.107550 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1130 09:23:03.107810 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "I1130 09:23:03.108078 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1130 09:23:03.108317 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "I1130 09:23:03.108577 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1130 09:23:03.108846 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1130 09:23:04.281646 140184336205696 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-11-30T09:23:04Z\n",
            "I1130 09:23:04.301625 140184336205696 evaluation.py:255] Starting evaluation at 2021-11-30T09:23:04Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1130 09:23:05.259037 140184336205696 monitored_session.py:240] Graph was finalized.\n",
            "2021-11-30 09:23:05.259812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:23:05.260327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 09:23:05.260421: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 09:23:05.260479: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 09:23:05.260537: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 09:23:05.260597: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 09:23:05.260646: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 09:23:05.260694: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 09:23:05.260742: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 09:23:05.260838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:23:05.261292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:23:05.261617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 09:23:05.261703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-30 09:23:05.261727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-30 09:23:05.261742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-30 09:23:05.261869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:23:05.262268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:23:05.262602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-7091\n",
            "I1130 09:23:05.263778 140184336205696 saver.py:1284] Restoring parameters from training/model.ckpt-7091\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1130 09:23:06.836447 140184336205696 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1130 09:23:07.016626 140184336205696 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 147 images.\n",
            "I1130 09:23:19.687334 140181839787776 coco_evaluation.py:293] Performing evaluation on 147 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1130 09:23:19.688100 140181839787776 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I1130 09:23:19.700888 140181839787776 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.85s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.13s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.032\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.059\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.048\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.236\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.012\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.037\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.078\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.233\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.412\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.480\n",
            "INFO:tensorflow:Finished evaluation at 2021-11-30-09:23:20\n",
            "I1130 09:23:20.844531 140184336205696 evaluation.py:275] Finished evaluation at 2021-11-30-09:23:20\n",
            "INFO:tensorflow:Saving dict for global step 7091: DetectionBoxes_Precision/mAP = 0.032476682, DetectionBoxes_Precision/mAP (large) = 0.011980039, DetectionBoxes_Precision/mAP (medium) = 0.2356293, DetectionBoxes_Precision/mAP (small) = 0.083919995, DetectionBoxes_Precision/mAP@.50IOU = 0.059436176, DetectionBoxes_Precision/mAP@.75IOU = 0.047960326, DetectionBoxes_Recall/AR@1 = 0.036538463, DetectionBoxes_Recall/AR@10 = 0.077564105, DetectionBoxes_Recall/AR@100 = 0.23301283, DetectionBoxes_Recall/AR@100 (large) = 0.48, DetectionBoxes_Recall/AR@100 (medium) = 0.41216215, DetectionBoxes_Recall/AR@100 (small) = 0.167102, Loss/classification_loss = 9.445048, Loss/localization_loss = 1.4314193, Loss/regularization_loss = 0.31933844, Loss/total_loss = 11.195806, global_step = 7091, learning_rate = 0.004, loss = 11.195806\n",
            "I1130 09:23:20.844840 140184336205696 estimator.py:2049] Saving dict for global step 7091: DetectionBoxes_Precision/mAP = 0.032476682, DetectionBoxes_Precision/mAP (large) = 0.011980039, DetectionBoxes_Precision/mAP (medium) = 0.2356293, DetectionBoxes_Precision/mAP (small) = 0.083919995, DetectionBoxes_Precision/mAP@.50IOU = 0.059436176, DetectionBoxes_Precision/mAP@.75IOU = 0.047960326, DetectionBoxes_Recall/AR@1 = 0.036538463, DetectionBoxes_Recall/AR@10 = 0.077564105, DetectionBoxes_Recall/AR@100 = 0.23301283, DetectionBoxes_Recall/AR@100 (large) = 0.48, DetectionBoxes_Recall/AR@100 (medium) = 0.41216215, DetectionBoxes_Recall/AR@100 (small) = 0.167102, Loss/classification_loss = 9.445048, Loss/localization_loss = 1.4314193, Loss/regularization_loss = 0.31933844, Loss/total_loss = 11.195806, global_step = 7091, learning_rate = 0.004, loss = 11.195806\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7091: training/model.ckpt-7091\n",
            "I1130 09:23:20.846379 140184336205696 estimator.py:2109] Saving 'checkpoint_path' summary for global step 7091: training/model.ckpt-7091\n",
            "INFO:tensorflow:global_step/sec: 0.933575\n",
            "I1130 09:23:29.098090 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 0.933575\n",
            "INFO:tensorflow:loss = 2.7928646, step = 7100 (107.115 sec)\n",
            "I1130 09:23:29.099235 140184336205696 basic_session_run_hooks.py:260] loss = 2.7928646, step = 7100 (107.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24468\n",
            "I1130 09:24:49.440267 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24468\n",
            "INFO:tensorflow:loss = 3.6959937, step = 7200 (80.342 sec)\n",
            "I1130 09:24:49.441436 140184336205696 basic_session_run_hooks.py:260] loss = 3.6959937, step = 7200 (80.342 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24673\n",
            "I1130 09:26:09.650249 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24673\n",
            "INFO:tensorflow:loss = 3.7410119, step = 7300 (80.210 sec)\n",
            "I1130 09:26:09.651273 140184336205696 basic_session_run_hooks.py:260] loss = 3.7410119, step = 7300 (80.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24532\n",
            "I1130 09:27:29.951151 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24532\n",
            "INFO:tensorflow:loss = 3.249496, step = 7400 (80.301 sec)\n",
            "I1130 09:27:29.952586 140184336205696 basic_session_run_hooks.py:260] loss = 3.249496, step = 7400 (80.301 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.2453\n",
            "I1130 09:28:50.253084 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.2453\n",
            "INFO:tensorflow:loss = 3.298332, step = 7500 (80.302 sec)\n",
            "I1130 09:28:50.254389 140184336205696 basic_session_run_hooks.py:260] loss = 3.298332, step = 7500 (80.302 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24187\n",
            "I1130 09:30:10.776829 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24187\n",
            "INFO:tensorflow:loss = 4.8243866, step = 7600 (80.524 sec)\n",
            "I1130 09:30:10.778135 140184336205696 basic_session_run_hooks.py:260] loss = 4.8243866, step = 7600 (80.524 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.2454\n",
            "I1130 09:31:31.072430 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.2454\n",
            "INFO:tensorflow:loss = 3.2245355, step = 7700 (80.296 sec)\n",
            "I1130 09:31:31.073722 140184336205696 basic_session_run_hooks.py:260] loss = 3.2245355, step = 7700 (80.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23742\n",
            "I1130 09:32:51.885463 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23742\n",
            "INFO:tensorflow:loss = 2.5617926, step = 7800 (80.813 sec)\n",
            "I1130 09:32:51.886839 140184336205696 basic_session_run_hooks.py:260] loss = 2.5617926, step = 7800 (80.813 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 7804 into training/model.ckpt.\n",
            "I1130 09:32:54.326204 140184336205696 basic_session_run_hooks.py:606] Saving checkpoints for 7804 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 09:32:56.832758 140184336205696 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 09:32:56.833447 140184336205696 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1130 09:32:56.833649 140184336205696 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e46b5f610>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W1130 09:32:56.898497 140184336205696 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e46b5f610>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e46dbf9e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1130 09:32:57.128631 140184336205696 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e46dbf9e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1130 09:32:58.417666 140184336205696 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:33:01.098502 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:33:01.134337 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:33:01.170142 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:33:01.209433 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:33:01.245656 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:33:01.280761 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "I1130 09:33:03.895866 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "I1130 09:33:03.896214 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "I1130 09:33:03.896537 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "I1130 09:33:03.896761 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "I1130 09:33:03.897096 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "I1130 09:33:03.897340 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "I1130 09:33:03.897678 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "I1130 09:33:03.897956 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "I1130 09:33:03.898276 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "I1130 09:33:03.898502 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "I1130 09:33:03.898800 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "I1130 09:33:03.899062 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "I1130 09:33:03.899371 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "I1130 09:33:03.899648 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "I1130 09:33:03.900015 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "I1130 09:33:03.900265 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "I1130 09:33:03.900629 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "I1130 09:33:03.900857 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "I1130 09:33:03.901226 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "I1130 09:33:03.901465 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "I1130 09:33:03.901758 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "I1130 09:33:03.902018 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "I1130 09:33:03.902352 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "I1130 09:33:03.902575 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "I1130 09:33:03.902894 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "I1130 09:33:03.903150 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "I1130 09:33:03.903547 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "I1130 09:33:03.903785 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "I1130 09:33:03.904130 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "I1130 09:33:03.904362 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "I1130 09:33:03.904685 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "I1130 09:33:03.904943 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "I1130 09:33:03.905254 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "I1130 09:33:03.905472 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "I1130 09:33:03.905778 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "I1130 09:33:03.906070 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1130 09:33:03.906313 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "I1130 09:33:03.906538 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1130 09:33:03.906795 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "I1130 09:33:03.907093 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1130 09:33:03.907381 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "I1130 09:33:03.907631 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1130 09:33:03.907867 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1130 09:33:05.084544 140184336205696 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-11-30T09:33:05Z\n",
            "I1130 09:33:05.104544 140184336205696 evaluation.py:255] Starting evaluation at 2021-11-30T09:33:05Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1130 09:33:06.084622 140184336205696 monitored_session.py:240] Graph was finalized.\n",
            "2021-11-30 09:33:06.085407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:33:06.085845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 09:33:06.086021: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 09:33:06.086092: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 09:33:06.086160: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 09:33:06.086226: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 09:33:06.086279: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 09:33:06.086329: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 09:33:06.086379: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 09:33:06.086490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:33:06.086930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:33:06.087279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 09:33:06.087338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-30 09:33:06.087361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-30 09:33:06.087381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-30 09:33:06.087516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:33:06.087921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:33:06.088336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-7804\n",
            "I1130 09:33:06.089555 140184336205696 saver.py:1284] Restoring parameters from training/model.ckpt-7804\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1130 09:33:07.796537 140184336205696 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1130 09:33:08.024619 140184336205696 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 147 images.\n",
            "I1130 09:33:20.988684 140181839787776 coco_evaluation.py:293] Performing evaluation on 147 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1130 09:33:20.989353 140181839787776 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I1130 09:33:21.003229 140181839787776 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.77s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.13s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.112\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.218\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.089\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.108\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.352\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.025\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.121\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.233\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.307\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.253\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.536\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.333\n",
            "INFO:tensorflow:Finished evaluation at 2021-11-30-09:33:22\n",
            "I1130 09:33:22.068684 140184336205696 evaluation.py:275] Finished evaluation at 2021-11-30-09:33:22\n",
            "INFO:tensorflow:Saving dict for global step 7804: DetectionBoxes_Precision/mAP = 0.11216226, DetectionBoxes_Precision/mAP (large) = 0.024891393, DetectionBoxes_Precision/mAP (medium) = 0.35223886, DetectionBoxes_Precision/mAP (small) = 0.10823697, DetectionBoxes_Precision/mAP@.50IOU = 0.21828444, DetectionBoxes_Precision/mAP@.75IOU = 0.089089625, DetectionBoxes_Recall/AR@1 = 0.12083333, DetectionBoxes_Recall/AR@10 = 0.23301283, DetectionBoxes_Recall/AR@100 = 0.30673078, DetectionBoxes_Recall/AR@100 (large) = 0.33333334, DetectionBoxes_Recall/AR@100 (medium) = 0.5364865, DetectionBoxes_Recall/AR@100 (small) = 0.25329602, Loss/classification_loss = 7.963724, Loss/localization_loss = 1.2336031, Loss/regularization_loss = 0.3201472, Loss/total_loss = 9.517473, global_step = 7804, learning_rate = 0.004, loss = 9.517473\n",
            "I1130 09:33:22.069041 140184336205696 estimator.py:2049] Saving dict for global step 7804: DetectionBoxes_Precision/mAP = 0.11216226, DetectionBoxes_Precision/mAP (large) = 0.024891393, DetectionBoxes_Precision/mAP (medium) = 0.35223886, DetectionBoxes_Precision/mAP (small) = 0.10823697, DetectionBoxes_Precision/mAP@.50IOU = 0.21828444, DetectionBoxes_Precision/mAP@.75IOU = 0.089089625, DetectionBoxes_Recall/AR@1 = 0.12083333, DetectionBoxes_Recall/AR@10 = 0.23301283, DetectionBoxes_Recall/AR@100 = 0.30673078, DetectionBoxes_Recall/AR@100 (large) = 0.33333334, DetectionBoxes_Recall/AR@100 (medium) = 0.5364865, DetectionBoxes_Recall/AR@100 (small) = 0.25329602, Loss/classification_loss = 7.963724, Loss/localization_loss = 1.2336031, Loss/regularization_loss = 0.3201472, Loss/total_loss = 9.517473, global_step = 7804, learning_rate = 0.004, loss = 9.517473\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7804: training/model.ckpt-7804\n",
            "I1130 09:33:22.070429 140184336205696 estimator.py:2109] Saving 'checkpoint_path' summary for global step 7804: training/model.ckpt-7804\n",
            "INFO:tensorflow:global_step/sec: 0.919407\n",
            "I1130 09:34:40.651204 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 0.919407\n",
            "INFO:tensorflow:loss = 3.9790633, step = 7900 (108.766 sec)\n",
            "I1130 09:34:40.652456 140184336205696 basic_session_run_hooks.py:260] loss = 3.9790633, step = 7900 (108.766 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23686\n",
            "I1130 09:36:01.500899 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23686\n",
            "INFO:tensorflow:loss = 4.9404154, step = 8000 (80.850 sec)\n",
            "I1130 09:36:01.502093 140184336205696 basic_session_run_hooks.py:260] loss = 4.9404154, step = 8000 (80.850 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23469\n",
            "I1130 09:37:22.493031 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23469\n",
            "INFO:tensorflow:loss = 4.409147, step = 8100 (80.992 sec)\n",
            "I1130 09:37:22.494210 140184336205696 basic_session_run_hooks.py:260] loss = 4.409147, step = 8100 (80.992 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23334\n",
            "I1130 09:38:43.573910 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23334\n",
            "INFO:tensorflow:loss = 2.9360507, step = 8200 (81.081 sec)\n",
            "I1130 09:38:43.575080 140184336205696 basic_session_run_hooks.py:260] loss = 2.9360507, step = 8200 (81.081 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23678\n",
            "I1130 09:40:04.429062 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23678\n",
            "INFO:tensorflow:loss = 2.8726, step = 8300 (80.855 sec)\n",
            "I1130 09:40:04.430392 140184336205696 basic_session_run_hooks.py:260] loss = 2.8726, step = 8300 (80.855 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23732\n",
            "I1130 09:41:25.248623 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23732\n",
            "INFO:tensorflow:loss = 4.6244802, step = 8400 (80.820 sec)\n",
            "I1130 09:41:25.250004 140184336205696 basic_session_run_hooks.py:260] loss = 4.6244802, step = 8400 (80.820 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23216\n",
            "I1130 09:42:46.407087 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23216\n",
            "INFO:tensorflow:loss = 3.5710647, step = 8500 (81.158 sec)\n",
            "I1130 09:42:46.408411 140184336205696 basic_session_run_hooks.py:260] loss = 3.5710647, step = 8500 (81.158 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 8511 into training/model.ckpt.\n",
            "I1130 09:42:54.531490 140184336205696 basic_session_run_hooks.py:606] Saving checkpoints for 8511 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 09:42:57.105372 140184336205696 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 09:42:57.106073 140184336205696 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1130 09:42:57.106256 140184336205696 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e45e99110>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W1130 09:42:57.173946 140184336205696 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e45e99110>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e48ca14d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1130 09:42:57.419271 140184336205696 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e48ca14d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1130 09:42:58.091855 140184336205696 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:43:00.622477 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:43:00.659492 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:43:00.695539 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:43:00.732062 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:43:00.773263 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:43:00.808470 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "I1130 09:43:03.863975 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "I1130 09:43:03.864341 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "I1130 09:43:03.864693 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "I1130 09:43:03.865045 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "I1130 09:43:03.865399 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "I1130 09:43:03.865643 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "I1130 09:43:03.866005 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "I1130 09:43:03.866249 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "I1130 09:43:03.866583 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "I1130 09:43:03.866838 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "I1130 09:43:03.867197 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "I1130 09:43:03.867461 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "I1130 09:43:03.867801 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "I1130 09:43:03.868060 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "I1130 09:43:03.868460 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "I1130 09:43:03.868730 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "I1130 09:43:03.869136 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "I1130 09:43:03.869382 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "I1130 09:43:03.869762 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "I1130 09:43:03.870105 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "I1130 09:43:03.870527 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "I1130 09:43:03.870821 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "I1130 09:43:03.871227 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "I1130 09:43:03.871495 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "I1130 09:43:03.871889 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "I1130 09:43:03.872233 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "I1130 09:43:03.872645 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "I1130 09:43:03.872993 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "I1130 09:43:03.873352 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "I1130 09:43:03.873595 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "I1130 09:43:03.873955 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "I1130 09:43:03.874196 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "I1130 09:43:03.874541 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "I1130 09:43:03.874784 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "I1130 09:43:03.875501 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "I1130 09:43:03.875782 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1130 09:43:03.876044 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "I1130 09:43:03.876326 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1130 09:43:03.876575 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "I1130 09:43:03.876816 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1130 09:43:03.877062 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "I1130 09:43:03.877319 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1130 09:43:03.877598 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1130 09:43:05.025152 140184336205696 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-11-30T09:43:05Z\n",
            "I1130 09:43:05.045544 140184336205696 evaluation.py:255] Starting evaluation at 2021-11-30T09:43:05Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1130 09:43:06.007959 140184336205696 monitored_session.py:240] Graph was finalized.\n",
            "2021-11-30 09:43:06.008832: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:43:06.009437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 09:43:06.009547: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 09:43:06.009614: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 09:43:06.009677: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 09:43:06.009736: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 09:43:06.009790: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 09:43:06.009840: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 09:43:06.009931: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 09:43:06.010040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:43:06.010520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:43:06.010938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 09:43:06.011028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-30 09:43:06.011055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-30 09:43:06.011072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-30 09:43:06.011208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:43:06.011694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:43:06.012127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-8511\n",
            "I1130 09:43:06.013656 140184336205696 saver.py:1284] Restoring parameters from training/model.ckpt-8511\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1130 09:43:07.734192 140184336205696 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1130 09:43:07.943119 140184336205696 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 147 images.\n",
            "I1130 09:43:20.752227 140181839787776 coco_evaluation.py:293] Performing evaluation on 147 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1130 09:43:20.753198 140181839787776 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I1130 09:43:20.766267 140181839787776 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.89s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.15s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.135\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.261\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.126\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.153\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.401\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.037\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.268\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.371\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.320\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.582\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.493\n",
            "INFO:tensorflow:Finished evaluation at 2021-11-30-09:43:21\n",
            "I1130 09:43:21.974434 140184336205696 evaluation.py:275] Finished evaluation at 2021-11-30-09:43:21\n",
            "INFO:tensorflow:Saving dict for global step 8511: DetectionBoxes_Precision/mAP = 0.13548227, DetectionBoxes_Precision/mAP (large) = 0.037129812, DetectionBoxes_Precision/mAP (medium) = 0.4007005, DetectionBoxes_Precision/mAP (small) = 0.15310034, DetectionBoxes_Precision/mAP@.50IOU = 0.26077315, DetectionBoxes_Precision/mAP@.75IOU = 0.12600817, DetectionBoxes_Recall/AR@1 = 0.15, DetectionBoxes_Recall/AR@10 = 0.26826924, DetectionBoxes_Recall/AR@100 = 0.3705128, DetectionBoxes_Recall/AR@100 (large) = 0.49333334, DetectionBoxes_Recall/AR@100 (medium) = 0.58243245, DetectionBoxes_Recall/AR@100 (small) = 0.31977612, Loss/classification_loss = 7.1821365, Loss/localization_loss = 1.0578842, Loss/regularization_loss = 0.32092026, Loss/total_loss = 8.56094, global_step = 8511, learning_rate = 0.004, loss = 8.56094\n",
            "I1130 09:43:21.974755 140184336205696 estimator.py:2049] Saving dict for global step 8511: DetectionBoxes_Precision/mAP = 0.13548227, DetectionBoxes_Precision/mAP (large) = 0.037129812, DetectionBoxes_Precision/mAP (medium) = 0.4007005, DetectionBoxes_Precision/mAP (small) = 0.15310034, DetectionBoxes_Precision/mAP@.50IOU = 0.26077315, DetectionBoxes_Precision/mAP@.75IOU = 0.12600817, DetectionBoxes_Recall/AR@1 = 0.15, DetectionBoxes_Recall/AR@10 = 0.26826924, DetectionBoxes_Recall/AR@100 = 0.3705128, DetectionBoxes_Recall/AR@100 (large) = 0.49333334, DetectionBoxes_Recall/AR@100 (medium) = 0.58243245, DetectionBoxes_Recall/AR@100 (small) = 0.31977612, Loss/classification_loss = 7.1821365, Loss/localization_loss = 1.0578842, Loss/regularization_loss = 0.32092026, Loss/total_loss = 8.56094, global_step = 8511, learning_rate = 0.004, loss = 8.56094\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8511: training/model.ckpt-8511\n",
            "I1130 09:43:21.976268 140184336205696 estimator.py:2109] Saving 'checkpoint_path' summary for global step 8511: training/model.ckpt-8511\n",
            "INFO:tensorflow:global_step/sec: 0.919582\n",
            "I1130 09:44:35.152085 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 0.919582\n",
            "INFO:tensorflow:loss = 3.028611, step = 8600 (108.745 sec)\n",
            "I1130 09:44:35.153377 140184336205696 basic_session_run_hooks.py:260] loss = 3.028611, step = 8600 (108.745 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23525\n",
            "I1130 09:45:56.107445 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23525\n",
            "INFO:tensorflow:loss = 3.3088844, step = 8700 (80.955 sec)\n",
            "I1130 09:45:56.108805 140184336205696 basic_session_run_hooks.py:260] loss = 3.3088844, step = 8700 (80.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23481\n",
            "I1130 09:47:17.091642 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23481\n",
            "INFO:tensorflow:loss = 2.8972738, step = 8800 (80.984 sec)\n",
            "I1130 09:47:17.092865 140184336205696 basic_session_run_hooks.py:260] loss = 2.8972738, step = 8800 (80.984 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24062\n",
            "I1130 09:48:37.696771 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24062\n",
            "INFO:tensorflow:loss = 3.7873316, step = 8900 (80.605 sec)\n",
            "I1130 09:48:37.698046 140184336205696 basic_session_run_hooks.py:260] loss = 3.7873316, step = 8900 (80.605 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25025\n",
            "I1130 09:49:57.680901 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.25025\n",
            "INFO:tensorflow:loss = 4.2612576, step = 9000 (79.984 sec)\n",
            "I1130 09:49:57.681970 140184336205696 basic_session_run_hooks.py:260] loss = 4.2612576, step = 9000 (79.984 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25106\n",
            "I1130 09:51:17.613260 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.25106\n",
            "INFO:tensorflow:loss = 2.9838505, step = 9100 (79.933 sec)\n",
            "I1130 09:51:17.614523 140184336205696 basic_session_run_hooks.py:260] loss = 2.9838505, step = 9100 (79.933 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25013\n",
            "I1130 09:52:37.604746 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.25013\n",
            "INFO:tensorflow:loss = 3.0918741, step = 9200 (79.999 sec)\n",
            "I1130 09:52:37.613290 140184336205696 basic_session_run_hooks.py:260] loss = 3.0918741, step = 9200 (79.999 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 9223 into training/model.ckpt.\n",
            "I1130 09:52:55.141151 140184336205696 basic_session_run_hooks.py:606] Saving checkpoints for 9223 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 09:52:57.650483 140184336205696 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 09:52:57.651294 140184336205696 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1130 09:52:57.651442 140184336205696 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e4215df90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W1130 09:52:57.715639 140184336205696 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e4215df90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e41d184d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1130 09:52:57.939029 140184336205696 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e41d184d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1130 09:52:58.590500 140184336205696 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:53:01.138891 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:53:01.174355 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:53:01.209311 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:53:01.245418 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:53:01.283201 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 09:53:01.319259 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "I1130 09:53:03.823385 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "I1130 09:53:03.823802 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "I1130 09:53:03.824168 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "I1130 09:53:03.824428 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "I1130 09:53:03.824734 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "I1130 09:53:03.824988 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "I1130 09:53:03.825302 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "I1130 09:53:03.825674 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "I1130 09:53:03.826070 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "I1130 09:53:03.826320 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "I1130 09:53:03.826599 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "I1130 09:53:03.826866 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "I1130 09:53:03.827298 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "I1130 09:53:03.827531 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "I1130 09:53:03.827851 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "I1130 09:53:03.828139 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "I1130 09:53:03.828504 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "I1130 09:53:03.828738 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "I1130 09:53:03.829079 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "I1130 09:53:03.829325 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "I1130 09:53:03.829637 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "I1130 09:53:03.829858 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "I1130 09:53:03.830163 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "I1130 09:53:03.830371 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "I1130 09:53:03.830655 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "I1130 09:53:03.830867 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "I1130 09:53:03.831179 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "I1130 09:53:03.831401 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "I1130 09:53:03.831816 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "I1130 09:53:03.832064 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "I1130 09:53:03.832450 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "I1130 09:53:03.832804 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "I1130 09:53:03.833323 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "I1130 09:53:03.833703 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "I1130 09:53:03.834278 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "I1130 09:53:03.834583 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1130 09:53:03.834854 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "I1130 09:53:03.835130 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1130 09:53:03.835369 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "I1130 09:53:03.835580 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1130 09:53:03.835790 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "I1130 09:53:03.836059 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1130 09:53:03.836328 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1130 09:53:04.956022 140184336205696 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-11-30T09:53:04Z\n",
            "I1130 09:53:04.976762 140184336205696 evaluation.py:255] Starting evaluation at 2021-11-30T09:53:04Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1130 09:53:06.394250 140184336205696 monitored_session.py:240] Graph was finalized.\n",
            "2021-11-30 09:53:06.395000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:53:06.395447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 09:53:06.395554: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 09:53:06.395610: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 09:53:06.395683: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 09:53:06.395735: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 09:53:06.395785: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 09:53:06.395839: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 09:53:06.395937: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 09:53:06.396052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:53:06.396444: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:53:06.396749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 09:53:06.396807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-30 09:53:06.396829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-30 09:53:06.396866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-30 09:53:06.397039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:53:06.397498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 09:53:06.397949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-9223\n",
            "I1130 09:53:06.399265 140184336205696 saver.py:1284] Restoring parameters from training/model.ckpt-9223\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1130 09:53:08.087574 140184336205696 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1130 09:53:08.270333 140184336205696 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 147 images.\n",
            "I1130 09:53:20.769249 140181839787776 coco_evaluation.py:293] Performing evaluation on 147 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1130 09:53:20.769875 140181839787776 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I1130 09:53:20.782163 140181839787776 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.74s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.13s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.267\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.576\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.214\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.243\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.513\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.035\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.301\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.397\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.416\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.363\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.618\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.693\n",
            "INFO:tensorflow:Finished evaluation at 2021-11-30-09:53:21\n",
            "I1130 09:53:21.807252 140184336205696 evaluation.py:275] Finished evaluation at 2021-11-30-09:53:21\n",
            "INFO:tensorflow:Saving dict for global step 9223: DetectionBoxes_Precision/mAP = 0.2666916, DetectionBoxes_Precision/mAP (large) = 0.034997705, DetectionBoxes_Precision/mAP (medium) = 0.51259434, DetectionBoxes_Precision/mAP (small) = 0.24332047, DetectionBoxes_Precision/mAP@.50IOU = 0.57640773, DetectionBoxes_Precision/mAP@.75IOU = 0.21368204, DetectionBoxes_Recall/AR@1 = 0.30128205, DetectionBoxes_Recall/AR@10 = 0.3974359, DetectionBoxes_Recall/AR@100 = 0.41634616, DetectionBoxes_Recall/AR@100 (large) = 0.6933333, DetectionBoxes_Recall/AR@100 (medium) = 0.61756754, DetectionBoxes_Recall/AR@100 (small) = 0.36256218, Loss/classification_loss = 5.0632896, Loss/localization_loss = 0.91947067, Loss/regularization_loss = 0.32169464, Loss/total_loss = 6.3044577, global_step = 9223, learning_rate = 0.004, loss = 6.3044577\n",
            "I1130 09:53:21.807566 140184336205696 estimator.py:2049] Saving dict for global step 9223: DetectionBoxes_Precision/mAP = 0.2666916, DetectionBoxes_Precision/mAP (large) = 0.034997705, DetectionBoxes_Precision/mAP (medium) = 0.51259434, DetectionBoxes_Precision/mAP (small) = 0.24332047, DetectionBoxes_Precision/mAP@.50IOU = 0.57640773, DetectionBoxes_Precision/mAP@.75IOU = 0.21368204, DetectionBoxes_Recall/AR@1 = 0.30128205, DetectionBoxes_Recall/AR@10 = 0.3974359, DetectionBoxes_Recall/AR@100 = 0.41634616, DetectionBoxes_Recall/AR@100 (large) = 0.6933333, DetectionBoxes_Recall/AR@100 (medium) = 0.61756754, DetectionBoxes_Recall/AR@100 (small) = 0.36256218, Loss/classification_loss = 5.0632896, Loss/localization_loss = 0.91947067, Loss/regularization_loss = 0.32169464, Loss/total_loss = 6.3044577, global_step = 9223, learning_rate = 0.004, loss = 6.3044577\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9223: training/model.ckpt-9223\n",
            "I1130 09:53:21.809192 140184336205696 estimator.py:2109] Saving 'checkpoint_path' summary for global step 9223: training/model.ckpt-9223\n",
            "INFO:tensorflow:global_step/sec: 0.937177\n",
            "I1130 09:54:24.308126 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 0.937177\n",
            "INFO:tensorflow:loss = 3.235441, step = 9300 (106.696 sec)\n",
            "I1130 09:54:24.309122 140184336205696 basic_session_run_hooks.py:260] loss = 3.235441, step = 9300 (106.696 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25025\n",
            "I1130 09:55:44.292087 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.25025\n",
            "INFO:tensorflow:loss = 3.0476825, step = 9400 (79.984 sec)\n",
            "I1130 09:55:44.293195 140184336205696 basic_session_run_hooks.py:260] loss = 3.0476825, step = 9400 (79.984 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.2512\n",
            "I1130 09:57:04.215528 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.2512\n",
            "INFO:tensorflow:loss = 2.3486745, step = 9500 (79.924 sec)\n",
            "I1130 09:57:04.216710 140184336205696 basic_session_run_hooks.py:260] loss = 2.3486745, step = 9500 (79.924 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25032\n",
            "I1130 09:58:24.194804 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.25032\n",
            "INFO:tensorflow:loss = 2.518425, step = 9600 (79.979 sec)\n",
            "I1130 09:58:24.195798 140184336205696 basic_session_run_hooks.py:260] loss = 2.518425, step = 9600 (79.979 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25732\n",
            "I1130 09:59:43.729038 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.25732\n",
            "INFO:tensorflow:loss = 2.931448, step = 9700 (79.535 sec)\n",
            "I1130 09:59:43.730707 140184336205696 basic_session_run_hooks.py:260] loss = 2.931448, step = 9700 (79.535 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25189\n",
            "I1130 10:01:03.607911 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.25189\n",
            "INFO:tensorflow:loss = 2.3971934, step = 9800 (79.878 sec)\n",
            "I1130 10:01:03.609106 140184336205696 basic_session_run_hooks.py:260] loss = 2.3971934, step = 9800 (79.878 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24351\n",
            "I1130 10:02:24.025444 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24351\n",
            "INFO:tensorflow:loss = 3.0185997, step = 9900 (80.418 sec)\n",
            "I1130 10:02:24.027039 140184336205696 basic_session_run_hooks.py:260] loss = 3.0185997, step = 9900 (80.418 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 9940 into training/model.ckpt.\n",
            "I1130 10:02:55.696824 140184336205696 basic_session_run_hooks.py:606] Saving checkpoints for 9940 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 10:02:58.383173 140184336205696 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 10:02:58.383975 140184336205696 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1130 10:02:58.384130 140184336205696 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7ea0246b90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W1130 10:02:58.450714 140184336205696 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7ea0246b90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e421e2cb0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1130 10:02:58.692817 140184336205696 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e421e2cb0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1130 10:02:59.400879 140184336205696 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:03:02.017910 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:03:02.055488 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:03:02.097680 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:03:02.133452 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:03:02.171140 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:03:02.207240 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "I1130 10:03:04.903445 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "I1130 10:03:04.903764 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "I1130 10:03:04.904187 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "I1130 10:03:04.904463 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "I1130 10:03:04.904865 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "I1130 10:03:04.905208 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "I1130 10:03:04.905591 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "I1130 10:03:04.905817 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "I1130 10:03:04.906225 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "I1130 10:03:04.906484 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "I1130 10:03:04.906833 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "I1130 10:03:04.907111 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "I1130 10:03:04.907450 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "I1130 10:03:04.907723 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "I1130 10:03:04.908070 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "I1130 10:03:04.908348 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "I1130 10:03:04.908759 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "I1130 10:03:04.909029 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "I1130 10:03:04.909349 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "I1130 10:03:04.909611 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "I1130 10:03:04.909987 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "I1130 10:03:04.910241 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "I1130 10:03:04.910643 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "I1130 10:03:04.910986 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "I1130 10:03:04.911373 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "I1130 10:03:04.911687 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "I1130 10:03:04.912067 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "I1130 10:03:04.912306 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "I1130 10:03:04.912646 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "I1130 10:03:04.912890 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "I1130 10:03:04.913230 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "I1130 10:03:04.913481 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "I1130 10:03:04.913810 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "I1130 10:03:04.914131 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "I1130 10:03:04.914461 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "I1130 10:03:04.914694 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1130 10:03:04.914967 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "I1130 10:03:04.915199 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1130 10:03:04.915440 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "I1130 10:03:04.915725 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1130 10:03:04.916008 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "I1130 10:03:04.916273 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1130 10:03:04.916534 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1130 10:03:06.172133 140184336205696 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-11-30T10:03:06Z\n",
            "I1130 10:03:06.201116 140184336205696 evaluation.py:255] Starting evaluation at 2021-11-30T10:03:06Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1130 10:03:07.232086 140184336205696 monitored_session.py:240] Graph was finalized.\n",
            "2021-11-30 10:03:07.232927: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:03:07.233397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 10:03:07.233495: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 10:03:07.233552: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 10:03:07.233617: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 10:03:07.233699: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 10:03:07.233766: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 10:03:07.233823: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 10:03:07.233885: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 10:03:07.234017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:03:07.234422: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:03:07.234843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 10:03:07.234966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-30 10:03:07.234995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-30 10:03:07.235014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-30 10:03:07.235206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:03:07.235614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:03:07.235994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-9940\n",
            "I1130 10:03:07.237075 140184336205696 saver.py:1284] Restoring parameters from training/model.ckpt-9940\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1130 10:03:08.847134 140184336205696 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1130 10:03:09.036063 140184336205696 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 147 images.\n",
            "I1130 10:03:21.903486 140181848180480 coco_evaluation.py:293] Performing evaluation on 147 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1130 10:03:21.904392 140181848180480 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.02s)\n",
            "I1130 10:03:21.919788 140181848180480 coco_tools.py:138] DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.86s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.14s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.298\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.623\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.261\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.234\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.594\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.623\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.328\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.446\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.397\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.688\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.740\n",
            "INFO:tensorflow:Finished evaluation at 2021-11-30-10:03:23\n",
            "I1130 10:03:23.083711 140184336205696 evaluation.py:275] Finished evaluation at 2021-11-30-10:03:23\n",
            "INFO:tensorflow:Saving dict for global step 9940: DetectionBoxes_Precision/mAP = 0.29820085, DetectionBoxes_Precision/mAP (large) = 0.6233585, DetectionBoxes_Precision/mAP (medium) = 0.5944411, DetectionBoxes_Precision/mAP (small) = 0.23391078, DetectionBoxes_Precision/mAP@.50IOU = 0.62285644, DetectionBoxes_Precision/mAP@.75IOU = 0.26129046, DetectionBoxes_Recall/AR@1 = 0.32820514, DetectionBoxes_Recall/AR@10 = 0.44551283, DetectionBoxes_Recall/AR@100 = 0.4548077, DetectionBoxes_Recall/AR@100 (large) = 0.74, DetectionBoxes_Recall/AR@100 (medium) = 0.68783784, DetectionBoxes_Recall/AR@100 (small) = 0.39701492, Loss/classification_loss = 4.2521777, Loss/localization_loss = 0.8073198, Loss/regularization_loss = 0.32240394, Loss/total_loss = 5.3819017, global_step = 9940, learning_rate = 0.004, loss = 5.3819017\n",
            "I1130 10:03:23.084112 140184336205696 estimator.py:2049] Saving dict for global step 9940: DetectionBoxes_Precision/mAP = 0.29820085, DetectionBoxes_Precision/mAP (large) = 0.6233585, DetectionBoxes_Precision/mAP (medium) = 0.5944411, DetectionBoxes_Precision/mAP (small) = 0.23391078, DetectionBoxes_Precision/mAP@.50IOU = 0.62285644, DetectionBoxes_Precision/mAP@.75IOU = 0.26129046, DetectionBoxes_Recall/AR@1 = 0.32820514, DetectionBoxes_Recall/AR@10 = 0.44551283, DetectionBoxes_Recall/AR@100 = 0.4548077, DetectionBoxes_Recall/AR@100 (large) = 0.74, DetectionBoxes_Recall/AR@100 (medium) = 0.68783784, DetectionBoxes_Recall/AR@100 (small) = 0.39701492, Loss/classification_loss = 4.2521777, Loss/localization_loss = 0.8073198, Loss/regularization_loss = 0.32240394, Loss/total_loss = 5.3819017, global_step = 9940, learning_rate = 0.004, loss = 5.3819017\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9940: training/model.ckpt-9940\n",
            "I1130 10:03:23.086276 140184336205696 estimator.py:2109] Saving 'checkpoint_path' summary for global step 9940: training/model.ckpt-9940\n",
            "INFO:tensorflow:global_step/sec: 0.921241\n",
            "I1130 10:04:12.574657 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 0.921241\n",
            "INFO:tensorflow:loss = 5.347387, step = 10000 (108.549 sec)\n",
            "I1130 10:04:12.575816 140184336205696 basic_session_run_hooks.py:260] loss = 5.347387, step = 10000 (108.549 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23507\n",
            "I1130 10:05:33.541914 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23507\n",
            "INFO:tensorflow:loss = 4.1782675, step = 10100 (80.967 sec)\n",
            "I1130 10:05:33.543251 140184336205696 basic_session_run_hooks.py:260] loss = 4.1782675, step = 10100 (80.967 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23313\n",
            "I1130 10:06:54.636213 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23313\n",
            "INFO:tensorflow:loss = 2.4442704, step = 10200 (81.094 sec)\n",
            "I1130 10:06:54.637372 140184336205696 basic_session_run_hooks.py:260] loss = 2.4442704, step = 10200 (81.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24065\n",
            "I1130 10:08:15.239339 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24065\n",
            "INFO:tensorflow:loss = 2.5852442, step = 10300 (80.603 sec)\n",
            "I1130 10:08:15.240591 140184336205696 basic_session_run_hooks.py:260] loss = 2.5852442, step = 10300 (80.603 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24798\n",
            "I1130 10:09:35.369129 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24798\n",
            "INFO:tensorflow:loss = 2.6080308, step = 10400 (80.130 sec)\n",
            "I1130 10:09:35.370425 140184336205696 basic_session_run_hooks.py:260] loss = 2.6080308, step = 10400 (80.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24429\n",
            "I1130 10:10:55.736213 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24429\n",
            "INFO:tensorflow:loss = 2.455172, step = 10500 (80.367 sec)\n",
            "I1130 10:10:55.737401 140184336205696 basic_session_run_hooks.py:260] loss = 2.455172, step = 10500 (80.367 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24076\n",
            "I1130 10:12:16.332105 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24076\n",
            "INFO:tensorflow:loss = 2.4589415, step = 10600 (80.596 sec)\n",
            "I1130 10:12:16.333601 140184336205696 basic_session_run_hooks.py:260] loss = 2.4589415, step = 10600 (80.596 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10650 into training/model.ckpt.\n",
            "I1130 10:12:55.989103 140184336205696 basic_session_run_hooks.py:606] Saving checkpoints for 10650 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 10:12:58.553812 140184336205696 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 10:12:58.554549 140184336205696 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1130 10:12:58.554713 140184336205696 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e46aa6f50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W1130 10:12:58.621721 140184336205696 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e46aa6f50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e46d6eef0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1130 10:12:58.853179 140184336205696 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e46d6eef0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1130 10:12:59.491376 140184336205696 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:13:02.713979 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:13:02.753342 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:13:02.793483 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:13:02.830399 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:13:02.868815 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:13:02.906060 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "I1130 10:13:05.607350 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "I1130 10:13:05.607768 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "I1130 10:13:05.608157 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "I1130 10:13:05.608476 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "I1130 10:13:05.608854 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "I1130 10:13:05.609163 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "I1130 10:13:05.609555 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "I1130 10:13:05.609836 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "I1130 10:13:05.610221 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "I1130 10:13:05.610503 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "I1130 10:13:05.610895 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "I1130 10:13:05.611184 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "I1130 10:13:05.611586 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "I1130 10:13:05.611865 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "I1130 10:13:05.612265 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "I1130 10:13:05.612556 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "I1130 10:13:05.612948 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "I1130 10:13:05.613238 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "I1130 10:13:05.613632 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "I1130 10:13:05.613939 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "I1130 10:13:05.614326 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "I1130 10:13:05.614636 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "I1130 10:13:05.615074 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "I1130 10:13:05.615366 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "I1130 10:13:05.615786 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "I1130 10:13:05.616074 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "I1130 10:13:05.616468 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "I1130 10:13:05.616763 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "I1130 10:13:05.617147 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "I1130 10:13:05.617435 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "I1130 10:13:05.617817 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "I1130 10:13:05.618128 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "I1130 10:13:05.618530 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "I1130 10:13:05.618811 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "I1130 10:13:05.619196 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "I1130 10:13:05.619477 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1130 10:13:05.619784 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "I1130 10:13:05.620084 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1130 10:13:05.620394 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "I1130 10:13:05.620661 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1130 10:13:05.620981 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "I1130 10:13:05.621243 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1130 10:13:05.621542 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1130 10:13:06.825453 140184336205696 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-11-30T10:13:06Z\n",
            "I1130 10:13:06.847635 140184336205696 evaluation.py:255] Starting evaluation at 2021-11-30T10:13:06Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1130 10:13:07.856169 140184336205696 monitored_session.py:240] Graph was finalized.\n",
            "2021-11-30 10:13:07.857066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:13:07.857530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 10:13:07.857646: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 10:13:07.857718: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 10:13:07.857786: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 10:13:07.857872: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 10:13:07.857959: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 10:13:07.858024: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 10:13:07.858085: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 10:13:07.858211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:13:07.858675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:13:07.859089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 10:13:07.859155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-30 10:13:07.859190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-30 10:13:07.859216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-30 10:13:07.859384: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:13:07.859906: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:13:07.860334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-10650\n",
            "I1130 10:13:07.861691 140184336205696 saver.py:1284] Restoring parameters from training/model.ckpt-10650\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1130 10:13:09.541870 140184336205696 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1130 10:13:09.756574 140184336205696 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 147 images.\n",
            "I1130 10:13:23.069776 140181848180480 coco_evaluation.py:293] Performing evaluation on 147 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1130 10:13:23.070549 140181848180480 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I1130 10:13:23.084064 140181848180480 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.79s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.13s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.429\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.755\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.401\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.351\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.678\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.792\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.418\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.512\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.514\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.726\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.820\n",
            "INFO:tensorflow:Finished evaluation at 2021-11-30-10:13:24\n",
            "I1130 10:13:24.167289 140184336205696 evaluation.py:275] Finished evaluation at 2021-11-30-10:13:24\n",
            "INFO:tensorflow:Saving dict for global step 10650: DetectionBoxes_Precision/mAP = 0.4293242, DetectionBoxes_Precision/mAP (large) = 0.79210544, DetectionBoxes_Precision/mAP (medium) = 0.67787313, DetectionBoxes_Precision/mAP (small) = 0.35125852, DetectionBoxes_Precision/mAP@.50IOU = 0.7549191, DetectionBoxes_Precision/mAP@.75IOU = 0.40135163, DetectionBoxes_Recall/AR@1 = 0.41794872, DetectionBoxes_Recall/AR@10 = 0.511859, DetectionBoxes_Recall/AR@100 = 0.5141026, DetectionBoxes_Recall/AR@100 (large) = 0.82, DetectionBoxes_Recall/AR@100 (medium) = 0.7256757, DetectionBoxes_Recall/AR@100 (small) = 0.45541045, Loss/classification_loss = 2.9003613, Loss/localization_loss = 0.6064069, Loss/regularization_loss = 0.3230286, Loss/total_loss = 3.829797, global_step = 10650, learning_rate = 0.004, loss = 3.829797\n",
            "I1130 10:13:24.167697 140184336205696 estimator.py:2049] Saving dict for global step 10650: DetectionBoxes_Precision/mAP = 0.4293242, DetectionBoxes_Precision/mAP (large) = 0.79210544, DetectionBoxes_Precision/mAP (medium) = 0.67787313, DetectionBoxes_Precision/mAP (small) = 0.35125852, DetectionBoxes_Precision/mAP@.50IOU = 0.7549191, DetectionBoxes_Precision/mAP@.75IOU = 0.40135163, DetectionBoxes_Recall/AR@1 = 0.41794872, DetectionBoxes_Recall/AR@10 = 0.511859, DetectionBoxes_Recall/AR@100 = 0.5141026, DetectionBoxes_Recall/AR@100 (large) = 0.82, DetectionBoxes_Recall/AR@100 (medium) = 0.7256757, DetectionBoxes_Recall/AR@100 (small) = 0.45541045, Loss/classification_loss = 2.9003613, Loss/localization_loss = 0.6064069, Loss/regularization_loss = 0.3230286, Loss/total_loss = 3.829797, global_step = 10650, learning_rate = 0.004, loss = 3.829797\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10650: training/model.ckpt-10650\n",
            "I1130 10:13:24.169137 140184336205696 estimator.py:2109] Saving 'checkpoint_path' summary for global step 10650: training/model.ckpt-10650\n",
            "INFO:tensorflow:global_step/sec: 0.916217\n",
            "I1130 10:14:05.476553 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 0.916217\n",
            "INFO:tensorflow:loss = 3.138958, step = 10700 (109.144 sec)\n",
            "I1130 10:14:05.477560 140184336205696 basic_session_run_hooks.py:260] loss = 3.138958, step = 10700 (109.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24305\n",
            "I1130 10:15:25.923954 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24305\n",
            "INFO:tensorflow:loss = 4.0639205, step = 10800 (80.448 sec)\n",
            "I1130 10:15:25.925373 140184336205696 basic_session_run_hooks.py:260] loss = 4.0639205, step = 10800 (80.448 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24349\n",
            "I1130 10:16:46.342565 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24349\n",
            "INFO:tensorflow:loss = 2.0039823, step = 10900 (80.419 sec)\n",
            "I1130 10:16:46.343906 140184336205696 basic_session_run_hooks.py:260] loss = 2.0039823, step = 10900 (80.419 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23806\n",
            "I1130 10:18:07.114160 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23806\n",
            "INFO:tensorflow:loss = 2.2747302, step = 11000 (80.771 sec)\n",
            "I1130 10:18:07.115386 140184336205696 basic_session_run_hooks.py:260] loss = 2.2747302, step = 11000 (80.771 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24519\n",
            "I1130 10:19:27.423210 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24519\n",
            "INFO:tensorflow:loss = 2.3442018, step = 11100 (80.309 sec)\n",
            "I1130 10:19:27.424607 140184336205696 basic_session_run_hooks.py:260] loss = 2.3442018, step = 11100 (80.309 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24719\n",
            "I1130 10:20:47.603646 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24719\n",
            "INFO:tensorflow:loss = 2.1802683, step = 11200 (80.180 sec)\n",
            "I1130 10:20:47.604671 140184336205696 basic_session_run_hooks.py:260] loss = 2.1802683, step = 11200 (80.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24355\n",
            "I1130 10:22:08.018728 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24355\n",
            "INFO:tensorflow:loss = 3.1777642, step = 11300 (80.415 sec)\n",
            "I1130 10:22:08.019967 140184336205696 basic_session_run_hooks.py:260] loss = 3.1777642, step = 11300 (80.415 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 11361 into training/model.ckpt.\n",
            "I1130 10:22:56.221627 140184336205696 basic_session_run_hooks.py:606] Saving checkpoints for 11361 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 10:22:58.903063 140184336205696 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 10:22:58.903812 140184336205696 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1130 10:22:58.903991 140184336205696 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e47062890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W1130 10:22:58.966982 140184336205696 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e47062890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e46915b00> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1130 10:22:59.199430 140184336205696 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e46915b00> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1130 10:22:59.893055 140184336205696 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:23:02.572570 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:23:02.610423 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:23:02.646678 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:23:02.684762 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:23:02.722858 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:23:02.759343 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "I1130 10:23:05.871793 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "I1130 10:23:05.872195 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "I1130 10:23:05.872568 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "I1130 10:23:05.872860 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "I1130 10:23:05.873245 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "I1130 10:23:05.873500 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "I1130 10:23:05.873843 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "I1130 10:23:05.874113 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "I1130 10:23:05.874454 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "I1130 10:23:05.874722 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "I1130 10:23:05.875108 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "I1130 10:23:05.875351 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "I1130 10:23:05.875682 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "I1130 10:23:05.875959 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "I1130 10:23:05.876284 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "I1130 10:23:05.876544 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "I1130 10:23:05.876892 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "I1130 10:23:05.877144 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "I1130 10:23:05.877471 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "I1130 10:23:05.877707 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "I1130 10:23:05.878069 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "I1130 10:23:05.878320 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "I1130 10:23:05.878641 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "I1130 10:23:05.878906 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "I1130 10:23:05.879308 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "I1130 10:23:05.879541 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "I1130 10:23:05.880002 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "I1130 10:23:05.880268 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "I1130 10:23:05.880588 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "I1130 10:23:05.880822 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "I1130 10:23:05.881216 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "I1130 10:23:05.881463 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "I1130 10:23:05.881819 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "I1130 10:23:05.882170 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "I1130 10:23:05.882524 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "I1130 10:23:05.882758 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1130 10:23:05.883028 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "I1130 10:23:05.883273 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1130 10:23:05.883517 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "I1130 10:23:05.883812 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1130 10:23:05.884187 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "I1130 10:23:05.884429 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1130 10:23:05.884675 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1130 10:23:07.149734 140184336205696 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-11-30T10:23:07Z\n",
            "I1130 10:23:07.171008 140184336205696 evaluation.py:255] Starting evaluation at 2021-11-30T10:23:07Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1130 10:23:08.178635 140184336205696 monitored_session.py:240] Graph was finalized.\n",
            "2021-11-30 10:23:08.179511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:23:08.180065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 10:23:08.180169: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 10:23:08.180234: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 10:23:08.180302: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 10:23:08.180365: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 10:23:08.180423: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 10:23:08.180478: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 10:23:08.180531: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 10:23:08.180639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:23:08.181298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:23:08.181665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 10:23:08.181780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-30 10:23:08.181806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-30 10:23:08.181822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-30 10:23:08.181979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:23:08.182381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:23:08.182760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-11361\n",
            "I1130 10:23:08.184135 140184336205696 saver.py:1284] Restoring parameters from training/model.ckpt-11361\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1130 10:23:09.989765 140184336205696 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1130 10:23:10.197814 140184336205696 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 147 images.\n",
            "I1130 10:23:23.370213 140181839787776 coco_evaluation.py:293] Performing evaluation on 147 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1130 10:23:23.371138 140181839787776 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I1130 10:23:23.384608 140181839787776 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.89s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.14s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.439\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.739\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.453\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.704\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.816\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.445\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.549\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.554\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.503\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.759\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.860\n",
            "INFO:tensorflow:Finished evaluation at 2021-11-30-10:23:24\n",
            "I1130 10:23:24.583245 140184336205696 evaluation.py:275] Finished evaluation at 2021-11-30-10:23:24\n",
            "INFO:tensorflow:Saving dict for global step 11361: DetectionBoxes_Precision/mAP = 0.43948486, DetectionBoxes_Precision/mAP (large) = 0.8164824, DetectionBoxes_Precision/mAP (medium) = 0.70389277, DetectionBoxes_Precision/mAP (small) = 0.35803446, DetectionBoxes_Precision/mAP@.50IOU = 0.7389955, DetectionBoxes_Precision/mAP@.75IOU = 0.4532819, DetectionBoxes_Recall/AR@1 = 0.44487178, DetectionBoxes_Recall/AR@10 = 0.54935896, DetectionBoxes_Recall/AR@100 = 0.5538462, DetectionBoxes_Recall/AR@100 (large) = 0.86, DetectionBoxes_Recall/AR@100 (medium) = 0.75945944, DetectionBoxes_Recall/AR@100 (small) = 0.5026741, Loss/classification_loss = 2.9819279, Loss/localization_loss = 0.5182493, Loss/regularization_loss = 0.3236888, Loss/total_loss = 3.8238678, global_step = 11361, learning_rate = 0.004, loss = 3.8238678\n",
            "I1130 10:23:24.583560 140184336205696 estimator.py:2049] Saving dict for global step 11361: DetectionBoxes_Precision/mAP = 0.43948486, DetectionBoxes_Precision/mAP (large) = 0.8164824, DetectionBoxes_Precision/mAP (medium) = 0.70389277, DetectionBoxes_Precision/mAP (small) = 0.35803446, DetectionBoxes_Precision/mAP@.50IOU = 0.7389955, DetectionBoxes_Precision/mAP@.75IOU = 0.4532819, DetectionBoxes_Recall/AR@1 = 0.44487178, DetectionBoxes_Recall/AR@10 = 0.54935896, DetectionBoxes_Recall/AR@100 = 0.5538462, DetectionBoxes_Recall/AR@100 (large) = 0.86, DetectionBoxes_Recall/AR@100 (medium) = 0.75945944, DetectionBoxes_Recall/AR@100 (small) = 0.5026741, Loss/classification_loss = 2.9819279, Loss/localization_loss = 0.5182493, Loss/regularization_loss = 0.3236888, Loss/total_loss = 3.8238678, global_step = 11361, learning_rate = 0.004, loss = 3.8238678\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 11361: training/model.ckpt-11361\n",
            "I1130 10:23:24.585153 140184336205696 estimator.py:2109] Saving 'checkpoint_path' summary for global step 11361: training/model.ckpt-11361\n",
            "INFO:tensorflow:global_step/sec: 0.917181\n",
            "I1130 10:23:57.048330 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 0.917181\n",
            "INFO:tensorflow:loss = 3.0579176, step = 11400 (109.029 sec)\n",
            "I1130 10:23:57.049397 140184336205696 basic_session_run_hooks.py:260] loss = 3.0579176, step = 11400 (109.029 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24242\n",
            "I1130 10:25:17.536214 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24242\n",
            "INFO:tensorflow:loss = 3.767693, step = 11500 (80.488 sec)\n",
            "I1130 10:25:17.537484 140184336205696 basic_session_run_hooks.py:260] loss = 3.767693, step = 11500 (80.488 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24262\n",
            "I1130 10:26:38.011371 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24262\n",
            "INFO:tensorflow:loss = 3.7135744, step = 11600 (80.475 sec)\n",
            "I1130 10:26:38.012459 140184336205696 basic_session_run_hooks.py:260] loss = 3.7135744, step = 11600 (80.475 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24727\n",
            "I1130 10:27:58.186723 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24727\n",
            "INFO:tensorflow:loss = 2.6216927, step = 11700 (80.176 sec)\n",
            "I1130 10:27:58.188125 140184336205696 basic_session_run_hooks.py:260] loss = 2.6216927, step = 11700 (80.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25118\n",
            "I1130 10:29:18.111150 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.25118\n",
            "INFO:tensorflow:loss = 3.6540709, step = 11800 (79.924 sec)\n",
            "I1130 10:29:18.112461 140184336205696 basic_session_run_hooks.py:260] loss = 3.6540709, step = 11800 (79.924 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25373\n",
            "I1130 10:30:37.872994 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.25373\n",
            "INFO:tensorflow:loss = 3.4426293, step = 11900 (79.765 sec)\n",
            "I1130 10:30:37.877337 140184336205696 basic_session_run_hooks.py:260] loss = 3.4426293, step = 11900 (79.765 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25808\n",
            "I1130 10:31:57.359464 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.25808\n",
            "INFO:tensorflow:loss = 3.6471238, step = 12000 (79.484 sec)\n",
            "I1130 10:31:57.360978 140184336205696 basic_session_run_hooks.py:260] loss = 3.6471238, step = 12000 (79.484 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 12076 into training/model.ckpt.\n",
            "I1130 10:32:56.965490 140184336205696 basic_session_run_hooks.py:606] Saving checkpoints for 12076 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 10:32:59.483584 140184336205696 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 10:32:59.484481 140184336205696 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1130 10:32:59.484697 140184336205696 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e48478890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W1130 10:32:59.546692 140184336205696 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e48478890>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7eaad24d40> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1130 10:32:59.777870 140184336205696 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7eaad24d40> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1130 10:33:00.436729 140184336205696 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:33:03.021615 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:33:03.056700 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:33:03.091759 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:33:03.126797 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:33:03.161832 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:33:03.194109 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "I1130 10:33:05.650998 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "I1130 10:33:05.651309 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "I1130 10:33:05.651663 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "I1130 10:33:05.651904 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "I1130 10:33:05.652202 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "I1130 10:33:05.652411 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "I1130 10:33:05.652739 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "I1130 10:33:05.652989 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "I1130 10:33:05.653284 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "I1130 10:33:05.653509 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "I1130 10:33:05.653800 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "I1130 10:33:05.654018 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "I1130 10:33:05.654350 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "I1130 10:33:05.654578 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "I1130 10:33:05.654886 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "I1130 10:33:05.655158 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "I1130 10:33:05.655459 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "I1130 10:33:05.655667 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "I1130 10:33:05.655988 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "I1130 10:33:05.656202 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "I1130 10:33:05.656494 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "I1130 10:33:05.656712 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "I1130 10:33:05.657039 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "I1130 10:33:05.657236 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "I1130 10:33:05.657523 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "I1130 10:33:05.657734 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "I1130 10:33:05.658037 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "I1130 10:33:05.658251 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "I1130 10:33:05.658592 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "I1130 10:33:05.658860 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "I1130 10:33:05.659182 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "I1130 10:33:05.659413 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "I1130 10:33:05.659773 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "I1130 10:33:05.660040 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "I1130 10:33:05.660318 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "I1130 10:33:05.660516 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1130 10:33:05.660739 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "I1130 10:33:05.660984 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1130 10:33:05.661205 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "I1130 10:33:05.661408 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1130 10:33:05.661627 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "I1130 10:33:05.661872 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1130 10:33:05.662141 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1130 10:33:06.789118 140184336205696 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-11-30T10:33:06Z\n",
            "I1130 10:33:06.810383 140184336205696 evaluation.py:255] Starting evaluation at 2021-11-30T10:33:06Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1130 10:33:07.750230 140184336205696 monitored_session.py:240] Graph was finalized.\n",
            "2021-11-30 10:33:07.751036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:33:07.751478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 10:33:07.751593: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 10:33:07.751672: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 10:33:07.751725: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 10:33:07.751786: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 10:33:07.751841: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 10:33:07.751921: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 10:33:07.752000: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 10:33:07.752109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:33:07.752535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:33:07.752850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 10:33:07.752917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-30 10:33:07.752959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-30 10:33:07.752980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-30 10:33:07.753110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:33:07.753559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:33:07.753928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-12076\n",
            "I1130 10:33:07.755315 140184336205696 saver.py:1284] Restoring parameters from training/model.ckpt-12076\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1130 10:33:09.278530 140184336205696 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1130 10:33:09.458977 140184336205696 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 147 images.\n",
            "I1130 10:33:21.886845 140181848180480 coco_evaluation.py:293] Performing evaluation on 147 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1130 10:33:21.887493 140181848180480 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I1130 10:33:21.895935 140181848180480 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.29s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.13s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.379\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.715\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.312\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.306\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.610\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.797\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.394\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.506\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.457\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.670\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.820\n",
            "INFO:tensorflow:Finished evaluation at 2021-11-30-10:33:23\n",
            "I1130 10:33:23.483859 140184336205696 evaluation.py:275] Finished evaluation at 2021-11-30-10:33:23\n",
            "INFO:tensorflow:Saving dict for global step 12076: DetectionBoxes_Precision/mAP = 0.3793999, DetectionBoxes_Precision/mAP (large) = 0.79708755, DetectionBoxes_Precision/mAP (medium) = 0.6102079, DetectionBoxes_Precision/mAP (small) = 0.30585566, DetectionBoxes_Precision/mAP@.50IOU = 0.71511346, DetectionBoxes_Precision/mAP@.75IOU = 0.3119367, DetectionBoxes_Recall/AR@1 = 0.39391026, DetectionBoxes_Recall/AR@10 = 0.49679488, DetectionBoxes_Recall/AR@100 = 0.50641024, DetectionBoxes_Recall/AR@100 (large) = 0.82, DetectionBoxes_Recall/AR@100 (medium) = 0.67027026, DetectionBoxes_Recall/AR@100 (small) = 0.45702738, Loss/classification_loss = 2.5745199, Loss/localization_loss = 0.6710299, Loss/regularization_loss = 0.32429114, Loss/total_loss = 3.56984, global_step = 12076, learning_rate = 0.004, loss = 3.56984\n",
            "I1130 10:33:23.484211 140184336205696 estimator.py:2049] Saving dict for global step 12076: DetectionBoxes_Precision/mAP = 0.3793999, DetectionBoxes_Precision/mAP (large) = 0.79708755, DetectionBoxes_Precision/mAP (medium) = 0.6102079, DetectionBoxes_Precision/mAP (small) = 0.30585566, DetectionBoxes_Precision/mAP@.50IOU = 0.71511346, DetectionBoxes_Precision/mAP@.75IOU = 0.3119367, DetectionBoxes_Recall/AR@1 = 0.39391026, DetectionBoxes_Recall/AR@10 = 0.49679488, DetectionBoxes_Recall/AR@100 = 0.50641024, DetectionBoxes_Recall/AR@100 (large) = 0.82, DetectionBoxes_Recall/AR@100 (medium) = 0.67027026, DetectionBoxes_Recall/AR@100 (small) = 0.45702738, Loss/classification_loss = 2.5745199, Loss/localization_loss = 0.6710299, Loss/regularization_loss = 0.32429114, Loss/total_loss = 3.56984, global_step = 12076, learning_rate = 0.004, loss = 3.56984\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12076: training/model.ckpt-12076\n",
            "I1130 10:33:23.485545 140184336205696 estimator.py:2109] Saving 'checkpoint_path' summary for global step 12076: training/model.ckpt-12076\n",
            "INFO:tensorflow:global_step/sec: 0.940539\n",
            "I1130 10:33:43.681403 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 0.940539\n",
            "INFO:tensorflow:loss = 2.6889837, step = 12100 (106.321 sec)\n",
            "I1130 10:33:43.682438 140184336205696 basic_session_run_hooks.py:260] loss = 2.6889837, step = 12100 (106.321 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25203\n",
            "I1130 10:35:03.552018 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.25203\n",
            "INFO:tensorflow:loss = 2.5998502, step = 12200 (79.871 sec)\n",
            "I1130 10:35:03.553449 140184336205696 basic_session_run_hooks.py:260] loss = 2.5998502, step = 12200 (79.871 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25362\n",
            "I1130 10:36:23.321225 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.25362\n",
            "INFO:tensorflow:loss = 3.8972487, step = 12300 (79.769 sec)\n",
            "I1130 10:36:23.322452 140184336205696 basic_session_run_hooks.py:260] loss = 3.8972487, step = 12300 (79.769 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24901\n",
            "I1130 10:37:43.384517 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24901\n",
            "INFO:tensorflow:loss = 3.4581258, step = 12400 (80.063 sec)\n",
            "I1130 10:37:43.385579 140184336205696 basic_session_run_hooks.py:260] loss = 3.4581258, step = 12400 (80.063 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24718\n",
            "I1130 10:39:03.565730 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24718\n",
            "INFO:tensorflow:loss = 2.6323514, step = 12500 (80.181 sec)\n",
            "I1130 10:39:03.567060 140184336205696 basic_session_run_hooks.py:260] loss = 2.6323514, step = 12500 (80.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25367\n",
            "I1130 10:40:23.331421 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.25367\n",
            "INFO:tensorflow:loss = 3.0719807, step = 12600 (79.766 sec)\n",
            "I1130 10:40:23.332837 140184336205696 basic_session_run_hooks.py:260] loss = 3.0719807, step = 12600 (79.766 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25397\n",
            "I1130 10:41:43.078273 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.25397\n",
            "INFO:tensorflow:loss = 2.3034995, step = 12700 (79.746 sec)\n",
            "I1130 10:41:43.079297 140184336205696 basic_session_run_hooks.py:260] loss = 2.3034995, step = 12700 (79.746 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 12794 into training/model.ckpt.\n",
            "I1130 10:42:57.305698 140184336205696 basic_session_run_hooks.py:606] Saving checkpoints for 12794 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 10:42:59.835671 140184336205696 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 10:42:59.836280 140184336205696 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1130 10:42:59.836423 140184336205696 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e45a11990>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W1130 10:42:59.894387 140184336205696 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e45a11990>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e468a4560> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1130 10:43:00.094132 140184336205696 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e468a4560> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1130 10:43:00.720053 140184336205696 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:43:03.296299 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:43:03.335141 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:43:03.369742 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:43:03.404448 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:43:03.440048 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:43:03.474834 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "I1130 10:43:06.073115 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "I1130 10:43:06.073520 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "I1130 10:43:06.073926 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "I1130 10:43:06.074181 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "I1130 10:43:06.074552 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "I1130 10:43:06.074813 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "I1130 10:43:06.075198 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "I1130 10:43:06.075469 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "I1130 10:43:06.075865 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "I1130 10:43:06.076160 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "I1130 10:43:06.076534 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "I1130 10:43:06.076848 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "I1130 10:43:06.077287 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "I1130 10:43:06.077569 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "I1130 10:43:06.077958 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "I1130 10:43:06.078204 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "I1130 10:43:06.078552 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "I1130 10:43:06.078807 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "I1130 10:43:06.079186 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "I1130 10:43:06.079483 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "I1130 10:43:06.079908 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "I1130 10:43:06.080169 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "I1130 10:43:06.080543 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "I1130 10:43:06.080802 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "I1130 10:43:06.081229 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "I1130 10:43:06.081483 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "I1130 10:43:06.081941 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "I1130 10:43:06.082279 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "I1130 10:43:06.082634 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "I1130 10:43:06.082933 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "I1130 10:43:06.083317 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "I1130 10:43:06.083601 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "I1130 10:43:06.083971 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "I1130 10:43:06.084216 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "I1130 10:43:06.084570 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "I1130 10:43:06.084806 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1130 10:43:06.085088 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "I1130 10:43:06.085350 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1130 10:43:06.085621 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "I1130 10:43:06.085910 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1130 10:43:06.086199 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "I1130 10:43:06.086467 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1130 10:43:06.086732 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1130 10:43:07.253656 140184336205696 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-11-30T10:43:07Z\n",
            "I1130 10:43:07.274453 140184336205696 evaluation.py:255] Starting evaluation at 2021-11-30T10:43:07Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1130 10:43:08.247454 140184336205696 monitored_session.py:240] Graph was finalized.\n",
            "2021-11-30 10:43:08.248262: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:43:08.248691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 10:43:08.248797: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 10:43:08.248856: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 10:43:08.248947: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 10:43:08.249008: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 10:43:08.249060: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 10:43:08.249115: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 10:43:08.249169: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 10:43:08.249290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:43:08.249694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:43:08.250056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 10:43:08.250159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-30 10:43:08.250182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-30 10:43:08.250197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-30 10:43:08.250319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:43:08.250740: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:43:08.251096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-12794\n",
            "I1130 10:43:08.252521 140184336205696 saver.py:1284] Restoring parameters from training/model.ckpt-12794\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1130 10:43:09.859230 140184336205696 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1130 10:43:10.036480 140184336205696 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 147 images.\n",
            "I1130 10:43:22.767838 140181839787776 coco_evaluation.py:293] Performing evaluation on 147 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1130 10:43:22.768712 140181839787776 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I1130 10:43:22.782950 140181839787776 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.83s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.13s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.412\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.771\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.431\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.321\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.732\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.857\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.407\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.491\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.505\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.433\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.778\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.873\n",
            "INFO:tensorflow:Finished evaluation at 2021-11-30-10:43:23\n",
            "I1130 10:43:23.895006 140184336205696 evaluation.py:275] Finished evaluation at 2021-11-30-10:43:23\n",
            "INFO:tensorflow:Saving dict for global step 12794: DetectionBoxes_Precision/mAP = 0.4123925, DetectionBoxes_Precision/mAP (large) = 0.8568741, DetectionBoxes_Precision/mAP (medium) = 0.7320511, DetectionBoxes_Precision/mAP (small) = 0.32091925, DetectionBoxes_Precision/mAP@.50IOU = 0.77076703, DetectionBoxes_Precision/mAP@.75IOU = 0.4307931, DetectionBoxes_Recall/AR@1 = 0.40673077, DetectionBoxes_Recall/AR@10 = 0.49134615, DetectionBoxes_Recall/AR@100 = 0.5051282, DetectionBoxes_Recall/AR@100 (large) = 0.87333333, DetectionBoxes_Recall/AR@100 (medium) = 0.77837837, DetectionBoxes_Recall/AR@100 (small) = 0.43264925, Loss/classification_loss = 2.5898848, Loss/localization_loss = 0.54966956, Loss/regularization_loss = 0.3249562, Loss/total_loss = 3.464511, global_step = 12794, learning_rate = 0.004, loss = 3.464511\n",
            "I1130 10:43:23.895334 140184336205696 estimator.py:2049] Saving dict for global step 12794: DetectionBoxes_Precision/mAP = 0.4123925, DetectionBoxes_Precision/mAP (large) = 0.8568741, DetectionBoxes_Precision/mAP (medium) = 0.7320511, DetectionBoxes_Precision/mAP (small) = 0.32091925, DetectionBoxes_Precision/mAP@.50IOU = 0.77076703, DetectionBoxes_Precision/mAP@.75IOU = 0.4307931, DetectionBoxes_Recall/AR@1 = 0.40673077, DetectionBoxes_Recall/AR@10 = 0.49134615, DetectionBoxes_Recall/AR@100 = 0.5051282, DetectionBoxes_Recall/AR@100 (large) = 0.87333333, DetectionBoxes_Recall/AR@100 (medium) = 0.77837837, DetectionBoxes_Recall/AR@100 (small) = 0.43264925, Loss/classification_loss = 2.5898848, Loss/localization_loss = 0.54966956, Loss/regularization_loss = 0.3249562, Loss/total_loss = 3.464511, global_step = 12794, learning_rate = 0.004, loss = 3.464511\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12794: training/model.ckpt-12794\n",
            "I1130 10:43:23.896770 140184336205696 estimator.py:2109] Saving 'checkpoint_path' summary for global step 12794: training/model.ckpt-12794\n",
            "INFO:tensorflow:global_step/sec: 0.938467\n",
            "I1130 10:43:29.635073 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 0.938467\n",
            "INFO:tensorflow:loss = 2.634194, step = 12800 (106.557 sec)\n",
            "I1130 10:43:29.635996 140184336205696 basic_session_run_hooks.py:260] loss = 2.634194, step = 12800 (106.557 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24531\n",
            "I1130 10:44:49.936596 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24531\n",
            "INFO:tensorflow:loss = 3.525814, step = 12900 (80.302 sec)\n",
            "I1130 10:44:49.937646 140184336205696 basic_session_run_hooks.py:260] loss = 3.525814, step = 12900 (80.302 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25291\n",
            "I1130 10:46:09.751040 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.25291\n",
            "INFO:tensorflow:loss = 2.6732278, step = 13000 (79.815 sec)\n",
            "I1130 10:46:09.752248 140184336205696 basic_session_run_hooks.py:260] loss = 2.6732278, step = 13000 (79.815 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24897\n",
            "I1130 10:47:29.816772 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24897\n",
            "INFO:tensorflow:loss = 3.0725455, step = 13100 (80.066 sec)\n",
            "I1130 10:47:29.818222 140184336205696 basic_session_run_hooks.py:260] loss = 3.0725455, step = 13100 (80.066 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25084\n",
            "I1130 10:48:49.763145 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.25084\n",
            "INFO:tensorflow:loss = 3.724968, step = 13200 (79.946 sec)\n",
            "I1130 10:48:49.764175 140184336205696 basic_session_run_hooks.py:260] loss = 3.724968, step = 13200 (79.946 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25192\n",
            "I1130 10:50:09.640518 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.25192\n",
            "INFO:tensorflow:loss = 2.6062896, step = 13300 (79.878 sec)\n",
            "I1130 10:50:09.641980 140184336205696 basic_session_run_hooks.py:260] loss = 2.6062896, step = 13300 (79.878 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25386\n",
            "I1130 10:51:29.394265 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.25386\n",
            "INFO:tensorflow:loss = 1.611147, step = 13400 (79.753 sec)\n",
            "I1130 10:51:29.395419 140184336205696 basic_session_run_hooks.py:260] loss = 1.611147, step = 13400 (79.753 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25403\n",
            "I1130 10:52:49.137148 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.25403\n",
            "INFO:tensorflow:loss = 2.2469866, step = 13500 (79.743 sec)\n",
            "I1130 10:52:49.138296 140184336205696 basic_session_run_hooks.py:260] loss = 2.2469866, step = 13500 (79.743 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 13512 into training/model.ckpt.\n",
            "I1130 10:52:57.913073 140184336205696 basic_session_run_hooks.py:606] Saving checkpoints for 13512 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 10:53:00.357298 140184336205696 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 10:53:00.358065 140184336205696 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1130 10:53:00.358212 140184336205696 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e4204f710>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W1130 10:53:00.418555 140184336205696 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e4204f710>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e420623b0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1130 10:53:00.621653 140184336205696 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e420623b0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1130 10:53:01.268539 140184336205696 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:53:03.824569 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:53:03.861129 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:53:03.896921 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:53:03.931593 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:53:03.966013 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 10:53:04.010650 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "I1130 10:53:07.097165 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "I1130 10:53:07.097528 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "I1130 10:53:07.097858 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "I1130 10:53:07.098098 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "I1130 10:53:07.098452 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "I1130 10:53:07.098708 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "I1130 10:53:07.099037 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "I1130 10:53:07.099291 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "I1130 10:53:07.099674 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "I1130 10:53:07.099902 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "I1130 10:53:07.100267 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "I1130 10:53:07.100521 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "I1130 10:53:07.100827 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "I1130 10:53:07.101062 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "I1130 10:53:07.101366 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "I1130 10:53:07.101598 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "I1130 10:53:07.101908 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "I1130 10:53:07.102149 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "I1130 10:53:07.102459 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "I1130 10:53:07.102668 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "I1130 10:53:07.103004 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "I1130 10:53:07.103278 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "I1130 10:53:07.103615 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "I1130 10:53:07.103885 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "I1130 10:53:07.104276 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "I1130 10:53:07.104519 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "I1130 10:53:07.104879 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "I1130 10:53:07.105125 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "I1130 10:53:07.105460 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "I1130 10:53:07.105705 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "I1130 10:53:07.106036 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "I1130 10:53:07.106250 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "I1130 10:53:07.106601 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "I1130 10:53:07.106839 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "I1130 10:53:07.107161 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "I1130 10:53:07.107388 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1130 10:53:07.107618 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "I1130 10:53:07.107855 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1130 10:53:07.108107 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "I1130 10:53:07.108336 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1130 10:53:07.108604 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "I1130 10:53:07.108862 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1130 10:53:07.109202 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1130 10:53:08.271787 140184336205696 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-11-30T10:53:08Z\n",
            "I1130 10:53:08.290748 140184336205696 evaluation.py:255] Starting evaluation at 2021-11-30T10:53:08Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1130 10:53:09.213755 140184336205696 monitored_session.py:240] Graph was finalized.\n",
            "2021-11-30 10:53:09.214492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:53:09.214924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 10:53:09.215045: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 10:53:09.215128: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 10:53:09.215182: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 10:53:09.215238: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 10:53:09.215321: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 10:53:09.215389: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 10:53:09.215439: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 10:53:09.215539: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:53:09.215978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:53:09.216331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 10:53:09.216395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-30 10:53:09.216421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-30 10:53:09.216437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-30 10:53:09.216584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:53:09.217061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 10:53:09.217429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-13512\n",
            "I1130 10:53:09.218554 140184336205696 saver.py:1284] Restoring parameters from training/model.ckpt-13512\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1130 10:53:10.839117 140184336205696 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1130 10:53:11.038908 140184336205696 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 147 images.\n",
            "I1130 10:53:23.683754 140181839787776 coco_evaluation.py:293] Performing evaluation on 147 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1130 10:53:23.684659 140181839787776 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I1130 10:53:23.692330 140181839787776 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.79s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.13s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.396\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.685\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.423\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.326\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.708\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.840\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.429\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.495\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.523\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.457\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.759\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.873\n",
            "INFO:tensorflow:Finished evaluation at 2021-11-30-10:53:24\n",
            "I1130 10:53:24.774863 140184336205696 evaluation.py:275] Finished evaluation at 2021-11-30-10:53:24\n",
            "INFO:tensorflow:Saving dict for global step 13512: DetectionBoxes_Precision/mAP = 0.39627028, DetectionBoxes_Precision/mAP (large) = 0.84020036, DetectionBoxes_Precision/mAP (medium) = 0.7078953, DetectionBoxes_Precision/mAP (small) = 0.32575488, DetectionBoxes_Precision/mAP@.50IOU = 0.68469316, DetectionBoxes_Precision/mAP@.75IOU = 0.4228321, DetectionBoxes_Recall/AR@1 = 0.42916667, DetectionBoxes_Recall/AR@10 = 0.4948718, DetectionBoxes_Recall/AR@100 = 0.52307695, DetectionBoxes_Recall/AR@100 (large) = 0.87333333, DetectionBoxes_Recall/AR@100 (medium) = 0.75945944, DetectionBoxes_Recall/AR@100 (small) = 0.45721394, Loss/classification_loss = 2.7650745, Loss/localization_loss = 0.55882066, Loss/regularization_loss = 0.3255081, Loss/total_loss = 3.649402, global_step = 13512, learning_rate = 0.004, loss = 3.649402\n",
            "I1130 10:53:24.775331 140184336205696 estimator.py:2049] Saving dict for global step 13512: DetectionBoxes_Precision/mAP = 0.39627028, DetectionBoxes_Precision/mAP (large) = 0.84020036, DetectionBoxes_Precision/mAP (medium) = 0.7078953, DetectionBoxes_Precision/mAP (small) = 0.32575488, DetectionBoxes_Precision/mAP@.50IOU = 0.68469316, DetectionBoxes_Precision/mAP@.75IOU = 0.4228321, DetectionBoxes_Recall/AR@1 = 0.42916667, DetectionBoxes_Recall/AR@10 = 0.4948718, DetectionBoxes_Recall/AR@100 = 0.52307695, DetectionBoxes_Recall/AR@100 (large) = 0.87333333, DetectionBoxes_Recall/AR@100 (medium) = 0.75945944, DetectionBoxes_Recall/AR@100 (small) = 0.45721394, Loss/classification_loss = 2.7650745, Loss/localization_loss = 0.55882066, Loss/regularization_loss = 0.3255081, Loss/total_loss = 3.649402, global_step = 13512, learning_rate = 0.004, loss = 3.649402\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 13512: training/model.ckpt-13512\n",
            "I1130 10:53:24.777136 140184336205696 estimator.py:2109] Saving 'checkpoint_path' summary for global step 13512: training/model.ckpt-13512\n",
            "INFO:tensorflow:global_step/sec: 0.937139\n",
            "I1130 10:54:35.844846 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 0.937139\n",
            "INFO:tensorflow:loss = 2.9301064, step = 13600 (106.708 sec)\n",
            "I1130 10:54:35.846025 140184336205696 basic_session_run_hooks.py:260] loss = 2.9301064, step = 13600 (106.708 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.2548\n",
            "I1130 10:55:55.538573 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.2548\n",
            "INFO:tensorflow:loss = 2.545623, step = 13700 (79.694 sec)\n",
            "I1130 10:55:55.539721 140184336205696 basic_session_run_hooks.py:260] loss = 2.545623, step = 13700 (79.694 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25691\n",
            "I1130 10:57:15.098978 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.25691\n",
            "INFO:tensorflow:loss = 3.601428, step = 13800 (79.561 sec)\n",
            "I1130 10:57:15.100294 140184336205696 basic_session_run_hooks.py:260] loss = 3.601428, step = 13800 (79.561 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25094\n",
            "I1130 10:58:35.039147 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.25094\n",
            "INFO:tensorflow:loss = 2.5698807, step = 13900 (79.940 sec)\n",
            "I1130 10:58:35.040507 140184336205696 basic_session_run_hooks.py:260] loss = 2.5698807, step = 13900 (79.940 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.25114\n",
            "I1130 10:59:54.966008 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.25114\n",
            "INFO:tensorflow:loss = 2.4866858, step = 14000 (79.927 sec)\n",
            "I1130 10:59:54.967259 140184336205696 basic_session_run_hooks.py:260] loss = 2.4866858, step = 14000 (79.927 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.2417\n",
            "I1130 11:01:15.501010 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.2417\n",
            "INFO:tensorflow:loss = 2.9646735, step = 14100 (80.535 sec)\n",
            "I1130 11:01:15.502097 140184336205696 basic_session_run_hooks.py:260] loss = 2.9646735, step = 14100 (80.535 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24723\n",
            "I1130 11:02:35.678941 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24723\n",
            "INFO:tensorflow:loss = 2.5525708, step = 14200 (80.178 sec)\n",
            "I1130 11:02:35.680581 140184336205696 basic_session_run_hooks.py:260] loss = 2.5525708, step = 14200 (80.178 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 14229 into training/model.ckpt.\n",
            "I1130 11:02:58.126029 140184336205696 basic_session_run_hooks.py:606] Saving checkpoints for 14229 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 11:03:00.751942 140184336205696 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 11:03:00.752991 140184336205696 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1130 11:03:00.753256 140184336205696 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e485fd5d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W1130 11:03:00.815547 140184336205696 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e485fd5d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e48e39b90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1130 11:03:01.047886 140184336205696 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e48e39b90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1130 11:03:01.752318 140184336205696 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:03:04.371431 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:03:04.422479 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:03:04.458167 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:03:04.494111 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:03:04.530709 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:03:04.583355 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "I1130 11:03:07.222183 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "I1130 11:03:07.222537 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "I1130 11:03:07.222896 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "I1130 11:03:07.223162 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "I1130 11:03:07.223470 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "I1130 11:03:07.223696 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "I1130 11:03:07.224076 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "I1130 11:03:07.224365 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "I1130 11:03:07.224732 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "I1130 11:03:07.225008 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "I1130 11:03:07.225366 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "I1130 11:03:07.225669 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "I1130 11:03:07.226019 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "I1130 11:03:07.226298 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "I1130 11:03:07.226600 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "I1130 11:03:07.226826 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "I1130 11:03:07.227203 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "I1130 11:03:07.227429 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "I1130 11:03:07.227771 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "I1130 11:03:07.228030 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "I1130 11:03:07.228344 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "I1130 11:03:07.228563 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "I1130 11:03:07.228869 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "I1130 11:03:07.229134 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "I1130 11:03:07.229460 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "I1130 11:03:07.229696 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "I1130 11:03:07.230045 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "I1130 11:03:07.230293 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "I1130 11:03:07.230644 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "I1130 11:03:07.230943 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "I1130 11:03:07.231311 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "I1130 11:03:07.231581 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "I1130 11:03:07.231940 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "I1130 11:03:07.232193 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "I1130 11:03:07.232502 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "I1130 11:03:07.232723 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1130 11:03:07.232987 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "I1130 11:03:07.233232 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1130 11:03:07.233496 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "I1130 11:03:07.233750 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1130 11:03:07.234009 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "I1130 11:03:07.234240 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1130 11:03:07.234474 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1130 11:03:08.439060 140184336205696 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-11-30T11:03:08Z\n",
            "I1130 11:03:08.461178 140184336205696 evaluation.py:255] Starting evaluation at 2021-11-30T11:03:08Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1130 11:03:09.493072 140184336205696 monitored_session.py:240] Graph was finalized.\n",
            "2021-11-30 11:03:09.493881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:03:09.494375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 11:03:09.494478: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 11:03:09.494532: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 11:03:09.494596: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 11:03:09.494664: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 11:03:09.494724: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 11:03:09.494792: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 11:03:09.494848: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 11:03:09.495008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:03:09.495440: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:03:09.495878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 11:03:09.495998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-30 11:03:09.496025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-30 11:03:09.496047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-30 11:03:09.496195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:03:09.496602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:03:09.496996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-14229\n",
            "I1130 11:03:09.498163 140184336205696 saver.py:1284] Restoring parameters from training/model.ckpt-14229\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1130 11:03:11.186707 140184336205696 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1130 11:03:11.369329 140184336205696 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 147 images.\n",
            "I1130 11:03:24.824219 140181848180480 coco_evaluation.py:293] Performing evaluation on 147 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1130 11:03:24.824980 140181848180480 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I1130 11:03:24.833452 140181848180480 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.87s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.14s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.442\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.786\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.500\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.372\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.707\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.836\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.427\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.518\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.529\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.481\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.754\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.867\n",
            "INFO:tensorflow:Finished evaluation at 2021-11-30-11:03:26\n",
            "I1130 11:03:26.018128 140184336205696 evaluation.py:275] Finished evaluation at 2021-11-30-11:03:26\n",
            "INFO:tensorflow:Saving dict for global step 14229: DetectionBoxes_Precision/mAP = 0.44184262, DetectionBoxes_Precision/mAP (large) = 0.8360001, DetectionBoxes_Precision/mAP (medium) = 0.7072398, DetectionBoxes_Precision/mAP (small) = 0.37209657, DetectionBoxes_Precision/mAP@.50IOU = 0.78570247, DetectionBoxes_Precision/mAP@.75IOU = 0.4996818, DetectionBoxes_Recall/AR@1 = 0.4272436, DetectionBoxes_Recall/AR@10 = 0.51826924, DetectionBoxes_Recall/AR@100 = 0.52916664, DetectionBoxes_Recall/AR@100 (large) = 0.8666667, DetectionBoxes_Recall/AR@100 (medium) = 0.75405407, DetectionBoxes_Recall/AR@100 (small) = 0.48065922, Loss/classification_loss = 2.3634202, Loss/localization_loss = 0.45528173, Loss/regularization_loss = 0.32604226, Loss/total_loss = 3.144746, global_step = 14229, learning_rate = 0.004, loss = 3.144746\n",
            "I1130 11:03:26.018433 140184336205696 estimator.py:2049] Saving dict for global step 14229: DetectionBoxes_Precision/mAP = 0.44184262, DetectionBoxes_Precision/mAP (large) = 0.8360001, DetectionBoxes_Precision/mAP (medium) = 0.7072398, DetectionBoxes_Precision/mAP (small) = 0.37209657, DetectionBoxes_Precision/mAP@.50IOU = 0.78570247, DetectionBoxes_Precision/mAP@.75IOU = 0.4996818, DetectionBoxes_Recall/AR@1 = 0.4272436, DetectionBoxes_Recall/AR@10 = 0.51826924, DetectionBoxes_Recall/AR@100 = 0.52916664, DetectionBoxes_Recall/AR@100 (large) = 0.8666667, DetectionBoxes_Recall/AR@100 (medium) = 0.75405407, DetectionBoxes_Recall/AR@100 (small) = 0.48065922, Loss/classification_loss = 2.3634202, Loss/localization_loss = 0.45528173, Loss/regularization_loss = 0.32604226, Loss/total_loss = 3.144746, global_step = 14229, learning_rate = 0.004, loss = 3.144746\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 14229: training/model.ckpt-14229\n",
            "I1130 11:03:26.020493 140184336205696 estimator.py:2109] Saving 'checkpoint_path' summary for global step 14229: training/model.ckpt-14229\n",
            "INFO:tensorflow:global_step/sec: 0.924903\n",
            "I1130 11:04:23.798333 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 0.924903\n",
            "INFO:tensorflow:loss = 2.7217891, step = 14300 (108.119 sec)\n",
            "I1130 11:04:23.799362 140184336205696 basic_session_run_hooks.py:260] loss = 2.7217891, step = 14300 (108.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24622\n",
            "I1130 11:05:44.041121 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24622\n",
            "INFO:tensorflow:loss = 2.9845476, step = 14400 (80.243 sec)\n",
            "I1130 11:05:44.042347 140184336205696 basic_session_run_hooks.py:260] loss = 2.9845476, step = 14400 (80.243 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24273\n",
            "I1130 11:07:04.508962 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24273\n",
            "INFO:tensorflow:loss = 3.4617116, step = 14500 (80.468 sec)\n",
            "I1130 11:07:04.510474 140184336205696 basic_session_run_hooks.py:260] loss = 3.4617116, step = 14500 (80.468 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24502\n",
            "I1130 11:08:24.828734 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24502\n",
            "INFO:tensorflow:loss = 2.1092334, step = 14600 (80.320 sec)\n",
            "I1130 11:08:24.830236 140184336205696 basic_session_run_hooks.py:260] loss = 2.1092334, step = 14600 (80.320 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24338\n",
            "I1130 11:09:45.254909 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24338\n",
            "INFO:tensorflow:loss = 2.2265618, step = 14700 (80.426 sec)\n",
            "I1130 11:09:45.256056 140184336205696 basic_session_run_hooks.py:260] loss = 2.2265618, step = 14700 (80.426 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24418\n",
            "I1130 11:11:05.629405 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24418\n",
            "INFO:tensorflow:loss = 2.1261854, step = 14800 (80.375 sec)\n",
            "I1130 11:11:05.630630 140184336205696 basic_session_run_hooks.py:260] loss = 2.1261854, step = 14800 (80.375 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24119\n",
            "I1130 11:12:26.197318 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24119\n",
            "INFO:tensorflow:loss = 2.7977173, step = 14900 (80.568 sec)\n",
            "I1130 11:12:26.198568 140184336205696 basic_session_run_hooks.py:260] loss = 2.7977173, step = 14900 (80.568 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 14941 into training/model.ckpt.\n",
            "I1130 11:12:58.384387 140184336205696 basic_session_run_hooks.py:606] Saving checkpoints for 14941 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 11:13:01.036951 140184336205696 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 11:13:01.037677 140184336205696 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1130 11:13:01.037826 140184336205696 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e4708ed90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W1130 11:13:01.098592 140184336205696 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e4708ed90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e484370e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1130 11:13:01.318863 140184336205696 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e484370e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1130 11:13:02.010508 140184336205696 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:13:04.643437 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:13:04.680850 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:13:04.716894 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:13:04.751960 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:13:04.788523 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:13:04.826259 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "I1130 11:13:07.445430 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "I1130 11:13:07.445805 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "I1130 11:13:07.446298 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "I1130 11:13:07.446578 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "I1130 11:13:07.446942 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "I1130 11:13:07.447214 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "I1130 11:13:07.447546 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "I1130 11:13:07.447857 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "I1130 11:13:07.448257 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "I1130 11:13:07.448498 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "I1130 11:13:07.448819 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "I1130 11:13:07.449069 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "I1130 11:13:07.449426 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "I1130 11:13:07.449710 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "I1130 11:13:07.450062 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "I1130 11:13:07.450316 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "I1130 11:13:07.450636 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "I1130 11:13:07.450869 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "I1130 11:13:07.451220 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "I1130 11:13:07.451456 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "I1130 11:13:07.451814 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "I1130 11:13:07.452070 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "I1130 11:13:07.452390 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "I1130 11:13:07.452620 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "I1130 11:13:07.452963 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "I1130 11:13:07.453246 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "I1130 11:13:07.453563 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "I1130 11:13:07.453795 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "I1130 11:13:07.454158 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "I1130 11:13:07.454385 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "I1130 11:13:07.454804 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "I1130 11:13:07.455084 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "I1130 11:13:07.455414 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "I1130 11:13:07.455668 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "I1130 11:13:07.456095 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "I1130 11:13:07.456349 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1130 11:13:07.456595 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "I1130 11:13:07.456834 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1130 11:13:07.457103 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "I1130 11:13:07.457349 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1130 11:13:07.457581 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "I1130 11:13:07.457814 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1130 11:13:07.458092 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1130 11:13:08.644307 140184336205696 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-11-30T11:13:08Z\n",
            "I1130 11:13:08.664151 140184336205696 evaluation.py:255] Starting evaluation at 2021-11-30T11:13:08Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1130 11:13:09.728792 140184336205696 monitored_session.py:240] Graph was finalized.\n",
            "2021-11-30 11:13:09.729669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:13:09.730207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 11:13:09.730364: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 11:13:09.730422: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 11:13:09.730482: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 11:13:09.730550: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 11:13:09.730605: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 11:13:09.730667: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 11:13:09.730721: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 11:13:09.730830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:13:09.731334: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:13:09.731689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 11:13:09.731749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-30 11:13:09.731774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-30 11:13:09.731793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-30 11:13:09.731954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:13:09.732376: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:13:09.732743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-14941\n",
            "I1130 11:13:09.733856 140184336205696 saver.py:1284] Restoring parameters from training/model.ckpt-14941\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1130 11:13:11.439313 140184336205696 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1130 11:13:11.644056 140184336205696 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 147 images.\n",
            "I1130 11:13:24.688502 140181839787776 coco_evaluation.py:293] Performing evaluation on 147 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1130 11:13:24.689456 140181839787776 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I1130 11:13:24.704132 140181839787776 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.89s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.14s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.778\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.505\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.378\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.725\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.911\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.472\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.573\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.576\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.513\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.769\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.927\n",
            "INFO:tensorflow:Finished evaluation at 2021-11-30-11:13:25\n",
            "I1130 11:13:25.902042 140184336205696 evaluation.py:275] Finished evaluation at 2021-11-30-11:13:25\n",
            "INFO:tensorflow:Saving dict for global step 14941: DetectionBoxes_Precision/mAP = 0.44800815, DetectionBoxes_Precision/mAP (large) = 0.9112235, DetectionBoxes_Precision/mAP (medium) = 0.72540116, DetectionBoxes_Precision/mAP (small) = 0.37813374, DetectionBoxes_Precision/mAP@.50IOU = 0.77757347, DetectionBoxes_Precision/mAP@.75IOU = 0.5051178, DetectionBoxes_Recall/AR@1 = 0.4724359, DetectionBoxes_Recall/AR@10 = 0.57339746, DetectionBoxes_Recall/AR@100 = 0.57564104, DetectionBoxes_Recall/AR@100 (large) = 0.9266667, DetectionBoxes_Recall/AR@100 (medium) = 0.76891893, DetectionBoxes_Recall/AR@100 (small) = 0.5130597, Loss/classification_loss = 2.1445844, Loss/localization_loss = 0.4325192, Loss/regularization_loss = 0.3265035, Loss/total_loss = 2.903607, global_step = 14941, learning_rate = 0.004, loss = 2.903607\n",
            "I1130 11:13:25.902393 140184336205696 estimator.py:2049] Saving dict for global step 14941: DetectionBoxes_Precision/mAP = 0.44800815, DetectionBoxes_Precision/mAP (large) = 0.9112235, DetectionBoxes_Precision/mAP (medium) = 0.72540116, DetectionBoxes_Precision/mAP (small) = 0.37813374, DetectionBoxes_Precision/mAP@.50IOU = 0.77757347, DetectionBoxes_Precision/mAP@.75IOU = 0.5051178, DetectionBoxes_Recall/AR@1 = 0.4724359, DetectionBoxes_Recall/AR@10 = 0.57339746, DetectionBoxes_Recall/AR@100 = 0.57564104, DetectionBoxes_Recall/AR@100 (large) = 0.9266667, DetectionBoxes_Recall/AR@100 (medium) = 0.76891893, DetectionBoxes_Recall/AR@100 (small) = 0.5130597, Loss/classification_loss = 2.1445844, Loss/localization_loss = 0.4325192, Loss/regularization_loss = 0.3265035, Loss/total_loss = 2.903607, global_step = 14941, learning_rate = 0.004, loss = 2.903607\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 14941: training/model.ckpt-14941\n",
            "I1130 11:13:25.903943 140184336205696 estimator.py:2109] Saving 'checkpoint_path' summary for global step 14941: training/model.ckpt-14941\n",
            "INFO:tensorflow:global_step/sec: 0.923496\n",
            "I1130 11:14:14.481517 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 0.923496\n",
            "INFO:tensorflow:loss = 2.9784381, step = 15000 (108.284 sec)\n",
            "I1130 11:14:14.482856 140184336205696 basic_session_run_hooks.py:260] loss = 2.9784381, step = 15000 (108.284 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24576\n",
            "I1130 11:15:34.754132 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24576\n",
            "INFO:tensorflow:loss = 3.190401, step = 15100 (80.273 sec)\n",
            "I1130 11:15:34.755437 140184336205696 basic_session_run_hooks.py:260] loss = 3.190401, step = 15100 (80.273 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24035\n",
            "I1130 11:16:55.376499 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24035\n",
            "INFO:tensorflow:loss = 2.3020883, step = 15200 (80.622 sec)\n",
            "I1130 11:16:55.377716 140184336205696 basic_session_run_hooks.py:260] loss = 2.3020883, step = 15200 (80.622 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24484\n",
            "I1130 11:18:15.708346 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24484\n",
            "INFO:tensorflow:loss = 3.3570905, step = 15300 (80.332 sec)\n",
            "I1130 11:18:15.709499 140184336205696 basic_session_run_hooks.py:260] loss = 3.3570905, step = 15300 (80.332 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24494\n",
            "I1130 11:19:36.033367 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24494\n",
            "INFO:tensorflow:loss = 2.7561443, step = 15400 (80.325 sec)\n",
            "I1130 11:19:36.034893 140184336205696 basic_session_run_hooks.py:260] loss = 2.7561443, step = 15400 (80.325 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24826\n",
            "I1130 11:20:56.144878 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24826\n",
            "INFO:tensorflow:loss = 2.9027429, step = 15500 (80.111 sec)\n",
            "I1130 11:20:56.146243 140184336205696 basic_session_run_hooks.py:260] loss = 2.9027429, step = 15500 (80.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24597\n",
            "I1130 11:22:16.403764 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24597\n",
            "INFO:tensorflow:loss = 2.245121, step = 15600 (80.259 sec)\n",
            "I1130 11:22:16.405270 140184336205696 basic_session_run_hooks.py:260] loss = 2.245121, step = 15600 (80.259 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 15654 into training/model.ckpt.\n",
            "I1130 11:22:58.870153 140184336205696 basic_session_run_hooks.py:606] Saving checkpoints for 15654 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 11:23:01.436482 140184336205696 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 11:23:01.437089 140184336205696 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1130 11:23:01.437248 140184336205696 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e46c04f50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W1130 11:23:01.501689 140184336205696 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e46c04f50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e46fa30e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1130 11:23:01.745968 140184336205696 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e46fa30e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1130 11:23:02.382157 140184336205696 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:23:04.977290 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:23:05.017071 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:23:05.056118 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:23:05.091041 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:23:05.127733 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:23:05.164200 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "I1130 11:23:08.396912 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "I1130 11:23:08.397298 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "I1130 11:23:08.397632 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "I1130 11:23:08.397876 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "I1130 11:23:08.398273 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "I1130 11:23:08.398509 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "I1130 11:23:08.398885 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "I1130 11:23:08.399161 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "I1130 11:23:08.399503 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "I1130 11:23:08.399764 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "I1130 11:23:08.400182 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "I1130 11:23:08.400416 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "I1130 11:23:08.400734 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "I1130 11:23:08.401038 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "I1130 11:23:08.401372 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "I1130 11:23:08.401607 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "I1130 11:23:08.401942 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "I1130 11:23:08.402208 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "I1130 11:23:08.402533 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "I1130 11:23:08.402760 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "I1130 11:23:08.403171 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "I1130 11:23:08.403402 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "I1130 11:23:08.403812 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "I1130 11:23:08.404107 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "I1130 11:23:08.404429 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "I1130 11:23:08.404667 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "I1130 11:23:08.405029 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "I1130 11:23:08.405270 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "I1130 11:23:08.405579 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "I1130 11:23:08.405804 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "I1130 11:23:08.406165 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "I1130 11:23:08.406424 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "I1130 11:23:08.406728 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "I1130 11:23:08.407017 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "I1130 11:23:08.407313 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "I1130 11:23:08.407532 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1130 11:23:08.407778 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "I1130 11:23:08.408049 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1130 11:23:08.408293 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "I1130 11:23:08.408524 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1130 11:23:08.408754 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "I1130 11:23:08.409007 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1130 11:23:08.409240 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1130 11:23:09.602069 140184336205696 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-11-30T11:23:09Z\n",
            "I1130 11:23:09.621342 140184336205696 evaluation.py:255] Starting evaluation at 2021-11-30T11:23:09Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1130 11:23:10.567306 140184336205696 monitored_session.py:240] Graph was finalized.\n",
            "2021-11-30 11:23:10.568222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:23:10.568695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 11:23:10.568828: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 11:23:10.568916: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 11:23:10.569030: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 11:23:10.569087: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 11:23:10.569143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 11:23:10.569203: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 11:23:10.569278: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 11:23:10.569387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:23:10.569819: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:23:10.570202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 11:23:10.570292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-30 11:23:10.570318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-30 11:23:10.570335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-30 11:23:10.570469: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:23:10.570922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:23:10.571388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-15654\n",
            "I1130 11:23:10.572742 140184336205696 saver.py:1284] Restoring parameters from training/model.ckpt-15654\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1130 11:23:12.249710 140184336205696 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1130 11:23:12.437548 140184336205696 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 147 images.\n",
            "I1130 11:23:25.355408 140181848180480 coco_evaluation.py:293] Performing evaluation on 147 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1130 11:23:25.356186 140181848180480 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I1130 11:23:25.367928 140181848180480 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.92s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.14s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.437\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.748\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.456\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.370\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.701\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.478\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.538\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.541\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.753\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.800\n",
            "INFO:tensorflow:Finished evaluation at 2021-11-30-11:23:26\n",
            "I1130 11:23:26.588082 140184336205696 evaluation.py:275] Finished evaluation at 2021-11-30-11:23:26\n",
            "INFO:tensorflow:Saving dict for global step 15654: DetectionBoxes_Precision/mAP = 0.43664998, DetectionBoxes_Precision/mAP (large) = 0.78819305, DetectionBoxes_Precision/mAP (medium) = 0.700859, DetectionBoxes_Precision/mAP (small) = 0.37044525, DetectionBoxes_Precision/mAP@.50IOU = 0.7475399, DetectionBoxes_Precision/mAP@.75IOU = 0.45551828, DetectionBoxes_Recall/AR@1 = 0.4775641, DetectionBoxes_Recall/AR@10 = 0.53846157, DetectionBoxes_Recall/AR@100 = 0.54102564, DetectionBoxes_Recall/AR@100 (large) = 0.8, DetectionBoxes_Recall/AR@100 (medium) = 0.7527027, DetectionBoxes_Recall/AR@100 (small) = 0.49987563, Loss/classification_loss = 2.275887, Loss/localization_loss = 0.45039457, Loss/regularization_loss = 0.32699195, Loss/total_loss = 3.0532732, global_step = 15654, learning_rate = 0.004, loss = 3.0532732\n",
            "I1130 11:23:26.588445 140184336205696 estimator.py:2049] Saving dict for global step 15654: DetectionBoxes_Precision/mAP = 0.43664998, DetectionBoxes_Precision/mAP (large) = 0.78819305, DetectionBoxes_Precision/mAP (medium) = 0.700859, DetectionBoxes_Precision/mAP (small) = 0.37044525, DetectionBoxes_Precision/mAP@.50IOU = 0.7475399, DetectionBoxes_Precision/mAP@.75IOU = 0.45551828, DetectionBoxes_Recall/AR@1 = 0.4775641, DetectionBoxes_Recall/AR@10 = 0.53846157, DetectionBoxes_Recall/AR@100 = 0.54102564, DetectionBoxes_Recall/AR@100 (large) = 0.8, DetectionBoxes_Recall/AR@100 (medium) = 0.7527027, DetectionBoxes_Recall/AR@100 (small) = 0.49987563, Loss/classification_loss = 2.275887, Loss/localization_loss = 0.45039457, Loss/regularization_loss = 0.32699195, Loss/total_loss = 3.0532732, global_step = 15654, learning_rate = 0.004, loss = 3.0532732\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 15654: training/model.ckpt-15654\n",
            "I1130 11:23:26.589986 140184336205696 estimator.py:2109] Saving 'checkpoint_path' summary for global step 15654: training/model.ckpt-15654\n",
            "INFO:tensorflow:global_step/sec: 0.926934\n",
            "I1130 11:24:04.286305 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 0.926934\n",
            "INFO:tensorflow:loss = 2.8521464, step = 15700 (107.882 sec)\n",
            "I1130 11:24:04.287501 140184336205696 basic_session_run_hooks.py:260] loss = 2.8521464, step = 15700 (107.882 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24568\n",
            "I1130 11:25:24.563857 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24568\n",
            "INFO:tensorflow:loss = 1.9138196, step = 15800 (80.278 sec)\n",
            "I1130 11:25:24.565362 140184336205696 basic_session_run_hooks.py:260] loss = 1.9138196, step = 15800 (80.278 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24654\n",
            "I1130 11:26:44.786122 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24654\n",
            "INFO:tensorflow:loss = 2.2558894, step = 15900 (80.222 sec)\n",
            "I1130 11:26:44.787353 140184336205696 basic_session_run_hooks.py:260] loss = 2.2558894, step = 15900 (80.222 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24952\n",
            "I1130 11:28:04.817016 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24952\n",
            "INFO:tensorflow:loss = 2.4145489, step = 16000 (80.031 sec)\n",
            "I1130 11:28:04.818294 140184336205696 basic_session_run_hooks.py:260] loss = 2.4145489, step = 16000 (80.031 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24806\n",
            "I1130 11:29:24.941386 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24806\n",
            "INFO:tensorflow:loss = 2.9507966, step = 16100 (80.124 sec)\n",
            "I1130 11:29:24.942726 140184336205696 basic_session_run_hooks.py:260] loss = 2.9507966, step = 16100 (80.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24721\n",
            "I1130 11:30:45.120166 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24721\n",
            "INFO:tensorflow:loss = 5.384229, step = 16200 (80.179 sec)\n",
            "I1130 11:30:45.121481 140184336205696 basic_session_run_hooks.py:260] loss = 5.384229, step = 16200 (80.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24835\n",
            "I1130 11:32:05.225884 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24835\n",
            "INFO:tensorflow:loss = 3.229395, step = 16300 (80.106 sec)\n",
            "I1130 11:32:05.227124 140184336205696 basic_session_run_hooks.py:260] loss = 3.229395, step = 16300 (80.106 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 16369 into training/model.ckpt.\n",
            "I1130 11:32:59.681000 140184336205696 basic_session_run_hooks.py:606] Saving checkpoints for 16369 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 11:33:02.343401 140184336205696 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 11:33:02.344140 140184336205696 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1130 11:33:02.344358 140184336205696 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e46a3d1d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W1130 11:33:02.405555 140184336205696 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e46a3d1d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e4856c5f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1130 11:33:02.623241 140184336205696 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e4856c5f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1130 11:33:03.296488 140184336205696 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:33:05.837746 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:33:05.876332 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:33:05.912184 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:33:05.949553 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:33:05.989443 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:33:06.024753 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "I1130 11:33:08.657838 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "I1130 11:33:08.658182 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "I1130 11:33:08.658502 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "I1130 11:33:08.658755 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "I1130 11:33:08.659137 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "I1130 11:33:08.659425 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "I1130 11:33:08.659782 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "I1130 11:33:08.660064 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "I1130 11:33:08.660472 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "I1130 11:33:08.660697 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "I1130 11:33:08.661043 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "I1130 11:33:08.661326 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "I1130 11:33:08.661741 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "I1130 11:33:08.661995 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "I1130 11:33:08.662334 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "I1130 11:33:08.662591 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "I1130 11:33:08.662902 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "I1130 11:33:08.663184 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "I1130 11:33:08.663537 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "I1130 11:33:08.663803 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "I1130 11:33:08.664226 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "I1130 11:33:08.664464 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "I1130 11:33:08.664792 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "I1130 11:33:08.665059 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "I1130 11:33:08.665428 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "I1130 11:33:08.665681 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "I1130 11:33:08.666017 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "I1130 11:33:08.666374 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "I1130 11:33:08.666776 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "I1130 11:33:08.667018 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "I1130 11:33:08.667428 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "I1130 11:33:08.667777 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "I1130 11:33:08.668329 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "I1130 11:33:08.668698 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "I1130 11:33:08.669395 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "I1130 11:33:08.669806 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1130 11:33:08.670204 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "I1130 11:33:08.670578 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1130 11:33:08.671001 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "I1130 11:33:08.671411 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1130 11:33:08.671779 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "I1130 11:33:08.672174 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1130 11:33:08.672536 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1130 11:33:09.844464 140184336205696 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-11-30T11:33:09Z\n",
            "I1130 11:33:09.866602 140184336205696 evaluation.py:255] Starting evaluation at 2021-11-30T11:33:09Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1130 11:33:10.906592 140184336205696 monitored_session.py:240] Graph was finalized.\n",
            "2021-11-30 11:33:10.907509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:33:10.908742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 11:33:10.908884: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 11:33:10.908992: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 11:33:10.909058: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 11:33:10.909116: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 11:33:10.909171: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 11:33:10.909242: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 11:33:10.909302: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 11:33:10.909412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:33:10.909833: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:33:10.910199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 11:33:10.910259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-30 11:33:10.910284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-30 11:33:10.910304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-30 11:33:10.910455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:33:10.910960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:33:10.911368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-16369\n",
            "I1130 11:33:10.918018 140184336205696 saver.py:1284] Restoring parameters from training/model.ckpt-16369\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1130 11:33:12.575100 140184336205696 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1130 11:33:12.770499 140184336205696 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 147 images.\n",
            "I1130 11:33:25.726609 140181839787776 coco_evaluation.py:293] Performing evaluation on 147 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1130 11:33:25.727304 140181839787776 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I1130 11:33:25.741119 140181839787776 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.90s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.14s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.490\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.812\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.548\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.418\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.718\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.837\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.462\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.575\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.576\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.776\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.853\n",
            "INFO:tensorflow:Finished evaluation at 2021-11-30-11:33:26\n",
            "I1130 11:33:26.959031 140184336205696 evaluation.py:275] Finished evaluation at 2021-11-30-11:33:26\n",
            "INFO:tensorflow:Saving dict for global step 16369: DetectionBoxes_Precision/mAP = 0.48985434, DetectionBoxes_Precision/mAP (large) = 0.83719474, DetectionBoxes_Precision/mAP (medium) = 0.7183866, DetectionBoxes_Precision/mAP (small) = 0.41793695, DetectionBoxes_Precision/mAP@.50IOU = 0.8116172, DetectionBoxes_Precision/mAP@.75IOU = 0.54764986, DetectionBoxes_Recall/AR@1 = 0.461859, DetectionBoxes_Recall/AR@10 = 0.57532054, DetectionBoxes_Recall/AR@100 = 0.57596153, DetectionBoxes_Recall/AR@100 (large) = 0.85333335, DetectionBoxes_Recall/AR@100 (medium) = 0.77567565, DetectionBoxes_Recall/AR@100 (small) = 0.52381843, Loss/classification_loss = 2.3487508, Loss/localization_loss = 0.42973068, Loss/regularization_loss = 0.32749462, Loss/total_loss = 3.1059763, global_step = 16369, learning_rate = 0.004, loss = 3.1059763\n",
            "I1130 11:33:26.959396 140184336205696 estimator.py:2049] Saving dict for global step 16369: DetectionBoxes_Precision/mAP = 0.48985434, DetectionBoxes_Precision/mAP (large) = 0.83719474, DetectionBoxes_Precision/mAP (medium) = 0.7183866, DetectionBoxes_Precision/mAP (small) = 0.41793695, DetectionBoxes_Precision/mAP@.50IOU = 0.8116172, DetectionBoxes_Precision/mAP@.75IOU = 0.54764986, DetectionBoxes_Recall/AR@1 = 0.461859, DetectionBoxes_Recall/AR@10 = 0.57532054, DetectionBoxes_Recall/AR@100 = 0.57596153, DetectionBoxes_Recall/AR@100 (large) = 0.85333335, DetectionBoxes_Recall/AR@100 (medium) = 0.77567565, DetectionBoxes_Recall/AR@100 (small) = 0.52381843, Loss/classification_loss = 2.3487508, Loss/localization_loss = 0.42973068, Loss/regularization_loss = 0.32749462, Loss/total_loss = 3.1059763, global_step = 16369, learning_rate = 0.004, loss = 3.1059763\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 16369: training/model.ckpt-16369\n",
            "I1130 11:33:26.960978 140184336205696 estimator.py:2109] Saving 'checkpoint_path' summary for global step 16369: training/model.ckpt-16369\n",
            "INFO:tensorflow:global_step/sec: 0.929316\n",
            "I1130 11:33:52.831939 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 0.929316\n",
            "INFO:tensorflow:loss = 2.3668678, step = 16400 (107.606 sec)\n",
            "I1130 11:33:52.833235 140184336205696 basic_session_run_hooks.py:260] loss = 2.3668678, step = 16400 (107.606 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24337\n",
            "I1130 11:35:13.258419 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24337\n",
            "INFO:tensorflow:loss = 2.369577, step = 16500 (80.427 sec)\n",
            "I1130 11:35:13.259955 140184336205696 basic_session_run_hooks.py:260] loss = 2.369577, step = 16500 (80.427 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24392\n",
            "I1130 11:36:33.649997 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24392\n",
            "INFO:tensorflow:loss = 2.847937, step = 16600 (80.393 sec)\n",
            "I1130 11:36:33.653138 140184336205696 basic_session_run_hooks.py:260] loss = 2.847937, step = 16600 (80.393 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24055\n",
            "I1130 11:37:54.259386 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24055\n",
            "INFO:tensorflow:loss = 2.1880436, step = 16700 (80.608 sec)\n",
            "I1130 11:37:54.260801 140184336205696 basic_session_run_hooks.py:260] loss = 2.1880436, step = 16700 (80.608 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24579\n",
            "I1130 11:39:14.529616 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24579\n",
            "INFO:tensorflow:loss = 2.6947265, step = 16800 (80.270 sec)\n",
            "I1130 11:39:14.530831 140184336205696 basic_session_run_hooks.py:260] loss = 2.6947265, step = 16800 (80.270 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24843\n",
            "I1130 11:40:34.630117 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24843\n",
            "INFO:tensorflow:loss = 3.3964553, step = 16900 (80.100 sec)\n",
            "I1130 11:40:34.631303 140184336205696 basic_session_run_hooks.py:260] loss = 3.3964553, step = 16900 (80.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24966\n",
            "I1130 11:41:54.651539 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24966\n",
            "INFO:tensorflow:loss = 2.404788, step = 17000 (80.021 sec)\n",
            "I1130 11:41:54.652798 140184336205696 basic_session_run_hooks.py:260] loss = 2.404788, step = 17000 (80.021 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 17083 into training/model.ckpt.\n",
            "I1130 11:43:00.424223 140184336205696 basic_session_run_hooks.py:606] Saving checkpoints for 17083 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 11:43:02.990717 140184336205696 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 11:43:02.991399 140184336205696 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1130 11:43:02.991538 140184336205696 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e4882af90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W1130 11:43:03.065225 140184336205696 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e4882af90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e48a01c20> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1130 11:43:03.838496 140184336205696 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e48a01c20> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1130 11:43:04.496131 140184336205696 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:43:07.112846 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:43:07.149094 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:43:07.183192 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:43:07.219113 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:43:07.256016 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:43:07.290827 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "I1130 11:43:09.830966 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "I1130 11:43:09.831329 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "I1130 11:43:09.831706 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "I1130 11:43:09.832001 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "I1130 11:43:09.832329 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "I1130 11:43:09.832568 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "I1130 11:43:09.832880 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "I1130 11:43:09.833130 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "I1130 11:43:09.833456 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "I1130 11:43:09.833719 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "I1130 11:43:09.834121 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "I1130 11:43:09.834366 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "I1130 11:43:09.834732 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "I1130 11:43:09.834977 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "I1130 11:43:09.835317 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "I1130 11:43:09.835551 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "I1130 11:43:09.835860 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "I1130 11:43:09.836095 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "I1130 11:43:09.836410 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "I1130 11:43:09.836633 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "I1130 11:43:09.836985 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "I1130 11:43:09.837280 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "I1130 11:43:09.837627 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "I1130 11:43:09.837847 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "I1130 11:43:09.838183 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "I1130 11:43:09.838453 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "I1130 11:43:09.838834 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "I1130 11:43:09.839106 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "I1130 11:43:09.839420 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "I1130 11:43:09.839682 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "I1130 11:43:09.840022 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "I1130 11:43:09.840259 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "I1130 11:43:09.840606 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "I1130 11:43:09.840859 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "I1130 11:43:09.841243 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "I1130 11:43:09.841480 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1130 11:43:09.841749 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "I1130 11:43:09.841996 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1130 11:43:09.842229 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "I1130 11:43:09.842464 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1130 11:43:09.842696 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "I1130 11:43:09.842949 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1130 11:43:09.843181 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1130 11:43:10.993592 140184336205696 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-11-30T11:43:11Z\n",
            "I1130 11:43:11.018171 140184336205696 evaluation.py:255] Starting evaluation at 2021-11-30T11:43:11Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1130 11:43:12.003735 140184336205696 monitored_session.py:240] Graph was finalized.\n",
            "2021-11-30 11:43:12.004675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:43:12.005254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 11:43:12.005387: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 11:43:12.005467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 11:43:12.005539: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 11:43:12.005610: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 11:43:12.005670: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 11:43:12.005735: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 11:43:12.005789: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 11:43:12.005894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:43:12.006331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:43:12.006680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 11:43:12.006770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-30 11:43:12.006795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-30 11:43:12.006821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-30 11:43:12.006993: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:43:12.007425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:43:12.007821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-17083\n",
            "I1130 11:43:12.009013 140184336205696 saver.py:1284] Restoring parameters from training/model.ckpt-17083\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1130 11:43:13.635857 140184336205696 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1130 11:43:13.834979 140184336205696 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 147 images.\n",
            "I1130 11:43:26.661406 140181839787776 coco_evaluation.py:293] Performing evaluation on 147 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1130 11:43:26.662150 140181839787776 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I1130 11:43:26.676204 140181839787776 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.82s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.13s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.407\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.731\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.423\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.330\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.714\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.852\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.412\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.498\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.444\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.749\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.873\n",
            "INFO:tensorflow:Finished evaluation at 2021-11-30-11:43:27\n",
            "I1130 11:43:27.783655 140184336205696 evaluation.py:275] Finished evaluation at 2021-11-30-11:43:27\n",
            "INFO:tensorflow:Saving dict for global step 17083: DetectionBoxes_Precision/mAP = 0.4067618, DetectionBoxes_Precision/mAP (large) = 0.851724, DetectionBoxes_Precision/mAP (medium) = 0.71371233, DetectionBoxes_Precision/mAP (small) = 0.33030626, DetectionBoxes_Precision/mAP@.50IOU = 0.7306266, DetectionBoxes_Precision/mAP@.75IOU = 0.42349, DetectionBoxes_Recall/AR@1 = 0.41153845, DetectionBoxes_Recall/AR@10 = 0.49711537, DetectionBoxes_Recall/AR@100 = 0.49807692, DetectionBoxes_Recall/AR@100 (large) = 0.87333333, DetectionBoxes_Recall/AR@100 (medium) = 0.74864864, DetectionBoxes_Recall/AR@100 (small) = 0.4437189, Loss/classification_loss = 2.5685787, Loss/localization_loss = 0.53283095, Loss/regularization_loss = 0.32797503, Loss/total_loss = 3.4293842, global_step = 17083, learning_rate = 0.004, loss = 3.4293842\n",
            "I1130 11:43:27.784031 140184336205696 estimator.py:2049] Saving dict for global step 17083: DetectionBoxes_Precision/mAP = 0.4067618, DetectionBoxes_Precision/mAP (large) = 0.851724, DetectionBoxes_Precision/mAP (medium) = 0.71371233, DetectionBoxes_Precision/mAP (small) = 0.33030626, DetectionBoxes_Precision/mAP@.50IOU = 0.7306266, DetectionBoxes_Precision/mAP@.75IOU = 0.42349, DetectionBoxes_Recall/AR@1 = 0.41153845, DetectionBoxes_Recall/AR@10 = 0.49711537, DetectionBoxes_Recall/AR@100 = 0.49807692, DetectionBoxes_Recall/AR@100 (large) = 0.87333333, DetectionBoxes_Recall/AR@100 (medium) = 0.74864864, DetectionBoxes_Recall/AR@100 (small) = 0.4437189, Loss/classification_loss = 2.5685787, Loss/localization_loss = 0.53283095, Loss/regularization_loss = 0.32797503, Loss/total_loss = 3.4293842, global_step = 17083, learning_rate = 0.004, loss = 3.4293842\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 17083: training/model.ckpt-17083\n",
            "I1130 11:43:27.785544 140184336205696 estimator.py:2109] Saving 'checkpoint_path' summary for global step 17083: training/model.ckpt-17083\n",
            "INFO:tensorflow:global_step/sec: 0.928035\n",
            "I1130 11:43:42.406041 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 0.928035\n",
            "INFO:tensorflow:loss = 2.4223995, step = 17100 (107.754 sec)\n",
            "I1130 11:43:42.407199 140184336205696 basic_session_run_hooks.py:260] loss = 2.4223995, step = 17100 (107.754 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24757\n",
            "I1130 11:45:02.562001 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24757\n",
            "INFO:tensorflow:loss = 3.2815995, step = 17200 (80.156 sec)\n",
            "I1130 11:45:02.563312 140184336205696 basic_session_run_hooks.py:260] loss = 3.2815995, step = 17200 (80.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24762\n",
            "I1130 11:46:22.714372 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24762\n",
            "INFO:tensorflow:loss = 1.8099613, step = 17300 (80.153 sec)\n",
            "I1130 11:46:22.715866 140184336205696 basic_session_run_hooks.py:260] loss = 1.8099613, step = 17300 (80.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24299\n",
            "I1130 11:47:43.165429 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24299\n",
            "INFO:tensorflow:loss = 2.9321432, step = 17400 (80.451 sec)\n",
            "I1130 11:47:43.166528 140184336205696 basic_session_run_hooks.py:260] loss = 2.9321432, step = 17400 (80.451 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24667\n",
            "I1130 11:49:03.379353 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24667\n",
            "INFO:tensorflow:loss = 4.2758083, step = 17500 (80.214 sec)\n",
            "I1130 11:49:03.380786 140184336205696 basic_session_run_hooks.py:260] loss = 4.2758083, step = 17500 (80.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24534\n",
            "I1130 11:50:23.678823 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24534\n",
            "INFO:tensorflow:loss = 2.1075096, step = 17600 (80.299 sec)\n",
            "I1130 11:50:23.680145 140184336205696 basic_session_run_hooks.py:260] loss = 2.1075096, step = 17600 (80.299 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24659\n",
            "I1130 11:51:43.897568 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24659\n",
            "INFO:tensorflow:loss = 3.1117566, step = 17700 (80.219 sec)\n",
            "I1130 11:51:43.898896 140184336205696 basic_session_run_hooks.py:260] loss = 3.1117566, step = 17700 (80.219 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 17797 into training/model.ckpt.\n",
            "I1130 11:53:00.509073 140184336205696 basic_session_run_hooks.py:606] Saving checkpoints for 17797 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 11:53:03.036463 140184336205696 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 11:53:03.037115 140184336205696 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1130 11:53:03.037259 140184336205696 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e46973490>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W1130 11:53:03.104115 140184336205696 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e46973490>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7ea00ffb90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1130 11:53:03.343533 140184336205696 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7ea00ffb90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1130 11:53:04.000059 140184336205696 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:53:06.614492 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:53:06.649908 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:53:06.684561 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:53:06.718518 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:53:06.753205 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 11:53:06.788614 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "I1130 11:53:09.770193 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "I1130 11:53:09.770566 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "I1130 11:53:09.770890 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "I1130 11:53:09.771134 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "I1130 11:53:09.771444 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "I1130 11:53:09.771671 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "I1130 11:53:09.772005 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "I1130 11:53:09.772243 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "I1130 11:53:09.772559 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "I1130 11:53:09.772819 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "I1130 11:53:09.773165 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "I1130 11:53:09.773406 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "I1130 11:53:09.773716 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "I1130 11:53:09.773974 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "I1130 11:53:09.774313 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "I1130 11:53:09.774552 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "I1130 11:53:09.774921 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "I1130 11:53:09.775167 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "I1130 11:53:09.775482 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "I1130 11:53:09.775689 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "I1130 11:53:09.776035 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "I1130 11:53:09.776275 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "I1130 11:53:09.776643 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "I1130 11:53:09.776892 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "I1130 11:53:09.777243 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "I1130 11:53:09.777456 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "I1130 11:53:09.777755 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "I1130 11:53:09.778034 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "I1130 11:53:09.778356 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "I1130 11:53:09.778566 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "I1130 11:53:09.778949 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "I1130 11:53:09.779212 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "I1130 11:53:09.779553 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "I1130 11:53:09.779810 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "I1130 11:53:09.780140 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "I1130 11:53:09.780373 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1130 11:53:09.780592 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "I1130 11:53:09.780809 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1130 11:53:09.781058 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "I1130 11:53:09.781290 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1130 11:53:09.781502 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "I1130 11:53:09.781739 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1130 11:53:09.782001 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1130 11:53:10.978236 140184336205696 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-11-30T11:53:10Z\n",
            "I1130 11:53:10.999260 140184336205696 evaluation.py:255] Starting evaluation at 2021-11-30T11:53:10Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1130 11:53:12.012400 140184336205696 monitored_session.py:240] Graph was finalized.\n",
            "2021-11-30 11:53:12.013642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:53:12.014254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 11:53:12.014350: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 11:53:12.014404: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 11:53:12.014460: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 11:53:12.014515: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 11:53:12.014567: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 11:53:12.014617: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 11:53:12.014668: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 11:53:12.014771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:53:12.015270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:53:12.015633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 11:53:12.015701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-30 11:53:12.015725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-30 11:53:12.015744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-30 11:53:12.015885: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:53:12.016314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 11:53:12.016685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-17797\n",
            "I1130 11:53:12.017770 140184336205696 saver.py:1284] Restoring parameters from training/model.ckpt-17797\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1130 11:53:13.675671 140184336205696 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1130 11:53:13.862081 140184336205696 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 147 images.\n",
            "I1130 11:53:26.816338 140181848180480 coco_evaluation.py:293] Performing evaluation on 147 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1130 11:53:26.816997 140181848180480 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I1130 11:53:26.831446 140181848180480 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.92s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.14s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.410\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.693\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.426\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.327\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.759\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.880\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.448\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.520\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.520\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.460\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.796\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.907\n",
            "INFO:tensorflow:Finished evaluation at 2021-11-30-11:53:28\n",
            "I1130 11:53:28.057256 140184336205696 evaluation.py:275] Finished evaluation at 2021-11-30-11:53:28\n",
            "INFO:tensorflow:Saving dict for global step 17797: DetectionBoxes_Precision/mAP = 0.40960267, DetectionBoxes_Precision/mAP (large) = 0.8797182, DetectionBoxes_Precision/mAP (medium) = 0.7590516, DetectionBoxes_Precision/mAP (small) = 0.3269125, DetectionBoxes_Precision/mAP@.50IOU = 0.6927802, DetectionBoxes_Precision/mAP@.75IOU = 0.4255476, DetectionBoxes_Recall/AR@1 = 0.44839743, DetectionBoxes_Recall/AR@10 = 0.5198718, DetectionBoxes_Recall/AR@100 = 0.5201923, DetectionBoxes_Recall/AR@100 (large) = 0.9066667, DetectionBoxes_Recall/AR@100 (medium) = 0.79594594, DetectionBoxes_Recall/AR@100 (small) = 0.45982587, Loss/classification_loss = 2.1516094, Loss/localization_loss = 0.42712313, Loss/regularization_loss = 0.3284032, Loss/total_loss = 2.9071352, global_step = 17797, learning_rate = 0.004, loss = 2.9071352\n",
            "I1130 11:53:28.057627 140184336205696 estimator.py:2049] Saving dict for global step 17797: DetectionBoxes_Precision/mAP = 0.40960267, DetectionBoxes_Precision/mAP (large) = 0.8797182, DetectionBoxes_Precision/mAP (medium) = 0.7590516, DetectionBoxes_Precision/mAP (small) = 0.3269125, DetectionBoxes_Precision/mAP@.50IOU = 0.6927802, DetectionBoxes_Precision/mAP@.75IOU = 0.4255476, DetectionBoxes_Recall/AR@1 = 0.44839743, DetectionBoxes_Recall/AR@10 = 0.5198718, DetectionBoxes_Recall/AR@100 = 0.5201923, DetectionBoxes_Recall/AR@100 (large) = 0.9066667, DetectionBoxes_Recall/AR@100 (medium) = 0.79594594, DetectionBoxes_Recall/AR@100 (small) = 0.45982587, Loss/classification_loss = 2.1516094, Loss/localization_loss = 0.42712313, Loss/regularization_loss = 0.3284032, Loss/total_loss = 2.9071352, global_step = 17797, learning_rate = 0.004, loss = 2.9071352\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 17797: training/model.ckpt-17797\n",
            "I1130 11:53:28.059364 140184336205696 estimator.py:2109] Saving 'checkpoint_path' summary for global step 17797: training/model.ckpt-17797\n",
            "INFO:tensorflow:global_step/sec: 0.929968\n",
            "I1130 11:53:31.428208 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 0.929968\n",
            "INFO:tensorflow:loss = 3.1421113, step = 17800 (107.531 sec)\n",
            "I1130 11:53:31.429552 140184336205696 basic_session_run_hooks.py:260] loss = 3.1421113, step = 17800 (107.531 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24757\n",
            "I1130 11:54:51.584216 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24757\n",
            "INFO:tensorflow:loss = 3.870585, step = 17900 (80.156 sec)\n",
            "I1130 11:54:51.585522 140184336205696 basic_session_run_hooks.py:260] loss = 3.870585, step = 17900 (80.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24731\n",
            "I1130 11:56:11.756720 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24731\n",
            "INFO:tensorflow:loss = 3.7362232, step = 18000 (80.172 sec)\n",
            "I1130 11:56:11.757865 140184336205696 basic_session_run_hooks.py:260] loss = 3.7362232, step = 18000 (80.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.2465\n",
            "I1130 11:57:31.981776 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.2465\n",
            "INFO:tensorflow:loss = 2.5248053, step = 18100 (80.225 sec)\n",
            "I1130 11:57:31.983284 140184336205696 basic_session_run_hooks.py:260] loss = 2.5248053, step = 18100 (80.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.2477\n",
            "I1130 11:58:52.128952 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.2477\n",
            "INFO:tensorflow:loss = 1.8942662, step = 18200 (80.147 sec)\n",
            "I1130 11:58:52.130020 140184336205696 basic_session_run_hooks.py:260] loss = 1.8942662, step = 18200 (80.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24658\n",
            "I1130 12:00:12.348519 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24658\n",
            "INFO:tensorflow:loss = 2.0545983, step = 18300 (80.220 sec)\n",
            "I1130 12:00:12.349965 140184336205696 basic_session_run_hooks.py:260] loss = 2.0545983, step = 18300 (80.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24569\n",
            "I1130 12:01:32.625270 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24569\n",
            "INFO:tensorflow:loss = 1.8755925, step = 18400 (80.277 sec)\n",
            "I1130 12:01:32.626644 140184336205696 basic_session_run_hooks.py:260] loss = 1.8755925, step = 18400 (80.277 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24254\n",
            "I1130 12:02:53.105442 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24254\n",
            "INFO:tensorflow:loss = 2.7919269, step = 18500 (80.480 sec)\n",
            "I1130 12:02:53.106822 140184336205696 basic_session_run_hooks.py:260] loss = 2.7919269, step = 18500 (80.480 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 18511 into training/model.ckpt.\n",
            "I1130 12:03:01.125718 140184336205696 basic_session_run_hooks.py:606] Saving checkpoints for 18511 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 12:03:03.703129 140184336205696 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 12:03:03.703800 140184336205696 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1130 12:03:03.703976 140184336205696 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e4841ff10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W1130 12:03:03.799113 140184336205696 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e4841ff10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e45e1ea70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1130 12:03:04.036163 140184336205696 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e45e1ea70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1130 12:03:04.713991 140184336205696 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:03:07.423639 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:03:07.460810 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:03:07.497685 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:03:07.534897 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:03:07.575174 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:03:07.613284 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "I1130 12:03:10.383251 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "I1130 12:03:10.383711 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "I1130 12:03:10.384128 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "I1130 12:03:10.384434 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "I1130 12:03:10.384810 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "I1130 12:03:10.385188 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "I1130 12:03:10.385601 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "I1130 12:03:10.385877 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "I1130 12:03:10.386271 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "I1130 12:03:10.386552 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "I1130 12:03:10.386953 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "I1130 12:03:10.387239 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "I1130 12:03:10.387637 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "I1130 12:03:10.387930 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "I1130 12:03:10.388294 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "I1130 12:03:10.388586 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "I1130 12:03:10.388975 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "I1130 12:03:10.389245 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "I1130 12:03:10.389631 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "I1130 12:03:10.389918 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "I1130 12:03:10.390323 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "I1130 12:03:10.390611 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "I1130 12:03:10.390996 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "I1130 12:03:10.391270 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "I1130 12:03:10.391653 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "I1130 12:03:10.391988 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "I1130 12:03:10.392397 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "I1130 12:03:10.392705 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "I1130 12:03:10.393121 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "I1130 12:03:10.393421 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "I1130 12:03:10.393806 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "I1130 12:03:10.394096 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "I1130 12:03:10.394505 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "I1130 12:03:10.394786 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "I1130 12:03:10.395192 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "I1130 12:03:10.395468 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1130 12:03:10.395747 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "I1130 12:03:10.396044 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1130 12:03:10.396315 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "I1130 12:03:10.396603 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1130 12:03:10.396862 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "I1130 12:03:10.397149 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1130 12:03:10.397428 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1130 12:03:11.670196 140184336205696 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-11-30T12:03:11Z\n",
            "I1130 12:03:11.691540 140184336205696 evaluation.py:255] Starting evaluation at 2021-11-30T12:03:11Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1130 12:03:13.116605 140184336205696 monitored_session.py:240] Graph was finalized.\n",
            "2021-11-30 12:03:13.117467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:03:13.118120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 12:03:13.118259: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 12:03:13.118357: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 12:03:13.118424: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 12:03:13.118486: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 12:03:13.118544: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 12:03:13.118598: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 12:03:13.118651: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 12:03:13.118769: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:03:13.119232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:03:13.119571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 12:03:13.119685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-30 12:03:13.119712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-30 12:03:13.119728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-30 12:03:13.119884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:03:13.120293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:03:13.120643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-18511\n",
            "I1130 12:03:13.121888 140184336205696 saver.py:1284] Restoring parameters from training/model.ckpt-18511\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1130 12:03:14.815460 140184336205696 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1130 12:03:15.010765 140184336205696 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 147 images.\n",
            "I1130 12:03:28.057771 140181839787776 coco_evaluation.py:293] Performing evaluation on 147 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1130 12:03:28.058711 140181839787776 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I1130 12:03:28.069156 140181839787776 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.91s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.14s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.481\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.840\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.558\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.416\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.792\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.471\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.572\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.577\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.795\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.813\n",
            "INFO:tensorflow:Finished evaluation at 2021-11-30-12:03:29\n",
            "I1130 12:03:29.298724 140184336205696 evaluation.py:275] Finished evaluation at 2021-11-30-12:03:29\n",
            "INFO:tensorflow:Saving dict for global step 18511: DetectionBoxes_Precision/mAP = 0.48130667, DetectionBoxes_Precision/mAP (large) = 0.7918092, DetectionBoxes_Precision/mAP (medium) = 0.7499697, DetectionBoxes_Precision/mAP (small) = 0.41610792, DetectionBoxes_Precision/mAP@.50IOU = 0.8396949, DetectionBoxes_Precision/mAP@.75IOU = 0.5577393, DetectionBoxes_Recall/AR@1 = 0.47083333, DetectionBoxes_Recall/AR@10 = 0.5724359, DetectionBoxes_Recall/AR@100 = 0.5766026, DetectionBoxes_Recall/AR@100 (large) = 0.81333333, DetectionBoxes_Recall/AR@100 (medium) = 0.7945946, DetectionBoxes_Recall/AR@100 (small) = 0.53041047, Loss/classification_loss = 2.0637183, Loss/localization_loss = 0.40459514, Loss/regularization_loss = 0.32886386, Loss/total_loss = 2.7971766, global_step = 18511, learning_rate = 0.004, loss = 2.7971766\n",
            "I1130 12:03:29.299097 140184336205696 estimator.py:2049] Saving dict for global step 18511: DetectionBoxes_Precision/mAP = 0.48130667, DetectionBoxes_Precision/mAP (large) = 0.7918092, DetectionBoxes_Precision/mAP (medium) = 0.7499697, DetectionBoxes_Precision/mAP (small) = 0.41610792, DetectionBoxes_Precision/mAP@.50IOU = 0.8396949, DetectionBoxes_Precision/mAP@.75IOU = 0.5577393, DetectionBoxes_Recall/AR@1 = 0.47083333, DetectionBoxes_Recall/AR@10 = 0.5724359, DetectionBoxes_Recall/AR@100 = 0.5766026, DetectionBoxes_Recall/AR@100 (large) = 0.81333333, DetectionBoxes_Recall/AR@100 (medium) = 0.7945946, DetectionBoxes_Recall/AR@100 (small) = 0.53041047, Loss/classification_loss = 2.0637183, Loss/localization_loss = 0.40459514, Loss/regularization_loss = 0.32886386, Loss/total_loss = 2.7971766, global_step = 18511, learning_rate = 0.004, loss = 2.7971766\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 18511: training/model.ckpt-18511\n",
            "I1130 12:03:29.300594 140184336205696 estimator.py:2109] Saving 'checkpoint_path' summary for global step 18511: training/model.ckpt-18511\n",
            "INFO:tensorflow:global_step/sec: 0.91947\n",
            "I1130 12:04:41.863734 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 0.91947\n",
            "INFO:tensorflow:loss = 3.509791, step = 18600 (108.758 sec)\n",
            "I1130 12:04:41.865175 140184336205696 basic_session_run_hooks.py:260] loss = 3.509791, step = 18600 (108.758 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24486\n",
            "I1130 12:06:02.193967 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24486\n",
            "INFO:tensorflow:loss = 3.2312634, step = 18700 (80.330 sec)\n",
            "I1130 12:06:02.195301 140184336205696 basic_session_run_hooks.py:260] loss = 3.2312634, step = 18700 (80.330 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.2456\n",
            "I1130 12:07:22.476532 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.2456\n",
            "INFO:tensorflow:loss = 2.6001031, step = 18800 (80.282 sec)\n",
            "I1130 12:07:22.477718 140184336205696 basic_session_run_hooks.py:260] loss = 2.6001031, step = 18800 (80.282 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24363\n",
            "I1130 12:08:42.886198 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24363\n",
            "INFO:tensorflow:loss = 2.1849833, step = 18900 (80.410 sec)\n",
            "I1130 12:08:42.887299 140184336205696 basic_session_run_hooks.py:260] loss = 2.1849833, step = 18900 (80.410 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.2464\n",
            "I1130 12:10:03.117012 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.2464\n",
            "INFO:tensorflow:loss = 2.8356037, step = 19000 (80.231 sec)\n",
            "I1130 12:10:03.118366 140184336205696 basic_session_run_hooks.py:260] loss = 2.8356037, step = 19000 (80.231 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24711\n",
            "I1130 12:11:23.302123 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24711\n",
            "INFO:tensorflow:loss = 2.8876972, step = 19100 (80.185 sec)\n",
            "I1130 12:11:23.303298 140184336205696 basic_session_run_hooks.py:260] loss = 2.8876972, step = 19100 (80.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24374\n",
            "I1130 12:12:43.704460 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24374\n",
            "INFO:tensorflow:loss = 2.4157104, step = 19200 (80.402 sec)\n",
            "I1130 12:12:43.705593 140184336205696 basic_session_run_hooks.py:260] loss = 2.4157104, step = 19200 (80.402 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 19223 into training/model.ckpt.\n",
            "I1130 12:13:01.386539 140184336205696 basic_session_run_hooks.py:606] Saving checkpoints for 19223 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 12:13:04.019060 140184336205696 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 12:13:04.019739 140184336205696 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1130 12:13:04.019956 140184336205696 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e45b03190>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W1130 12:13:04.085734 140184336205696 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e45b03190>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e46fa4440> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1130 12:13:04.325908 140184336205696 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e46fa4440> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1130 12:13:04.980232 140184336205696 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:13:07.592655 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:13:07.630248 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:13:07.669255 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:13:07.703449 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:13:07.739578 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:13:07.773366 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "I1130 12:13:10.517575 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "I1130 12:13:10.518061 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "I1130 12:13:10.518512 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "I1130 12:13:10.518812 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "I1130 12:13:10.519201 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "I1130 12:13:10.519490 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "I1130 12:13:10.519902 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "I1130 12:13:10.520190 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "I1130 12:13:10.520596 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "I1130 12:13:10.520900 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "I1130 12:13:10.521260 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "I1130 12:13:10.521522 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "I1130 12:13:10.521983 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "I1130 12:13:10.522496 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "I1130 12:13:10.522943 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "I1130 12:13:10.523270 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "I1130 12:13:10.523639 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "I1130 12:13:10.523925 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "I1130 12:13:10.524267 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "I1130 12:13:10.524523 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "I1130 12:13:10.524902 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "I1130 12:13:10.525196 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "I1130 12:13:10.525549 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "I1130 12:13:10.525807 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "I1130 12:13:10.526194 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "I1130 12:13:10.526473 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "I1130 12:13:10.526816 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "I1130 12:13:10.527130 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "I1130 12:13:10.527529 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "I1130 12:13:10.527812 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "I1130 12:13:10.528197 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "I1130 12:13:10.528467 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "I1130 12:13:10.528867 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "I1130 12:13:10.529166 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "I1130 12:13:10.529529 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "I1130 12:13:10.529792 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1130 12:13:10.530085 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "I1130 12:13:10.530347 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1130 12:13:10.530622 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "I1130 12:13:10.530914 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1130 12:13:10.531168 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "I1130 12:13:10.531464 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1130 12:13:10.531729 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1130 12:13:11.756852 140184336205696 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-11-30T12:13:11Z\n",
            "I1130 12:13:11.776628 140184336205696 evaluation.py:255] Starting evaluation at 2021-11-30T12:13:11Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1130 12:13:12.784616 140184336205696 monitored_session.py:240] Graph was finalized.\n",
            "2021-11-30 12:13:12.785445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:13:12.785980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 12:13:12.786083: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 12:13:12.786138: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 12:13:12.786205: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 12:13:12.786269: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 12:13:12.786319: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 12:13:12.786367: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 12:13:12.786515: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 12:13:12.786698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:13:12.787219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:13:12.787661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 12:13:12.787722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-30 12:13:12.787748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-30 12:13:12.787764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-30 12:13:12.787905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:13:12.788367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:13:12.788783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-19223\n",
            "I1130 12:13:12.789948 140184336205696 saver.py:1284] Restoring parameters from training/model.ckpt-19223\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1130 12:13:14.595646 140184336205696 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1130 12:13:14.827022 140184336205696 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 147 images.\n",
            "I1130 12:13:28.496597 140181839787776 coco_evaluation.py:293] Performing evaluation on 147 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1130 12:13:28.497243 140181839787776 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I1130 12:13:28.504871 140181839787776 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.90s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.14s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.449\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.850\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.455\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.378\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.721\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.724\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.461\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.537\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.537\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.488\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.758\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.753\n",
            "INFO:tensorflow:Finished evaluation at 2021-11-30-12:13:29\n",
            "I1130 12:13:29.734358 140184336205696 evaluation.py:275] Finished evaluation at 2021-11-30-12:13:29\n",
            "INFO:tensorflow:Saving dict for global step 19223: DetectionBoxes_Precision/mAP = 0.44945657, DetectionBoxes_Precision/mAP (large) = 0.72432816, DetectionBoxes_Precision/mAP (medium) = 0.72147113, DetectionBoxes_Precision/mAP (small) = 0.37817833, DetectionBoxes_Precision/mAP@.50IOU = 0.84972167, DetectionBoxes_Precision/mAP@.75IOU = 0.45517504, DetectionBoxes_Recall/AR@1 = 0.46089745, DetectionBoxes_Recall/AR@10 = 0.536859, DetectionBoxes_Recall/AR@100 = 0.53717947, DetectionBoxes_Recall/AR@100 (large) = 0.75333333, DetectionBoxes_Recall/AR@100 (medium) = 0.7581081, DetectionBoxes_Recall/AR@100 (small) = 0.48762438, Loss/classification_loss = 1.919928, Loss/localization_loss = 0.52078146, Loss/regularization_loss = 0.32928586, Loss/total_loss = 2.769995, global_step = 19223, learning_rate = 0.004, loss = 2.769995\n",
            "I1130 12:13:29.734687 140184336205696 estimator.py:2049] Saving dict for global step 19223: DetectionBoxes_Precision/mAP = 0.44945657, DetectionBoxes_Precision/mAP (large) = 0.72432816, DetectionBoxes_Precision/mAP (medium) = 0.72147113, DetectionBoxes_Precision/mAP (small) = 0.37817833, DetectionBoxes_Precision/mAP@.50IOU = 0.84972167, DetectionBoxes_Precision/mAP@.75IOU = 0.45517504, DetectionBoxes_Recall/AR@1 = 0.46089745, DetectionBoxes_Recall/AR@10 = 0.536859, DetectionBoxes_Recall/AR@100 = 0.53717947, DetectionBoxes_Recall/AR@100 (large) = 0.75333333, DetectionBoxes_Recall/AR@100 (medium) = 0.7581081, DetectionBoxes_Recall/AR@100 (small) = 0.48762438, Loss/classification_loss = 1.919928, Loss/localization_loss = 0.52078146, Loss/regularization_loss = 0.32928586, Loss/total_loss = 2.769995, global_step = 19223, learning_rate = 0.004, loss = 2.769995\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 19223: training/model.ckpt-19223\n",
            "I1130 12:13:29.735985 140184336205696 estimator.py:2109] Saving 'checkpoint_path' summary for global step 19223: training/model.ckpt-19223\n",
            "INFO:tensorflow:global_step/sec: 0.917779\n",
            "I1130 12:14:32.663177 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 0.917779\n",
            "INFO:tensorflow:loss = 1.8205106, step = 19300 (108.959 sec)\n",
            "I1130 12:14:32.664517 140184336205696 basic_session_run_hooks.py:260] loss = 1.8205106, step = 19300 (108.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24312\n",
            "I1130 12:15:53.106067 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24312\n",
            "INFO:tensorflow:loss = 2.9186058, step = 19400 (80.443 sec)\n",
            "I1130 12:15:53.107161 140184336205696 basic_session_run_hooks.py:260] loss = 2.9186058, step = 19400 (80.443 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.24146\n",
            "I1130 12:17:13.656602 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.24146\n",
            "INFO:tensorflow:loss = 1.9777188, step = 19500 (80.551 sec)\n",
            "I1130 12:17:13.657969 140184336205696 basic_session_run_hooks.py:260] loss = 1.9777188, step = 19500 (80.551 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.2387\n",
            "I1130 12:18:34.386538 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.2387\n",
            "INFO:tensorflow:loss = 2.425719, step = 19600 (80.730 sec)\n",
            "I1130 12:18:34.387875 140184336205696 basic_session_run_hooks.py:260] loss = 2.425719, step = 19600 (80.730 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23402\n",
            "I1130 12:19:55.422680 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23402\n",
            "INFO:tensorflow:loss = 3.3948061, step = 19700 (81.036 sec)\n",
            "I1130 12:19:55.424126 140184336205696 basic_session_run_hooks.py:260] loss = 3.3948061, step = 19700 (81.036 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.2393\n",
            "I1130 12:21:16.113622 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.2393\n",
            "INFO:tensorflow:loss = 2.50393, step = 19800 (80.691 sec)\n",
            "I1130 12:21:16.114788 140184336205696 basic_session_run_hooks.py:260] loss = 2.50393, step = 19800 (80.691 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.23632\n",
            "I1130 12:22:36.998884 140184336205696 basic_session_run_hooks.py:692] global_step/sec: 1.23632\n",
            "INFO:tensorflow:loss = 2.3780935, step = 19900 (80.886 sec)\n",
            "I1130 12:22:37.000443 140184336205696 basic_session_run_hooks.py:260] loss = 2.3780935, step = 19900 (80.886 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 19932 into training/model.ckpt.\n",
            "I1130 12:23:02.104379 140184336205696 basic_session_run_hooks.py:606] Saving checkpoints for 19932 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 12:23:04.831575 140184336205696 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 12:23:04.832549 140184336205696 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1130 12:23:04.832729 140184336205696 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e45d91650>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W1130 12:23:04.906271 140184336205696 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e45d91650>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e4676bf80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1130 12:23:05.152521 140184336205696 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e4676bf80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1130 12:23:05.833417 140184336205696 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:23:09.159821 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:23:09.197959 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:23:09.236854 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:23:09.274981 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:23:09.312843 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:23:09.349487 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "I1130 12:23:12.103337 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "I1130 12:23:12.103706 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "I1130 12:23:12.104173 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "I1130 12:23:12.104441 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "I1130 12:23:12.104855 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "I1130 12:23:12.105215 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "I1130 12:23:12.105604 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "I1130 12:23:12.105855 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "I1130 12:23:12.106261 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "I1130 12:23:12.106515 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "I1130 12:23:12.106878 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "I1130 12:23:12.107157 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "I1130 12:23:12.107517 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "I1130 12:23:12.107784 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "I1130 12:23:12.108148 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "I1130 12:23:12.108400 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "I1130 12:23:12.108753 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "I1130 12:23:12.109015 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "I1130 12:23:12.109353 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "I1130 12:23:12.109594 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "I1130 12:23:12.110004 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "I1130 12:23:12.110275 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "I1130 12:23:12.110611 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "I1130 12:23:12.110901 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "I1130 12:23:12.111308 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "I1130 12:23:12.111554 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "I1130 12:23:12.111936 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "I1130 12:23:12.112232 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "I1130 12:23:12.112572 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "I1130 12:23:12.112840 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "I1130 12:23:12.113206 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "I1130 12:23:12.113441 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "I1130 12:23:12.113817 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "I1130 12:23:12.114142 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "I1130 12:23:12.114509 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "I1130 12:23:12.114755 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1130 12:23:12.115085 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "I1130 12:23:12.115371 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1130 12:23:12.115629 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "I1130 12:23:12.115911 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1130 12:23:12.116172 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "I1130 12:23:12.116446 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1130 12:23:12.116692 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1130 12:23:13.346259 140184336205696 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-11-30T12:23:13Z\n",
            "I1130 12:23:13.367378 140184336205696 evaluation.py:255] Starting evaluation at 2021-11-30T12:23:13Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1130 12:23:14.371141 140184336205696 monitored_session.py:240] Graph was finalized.\n",
            "2021-11-30 12:23:14.372004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:23:14.372499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 12:23:14.372630: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 12:23:14.372701: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 12:23:14.372772: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 12:23:14.372836: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 12:23:14.372904: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 12:23:14.372977: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 12:23:14.373048: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 12:23:14.373158: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:23:14.373584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:23:14.373951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 12:23:14.374045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-30 12:23:14.374071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-30 12:23:14.374088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-30 12:23:14.374224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:23:14.374630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:23:14.375039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-19932\n",
            "I1130 12:23:14.376549 140184336205696 saver.py:1284] Restoring parameters from training/model.ckpt-19932\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1130 12:23:16.117273 140184336205696 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1130 12:23:16.325695 140184336205696 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 147 images.\n",
            "I1130 12:23:29.907458 140181848180480 coco_evaluation.py:293] Performing evaluation on 147 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1130 12:23:29.908532 140181848180480 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I1130 12:23:29.923209 140181848180480 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.97s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.15s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.509\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.887\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.538\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.434\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.776\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.815\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.521\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.588\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.589\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.534\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.815\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.853\n",
            "INFO:tensorflow:Finished evaluation at 2021-11-30-12:23:31\n",
            "I1130 12:23:31.239951 140184336205696 evaluation.py:275] Finished evaluation at 2021-11-30-12:23:31\n",
            "INFO:tensorflow:Saving dict for global step 19932: DetectionBoxes_Precision/mAP = 0.50920945, DetectionBoxes_Precision/mAP (large) = 0.8153237, DetectionBoxes_Precision/mAP (medium) = 0.7760072, DetectionBoxes_Precision/mAP (small) = 0.43358013, DetectionBoxes_Precision/mAP@.50IOU = 0.8868563, DetectionBoxes_Precision/mAP@.75IOU = 0.5379465, DetectionBoxes_Recall/AR@1 = 0.52115387, DetectionBoxes_Recall/AR@10 = 0.5884615, DetectionBoxes_Recall/AR@100 = 0.58942306, DetectionBoxes_Recall/AR@100 (large) = 0.85333335, DetectionBoxes_Recall/AR@100 (medium) = 0.8148649, DetectionBoxes_Recall/AR@100 (small) = 0.5335199, Loss/classification_loss = 1.819411, Loss/localization_loss = 0.4213725, Loss/regularization_loss = 0.32966876, Loss/total_loss = 2.5704517, global_step = 19932, learning_rate = 0.004, loss = 2.5704517\n",
            "I1130 12:23:31.240314 140184336205696 estimator.py:2049] Saving dict for global step 19932: DetectionBoxes_Precision/mAP = 0.50920945, DetectionBoxes_Precision/mAP (large) = 0.8153237, DetectionBoxes_Precision/mAP (medium) = 0.7760072, DetectionBoxes_Precision/mAP (small) = 0.43358013, DetectionBoxes_Precision/mAP@.50IOU = 0.8868563, DetectionBoxes_Precision/mAP@.75IOU = 0.5379465, DetectionBoxes_Recall/AR@1 = 0.52115387, DetectionBoxes_Recall/AR@10 = 0.5884615, DetectionBoxes_Recall/AR@100 = 0.58942306, DetectionBoxes_Recall/AR@100 (large) = 0.85333335, DetectionBoxes_Recall/AR@100 (medium) = 0.8148649, DetectionBoxes_Recall/AR@100 (small) = 0.5335199, Loss/classification_loss = 1.819411, Loss/localization_loss = 0.4213725, Loss/regularization_loss = 0.32966876, Loss/total_loss = 2.5704517, global_step = 19932, learning_rate = 0.004, loss = 2.5704517\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 19932: training/model.ckpt-19932\n",
            "I1130 12:23:31.241807 140184336205696 estimator.py:2109] Saving 'checkpoint_path' summary for global step 19932: training/model.ckpt-19932\n",
            "INFO:tensorflow:Saving checkpoints for 20000 into training/model.ckpt.\n",
            "I1130 12:24:26.459324 140184336205696 basic_session_run_hooks.py:606] Saving checkpoints for 20000 into training/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I1130 12:24:29.157522 140184336205696 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 12:24:29.181339 140184336205696 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "I1130 12:24:29.181967 140184336205696 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1130 12:24:29.182250 140184336205696 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e47709850>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W1130 12:24:29.248992 140184336205696 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f7e47709850>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e47bfdb00> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W1130 12:24:29.500412 140184336205696 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f7e47bfdb00> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1130 12:24:30.203910 140184336205696 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:24:32.990068 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:24:33.028760 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:24:33.066962 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:24:33.106382 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:24:33.145639 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:24:33.183257 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "I1130 12:24:36.355100 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "I1130 12:24:36.355480 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "I1130 12:24:36.355859 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "I1130 12:24:36.356140 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "I1130 12:24:36.356489 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "I1130 12:24:36.356755 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "I1130 12:24:36.357109 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "I1130 12:24:36.357358 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "I1130 12:24:36.357792 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "I1130 12:24:36.358131 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "I1130 12:24:36.358523 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "I1130 12:24:36.358775 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "I1130 12:24:36.359124 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "I1130 12:24:36.359381 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "I1130 12:24:36.359730 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "I1130 12:24:36.359994 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "I1130 12:24:36.360326 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "I1130 12:24:36.360675 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "I1130 12:24:36.361091 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "I1130 12:24:36.361373 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "I1130 12:24:36.361740 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "I1130 12:24:36.362007 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "I1130 12:24:36.362348 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "I1130 12:24:36.362604 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "I1130 12:24:36.362965 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "I1130 12:24:36.363210 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "I1130 12:24:36.363792 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "I1130 12:24:36.364279 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "I1130 12:24:36.364869 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "I1130 12:24:36.365291 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "I1130 12:24:36.365889 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "I1130 12:24:36.366248 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "I1130 12:24:36.366637 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "I1130 12:24:36.366900 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "I1130 12:24:36.367262 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "I1130 12:24:36.367516 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1130 12:24:36.367775 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "I1130 12:24:36.368034 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1130 12:24:36.368280 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "I1130 12:24:36.368524 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1130 12:24:36.368780 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "I1130 12:24:36.369041 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1130 12:24:36.369291 140184336205696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1130 12:24:37.666938 140184336205696 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-11-30T12:24:37Z\n",
            "I1130 12:24:37.689584 140184336205696 evaluation.py:255] Starting evaluation at 2021-11-30T12:24:37Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1130 12:24:38.689699 140184336205696 monitored_session.py:240] Graph was finalized.\n",
            "2021-11-30 12:24:38.690490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:24:38.690941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 12:24:38.691044: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 12:24:38.691116: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 12:24:38.691172: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 12:24:38.691276: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 12:24:38.691344: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 12:24:38.691424: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 12:24:38.691479: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 12:24:38.691595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:24:38.692166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:24:38.692647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 12:24:38.692718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-30 12:24:38.692756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-30 12:24:38.692785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-30 12:24:38.693003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:24:38.693544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:24:38.693966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-20000\n",
            "I1130 12:24:38.695208 140184336205696 saver.py:1284] Restoring parameters from training/model.ckpt-20000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1130 12:24:40.549995 140184336205696 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1130 12:24:40.776464 140184336205696 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 147 images.\n",
            "I1130 12:24:54.233889 140181839787776 coco_evaluation.py:293] Performing evaluation on 147 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1130 12:24:54.235715 140181839787776 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I1130 12:24:54.249572 140181839787776 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.91s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.15s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.482\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.848\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.482\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.416\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.735\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.821\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.475\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.537\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.538\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.495\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.774\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.833\n",
            "INFO:tensorflow:Finished evaluation at 2021-11-30-12:24:55\n",
            "I1130 12:24:55.476804 140184336205696 evaluation.py:275] Finished evaluation at 2021-11-30-12:24:55\n",
            "INFO:tensorflow:Saving dict for global step 20000: DetectionBoxes_Precision/mAP = 0.48222822, DetectionBoxes_Precision/mAP (large) = 0.82066005, DetectionBoxes_Precision/mAP (medium) = 0.73456234, DetectionBoxes_Precision/mAP (small) = 0.41625243, DetectionBoxes_Precision/mAP@.50IOU = 0.8478663, DetectionBoxes_Precision/mAP@.75IOU = 0.4822032, DetectionBoxes_Recall/AR@1 = 0.47532052, DetectionBoxes_Recall/AR@10 = 0.5365385, DetectionBoxes_Recall/AR@100 = 0.53846157, DetectionBoxes_Recall/AR@100 (large) = 0.8333333, DetectionBoxes_Recall/AR@100 (medium) = 0.7743243, DetectionBoxes_Recall/AR@100 (small) = 0.4948383, Loss/classification_loss = 1.9190075, Loss/localization_loss = 0.47261462, Loss/regularization_loss = 0.32970333, Loss/total_loss = 2.7213259, global_step = 20000, learning_rate = 0.004, loss = 2.7213259\n",
            "I1130 12:24:55.477205 140184336205696 estimator.py:2049] Saving dict for global step 20000: DetectionBoxes_Precision/mAP = 0.48222822, DetectionBoxes_Precision/mAP (large) = 0.82066005, DetectionBoxes_Precision/mAP (medium) = 0.73456234, DetectionBoxes_Precision/mAP (small) = 0.41625243, DetectionBoxes_Precision/mAP@.50IOU = 0.8478663, DetectionBoxes_Precision/mAP@.75IOU = 0.4822032, DetectionBoxes_Recall/AR@1 = 0.47532052, DetectionBoxes_Recall/AR@10 = 0.5365385, DetectionBoxes_Recall/AR@100 = 0.53846157, DetectionBoxes_Recall/AR@100 (large) = 0.8333333, DetectionBoxes_Recall/AR@100 (medium) = 0.7743243, DetectionBoxes_Recall/AR@100 (small) = 0.4948383, Loss/classification_loss = 1.9190075, Loss/localization_loss = 0.47261462, Loss/regularization_loss = 0.32970333, Loss/total_loss = 2.7213259, global_step = 20000, learning_rate = 0.004, loss = 2.7213259\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: training/model.ckpt-20000\n",
            "I1130 12:24:55.478906 140184336205696 estimator.py:2109] Saving 'checkpoint_path' summary for global step 20000: training/model.ckpt-20000\n",
            "INFO:tensorflow:Performing the final export in the end of training.\n",
            "I1130 12:24:55.480412 140184336205696 exporter.py:410] Performing the final export in the end of training.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1130 12:24:55.855833 140184336205696 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:24:58.561885 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:24:58.601374 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:24:58.639491 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:24:58.678042 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:24:58.715249 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:24:58.757455 140184336205696 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1130 12:24:59.693163 140184336205696 estimator.py:1150] Done calling model_fn.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W1130 12:24:59.693577 140184336205696 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "I1130 12:24:59.695290 140184336205696 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "I1130 12:24:59.695487 140184336205696 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "I1130 12:24:59.695675 140184336205696 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "I1130 12:24:59.695859 140184336205696 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "I1130 12:24:59.696035 140184336205696 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
            "2021-11-30 12:24:59.696730: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:24:59.697256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 12:24:59.697366: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 12:24:59.697437: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 12:24:59.697508: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 12:24:59.697593: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 12:24:59.697655: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 12:24:59.697738: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 12:24:59.697819: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 12:24:59.697996: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:24:59.698535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:24:59.699022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 12:24:59.699078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-30 12:24:59.699104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-30 12:24:59.699121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-30 12:24:59.699287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:24:59.699782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:24:59.700208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-20000\n",
            "I1130 12:24:59.703314 140184336205696 saver.py:1284] Restoring parameters from training/model.ckpt-20000\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "I1130 12:25:00.229048 140184336205696 builder_impl.py:665] Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I1130 12:25:00.229281 140184336205696 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: training/export/Servo/temp-b'1638275095'/saved_model.pb\n",
            "I1130 12:25:01.111985 140184336205696 builder_impl.py:425] SavedModel written to: training/export/Servo/temp-b'1638275095'/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 2.319319.\n",
            "I1130 12:25:01.784462 140184336205696 estimator.py:371] Loss for final step: 2.319319.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KP-tUdtnRybs",
        "outputId": "58541e18-2609-4667-8a52-54fdc5e1c960"
      },
      "source": [
        "!ls {model_dir}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint\n",
            "eval_0\n",
            "events.out.tfevents.1638258131.1f54391a8788\n",
            "export\n",
            "graph.pbtxt\n",
            "model.ckpt-17797.data-00000-of-00001\n",
            "model.ckpt-17797.index\n",
            "model.ckpt-17797.meta\n",
            "model.ckpt-18511.data-00000-of-00001\n",
            "model.ckpt-18511.index\n",
            "model.ckpt-18511.meta\n",
            "model.ckpt-19223.data-00000-of-00001\n",
            "model.ckpt-19223.index\n",
            "model.ckpt-19223.meta\n",
            "model.ckpt-19932.data-00000-of-00001\n",
            "model.ckpt-19932.index\n",
            "model.ckpt-19932.meta\n",
            "model.ckpt-20000.data-00000-of-00001\n",
            "model.ckpt-20000.index\n",
            "model.ckpt-20000.meta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmSESMetj1sa"
      },
      "source": [
        "## Exporting a Trained Inference Graph\n",
        "Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHoP90pUyKSq",
        "outputId": "388ecb7e-1a8f-4436-a179-e9bb7bc3940f"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "output_directory = 'tflite/'\n",
        "\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "!python /content/models/research/object_detection/export_tflite_ssd_graph.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path} \\\n",
        "    --add_postprocessing_op=true"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training/model.ckpt-20000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W1130 12:25:26.675951 139717344683904 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:25:29.401620 139717344683904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:25:29.440061 139717344683904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:25:29.479006 139717344683904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:25:29.516515 139717344683904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:25:29.558461 139717344683904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1130 12:25:29.596136 139717344683904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "2021-11-30 12:25:29.659852: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-11-30 12:25:29.691131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:25:29.691996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 12:25:29.692535: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 12:25:29.695522: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 12:25:29.696841: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 12:25:29.697602: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 12:25:29.708633: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 12:25:29.726756: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 12:25:29.744553: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 12:25:29.744693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:25:29.745571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:25:29.746276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 12:25:29.756742: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2021-11-30 12:25:29.757020: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560218aab100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-11-30 12:25:29.757057: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-11-30 12:25:29.866091: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:25:29.867006: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560218aabb80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-11-30 12:25:29.867042: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2021-11-30 12:25:29.867235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:25:29.868074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 12:25:29.868173: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 12:25:29.868240: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 12:25:29.868292: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 12:25:29.868346: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 12:25:29.868409: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 12:25:29.868457: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 12:25:29.868504: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 12:25:29.868606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:25:29.869428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:25:29.870169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 12:25:29.870263: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 12:25:29.871851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-30 12:25:29.871894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-30 12:25:29.871934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-30 12:25:29.872116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:25:29.872883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:25:29.873641: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-11-30 12:25:29.873712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "I1130 12:25:31.953143 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "I1130 12:25:31.953631 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "I1130 12:25:31.954003 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "I1130 12:25:31.954269 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "I1130 12:25:31.954604 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "I1130 12:25:31.954884 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "I1130 12:25:31.955240 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "I1130 12:25:31.955528 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "I1130 12:25:31.955868 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "I1130 12:25:31.956147 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "I1130 12:25:31.956492 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "I1130 12:25:31.956767 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "I1130 12:25:31.957104 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "I1130 12:25:31.957344 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "I1130 12:25:31.957667 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "I1130 12:25:31.957980 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "I1130 12:25:31.958327 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "I1130 12:25:31.958568 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "I1130 12:25:31.958909 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "I1130 12:25:31.959162 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "I1130 12:25:31.959480 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "I1130 12:25:31.959738 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "I1130 12:25:31.960092 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "I1130 12:25:31.960353 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "I1130 12:25:31.960678 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "I1130 12:25:31.960934 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "I1130 12:25:31.961479 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "I1130 12:25:31.961739 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "I1130 12:25:31.962078 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "I1130 12:25:31.962313 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "I1130 12:25:31.962643 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "I1130 12:25:31.962953 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "I1130 12:25:31.963303 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "I1130 12:25:31.963621 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "I1130 12:25:31.965376 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "I1130 12:25:31.965644 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1130 12:25:31.965908 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "I1130 12:25:31.966181 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1130 12:25:31.966475 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "I1130 12:25:31.966753 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1130 12:25:31.967055 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "I1130 12:25:31.967348 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1130 12:25:31.967602 139717344683904 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W1130 12:25:32.614753 139717344683904 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2021-11-30 12:25:33.599935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:25:33.600690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 12:25:33.600788: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 12:25:33.600848: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 12:25:33.600910: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 12:25:33.600986: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 12:25:33.601054: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 12:25:33.601110: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 12:25:33.601174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 12:25:33.601277: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:25:33.602114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:25:33.602769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 12:25:33.602823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-30 12:25:33.602853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-30 12:25:33.602877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-30 12:25:33.603024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:25:33.603806: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:25:33.604481: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-20000\n",
            "I1130 12:25:33.606021 139717344683904 saver.py:1284] Restoring parameters from training/model.ckpt-20000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W1130 12:25:34.944742 139717344683904 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W1130 12:25:34.945100 139717344683904 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 632 variables.\n",
            "I1130 12:25:35.531118 139717344683904 graph_util_impl.py:334] Froze 632 variables.\n",
            "INFO:tensorflow:Converted 632 variables to const ops.\n",
            "I1130 12:25:35.649955 139717344683904 graph_util_impl.py:394] Converted 632 variables to const ops.\n",
            "2021-11-30 12:25:35.786844: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usgBZvkz0nqD",
        "outputId": "9b148bb8-dbca-4a63-ac7b-e3f5dff7f5e2"
      },
      "source": [
        "!ls -lah tflite"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 70M\n",
            "drwxr-xr-x  2 root root 4.0K Nov 30 12:25 .\n",
            "drwxr-xr-x 25 root root 4.0K Nov 30 12:25 ..\n",
            "-rw-r--r--  1 root root  19M Nov 30 12:25 tflite_graph.pb\n",
            "-rw-r--r--  1 root root  51M Nov 30 12:25 tflite_graph.pbtxt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VP1m8mi4jxoj"
      },
      "source": [
        "# Convert model to Tensorflow Lite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saOXUGrsj0_u",
        "outputId": "cc3db9ce-f22c-4132-c13e-d5a096eea77b"
      },
      "source": [
        "!tflite_convert \\\n",
        "  --graph_def_file tflite/tflite_graph.pb \\\n",
        "  --output_file=tflite/detect.tflite \\\n",
        "  --output_format=TFLITE \\\n",
        "  --input_shapes=1,300,300,3 \\\n",
        "  --input_arrays=normalized_input_image_tensor \\\n",
        "  --output_arrays=TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3 \\\n",
        "  --inference_type=QUANTIZED_UINT8 \\\n",
        "  --mean_values=128 \\\n",
        "  --std_dev_values=127 \\\n",
        "  --change_concat_input_ranges=false \\\n",
        "  --allow_custom_ops"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-11-30 12:25:58.555155: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-11-30 12:25:58.575865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:25:58.576644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 12:25:58.577049: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 12:25:58.581757: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 12:25:58.582927: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 12:25:58.583314: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 12:25:58.585405: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 12:25:58.586362: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 12:25:58.590655: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 12:25:58.590780: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:25:58.591644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:25:58.592306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 12:25:58.597765: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2021-11-30 12:25:58.598051: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5651ae832d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-11-30 12:25:58.598089: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-11-30 12:25:58.704542: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:25:58.705472: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5651ae832f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-11-30 12:25:58.705510: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2021-11-30 12:25:58.705690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:25:58.706427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-30 12:25:58.706503: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 12:25:58.706546: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-30 12:25:58.706592: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-30 12:25:58.706638: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-30 12:25:58.706686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-30 12:25:58.706725: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-30 12:25:58.706765: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-30 12:25:58.706858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:25:58.707585: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:25:58.708155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-30 12:25:58.708226: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-30 12:25:58.709290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-30 12:25:58.709325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-30 12:25:58.709359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-30 12:25:58.709514: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:25:58.710164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-30 12:25:58.710847: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-11-30 12:25:58.710905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yQPHD0nlAfs",
        "outputId": "ebfc4bc0-f430-49ad-aeb3-c75cdbce4253"
      },
      "source": [
        "!ls -lah tflite"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 74M\n",
            "drwxr-xr-x  2 root root 4.0K Nov 30 12:26 .\n",
            "drwxr-xr-x 25 root root 4.0K Nov 30 12:25 ..\n",
            "-rw-r--r--  1 root root 4.6M Nov 30 12:26 detect.tflite\n",
            "-rw-r--r--  1 root root  19M Nov 30 12:25 tflite_graph.pb\n",
            "-rw-r--r--  1 root root  51M Nov 30 12:25 tflite_graph.pbtxt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LNu4Q-DlC7o"
      },
      "source": [
        "# Compress and Important Download Folders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2h44T8plYO9"
      },
      "source": [
        "models folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1mFq4OxlB-D",
        "outputId": "afa8231a-212d-4142-aeb1-e3ca02f41bbe"
      },
      "source": [
        "!zip -r /content/models.zip /content/models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/models/ (stored 0%)\n",
            "  adding: content/models/community/ (stored 0%)\n",
            "  adding: content/models/community/README.md (deflated 78%)\n",
            "  adding: content/models/README.md (deflated 54%)\n",
            "  adding: content/models/.git/ (stored 0%)\n",
            "  adding: content/models/.git/index (deflated 67%)\n",
            "  adding: content/models/.git/logs/ (stored 0%)\n",
            "  adding: content/models/.git/logs/HEAD (deflated 29%)\n",
            "  adding: content/models/.git/logs/refs/ (stored 0%)\n",
            "  adding: content/models/.git/logs/refs/remotes/ (stored 0%)\n",
            "  adding: content/models/.git/logs/refs/remotes/origin/ (stored 0%)\n",
            "  adding: content/models/.git/logs/refs/remotes/origin/HEAD (deflated 29%)\n",
            "  adding: content/models/.git/logs/refs/heads/ (stored 0%)\n",
            "  adding: content/models/.git/logs/refs/heads/master (deflated 29%)\n",
            "  adding: content/models/.git/branches/ (stored 0%)\n",
            "  adding: content/models/.git/info/ (stored 0%)\n",
            "  adding: content/models/.git/info/exclude (deflated 28%)\n",
            "  adding: content/models/.git/hooks/ (stored 0%)\n",
            "  adding: content/models/.git/hooks/applypatch-msg.sample (deflated 42%)\n",
            "  adding: content/models/.git/hooks/prepare-commit-msg.sample (deflated 50%)\n",
            "  adding: content/models/.git/hooks/pre-push.sample (deflated 50%)\n",
            "  adding: content/models/.git/hooks/post-update.sample (deflated 27%)\n",
            "  adding: content/models/.git/hooks/pre-rebase.sample (deflated 59%)\n",
            "  adding: content/models/.git/hooks/commit-msg.sample (deflated 44%)\n",
            "  adding: content/models/.git/hooks/pre-commit.sample (deflated 43%)\n",
            "  adding: content/models/.git/hooks/pre-receive.sample (deflated 40%)\n",
            "  adding: content/models/.git/hooks/fsmonitor-watchman.sample (deflated 53%)\n",
            "  adding: content/models/.git/hooks/pre-applypatch.sample (deflated 38%)\n",
            "  adding: content/models/.git/hooks/update.sample (deflated 68%)\n",
            "  adding: content/models/.git/objects/ (stored 0%)\n",
            "  adding: content/models/.git/objects/info/ (stored 0%)\n",
            "  adding: content/models/.git/objects/pack/ (stored 0%)\n",
            "  adding: content/models/.git/objects/pack/pack-660d5287ef3894c13c54d4b1d62d95fc9ef7e297.idx (deflated 1%)\n",
            "  adding: content/models/.git/objects/pack/pack-660d5287ef3894c13c54d4b1d62d95fc9ef7e297.pack (deflated 0%)\n",
            "  adding: content/models/.git/description (deflated 14%)\n",
            "  adding: content/models/.git/HEAD (stored 0%)\n",
            "  adding: content/models/.git/packed-refs (deflated 61%)\n",
            "  adding: content/models/.git/config (deflated 34%)\n",
            "  adding: content/models/.git/refs/ (stored 0%)\n",
            "  adding: content/models/.git/refs/remotes/ (stored 0%)\n",
            "  adding: content/models/.git/refs/remotes/origin/ (stored 0%)\n",
            "  adding: content/models/.git/refs/remotes/origin/HEAD (stored 0%)\n",
            "  adding: content/models/.git/refs/heads/ (stored 0%)\n",
            "  adding: content/models/.git/refs/heads/master (stored 0%)\n",
            "  adding: content/models/.git/refs/tags/ (stored 0%)\n",
            "  adding: content/models/AUTHORS (deflated 34%)\n",
            "  adding: content/models/CONTRIBUTING.md (deflated 36%)\n",
            "  adding: content/models/research/ (stored 0%)\n",
            "  adding: content/models/research/rebar/ (stored 0%)\n",
            "  adding: content/models/research/rebar/README.md (deflated 57%)\n",
            "  adding: content/models/research/rebar/rebar.py (deflated 81%)\n",
            "  adding: content/models/research/rebar/rebar_train.py (deflated 65%)\n",
            "  adding: content/models/research/rebar/datasets.py (deflated 60%)\n",
            "  adding: content/models/research/rebar/utils.py (deflated 57%)\n",
            "  adding: content/models/research/rebar/logger.py (deflated 47%)\n",
            "  adding: content/models/research/rebar/config.py (deflated 45%)\n",
            "  adding: content/models/research/rebar/download_data.py (deflated 60%)\n",
            "  adding: content/models/research/ngrok-stable-linux-amd64.zip (stored 0%)\n",
            "  adding: content/models/research/vid2depth/ (stored 0%)\n",
            "  adding: content/models/research/vid2depth/reader.py (deflated 70%)\n",
            "  adding: content/models/research/vid2depth/util.py (deflated 58%)\n",
            "  adding: content/models/research/vid2depth/README.md (deflated 65%)\n",
            "  adding: content/models/research/vid2depth/train.py (deflated 65%)\n",
            "  adding: content/models/research/vid2depth/dataset/ (stored 0%)\n",
            "  adding: content/models/research/vid2depth/dataset/__init__.py (deflated 43%)\n",
            "  adding: content/models/research/vid2depth/dataset/kitti/ (stored 0%)\n",
            "  adding: content/models/research/vid2depth/dataset/kitti/static_frames.txt (deflated 94%)\n",
            "  adding: content/models/research/vid2depth/dataset/kitti/test_files_eigen.txt (deflated 94%)\n",
            "  adding: content/models/research/vid2depth/dataset/kitti/test_scenes_eigen.txt (deflated 81%)\n",
            "  adding: content/models/research/vid2depth/dataset/kitti/test_scenes_stereo.txt (deflated 83%)\n",
            "  adding: content/models/research/vid2depth/dataset/kitti/test_files_stereo.txt (deflated 92%)\n",
            "  adding: content/models/research/vid2depth/dataset/dataset_loader.py (deflated 78%)\n",
            "  adding: content/models/research/vid2depth/dataset/gen_data.py (deflated 67%)\n",
            "  adding: content/models/research/vid2depth/project.py (deflated 68%)\n",
            "  adding: content/models/research/vid2depth/.bazelrc (deflated 31%)\n",
            "  adding: content/models/research/vid2depth/repo.bzl (deflated 57%)\n",
            "  adding: content/models/research/vid2depth/inference.py (deflated 64%)\n",
            "  adding: content/models/research/vid2depth/nets.py (deflated 72%)\n",
            "  adding: content/models/research/vid2depth/model.py (deflated 74%)\n",
            "  adding: content/models/research/vid2depth/third_party/ (stored 0%)\n",
            "  adding: content/models/research/vid2depth/third_party/eigen.BUILD (deflated 43%)\n",
            "  adding: content/models/research/vid2depth/third_party/pcl.BUILD (deflated 80%)\n",
            "  adding: content/models/research/vid2depth/third_party/hdf5.BUILD (deflated 66%)\n",
            "  adding: content/models/research/vid2depth/third_party/flann.BUILD (deflated 70%)\n",
            "  adding: content/models/research/vid2depth/third_party/BUILD (stored 0%)\n",
            "  adding: content/models/research/vid2depth/WORKSPACE (deflated 64%)\n",
            "  adding: content/models/research/vid2depth/ops/ (stored 0%)\n",
            "  adding: content/models/research/vid2depth/ops/icp_op.py (deflated 46%)\n",
            "  adding: content/models/research/vid2depth/ops/icp_grad_test.py (deflated 72%)\n",
            "  adding: content/models/research/vid2depth/ops/__init__.py (deflated 43%)\n",
            "  adding: content/models/research/vid2depth/ops/pcl_demo.cc (deflated 70%)\n",
            "  adding: content/models/research/vid2depth/ops/icp_grad.py (deflated 53%)\n",
            "  adding: content/models/research/vid2depth/ops/icp_util.py (deflated 71%)\n",
            "  adding: content/models/research/vid2depth/ops/icp_train_demo.py (deflated 64%)\n",
            "  adding: content/models/research/vid2depth/ops/testdata/ (stored 0%)\n",
            "  adding: content/models/research/vid2depth/ops/testdata/pointcloud.npy (deflated 23%)\n",
            "  adding: content/models/research/vid2depth/ops/icp_test.py (deflated 80%)\n",
            "  adding: content/models/research/vid2depth/ops/icp_op_kernel.cc (deflated 72%)\n",
            "  adding: content/models/research/vid2depth/ops/BUILD (deflated 78%)\n",
            "  adding: content/models/research/vid2depth/BUILD (deflated 11%)\n",
            "  adding: content/models/research/README.md (deflated 63%)\n",
            "  adding: content/models/research/autoaugment/ (stored 0%)\n",
            "  adding: content/models/research/autoaugment/README.md (deflated 57%)\n",
            "  adding: content/models/research/autoaugment/train_cifar.py (deflated 70%)\n",
            "  adding: content/models/research/autoaugment/augmentation_transforms.py (deflated 71%)\n",
            "  adding: content/models/research/autoaugment/custom_ops.py (deflated 66%)\n",
            "  adding: content/models/research/autoaugment/helper_utils.py (deflated 65%)\n",
            "  adding: content/models/research/autoaugment/shake_shake.py (deflated 64%)\n",
            "  adding: content/models/research/autoaugment/policies.py (deflated 77%)\n",
            "  adding: content/models/research/autoaugment/shake_drop.py (deflated 68%)\n",
            "  adding: content/models/research/autoaugment/data_utils.py (deflated 68%)\n",
            "  adding: content/models/research/autoaugment/wrn.py (deflated 66%)\n",
            "  adding: content/models/research/training/ (stored 0%)\n",
            "  adding: content/models/research/training/graph.pbtxt (deflated 97%)\n",
            "  adding: content/models/research/training/model.ckpt-20000.index (deflated 74%)\n",
            "  adding: content/models/research/training/model.ckpt-17797.meta (deflated 93%)\n",
            "  adding: content/models/research/training/model.ckpt-19223.data-00000-of-00001 (deflated 8%)\n",
            "  adding: content/models/research/training/checkpoint (deflated 72%)\n",
            "  adding: content/models/research/training/events.out.tfevents.1638258131.1f54391a8788 (deflated 93%)\n",
            "  adding: content/models/research/training/model.ckpt-18511.data-00000-of-00001 (deflated 8%)\n",
            "  adding: content/models/research/training/model.ckpt-17797.data-00000-of-00001 (deflated 8%)\n",
            "  adding: content/models/research/training/model.ckpt-20000.meta (deflated 93%)\n",
            "  adding: content/models/research/training/model.ckpt-19223.meta (deflated 93%)\n",
            "  adding: content/models/research/training/export/ (stored 0%)\n",
            "  adding: content/models/research/training/export/Servo/ (stored 0%)\n",
            "  adding: content/models/research/training/export/Servo/1638275095/ (stored 0%)\n",
            "  adding: content/models/research/training/export/Servo/1638275095/variables/ (stored 0%)\n",
            "  adding: content/models/research/training/export/Servo/1638275095/variables/variables.index (deflated 68%)\n",
            "  adding: content/models/research/training/export/Servo/1638275095/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: content/models/research/training/export/Servo/1638275095/saved_model.pb (deflated 93%)\n",
            "  adding: content/models/research/training/model.ckpt-19932.data-00000-of-00001 (deflated 8%)\n",
            "  adding: content/models/research/training/model.ckpt-18511.meta (deflated 93%)\n",
            "  adding: content/models/research/training/model.ckpt-19932.meta (deflated 93%)\n",
            "  adding: content/models/research/training/eval_0/ (stored 0%)\n",
            "  adding: content/models/research/training/eval_0/events.out.tfevents.1638258796.1f54391a8788 (deflated 34%)\n",
            "  adding: content/models/research/training/model.ckpt-18511.index (deflated 74%)\n",
            "  adding: content/models/research/training/model.ckpt-19223.index (deflated 74%)\n",
            "  adding: content/models/research/training/model.ckpt-17797.index (deflated 74%)\n",
            "  adding: content/models/research/training/model.ckpt-20000.data-00000-of-00001 (deflated 7%)\n",
            "  adding: content/models/research/training/model.ckpt-19932.index (deflated 74%)\n",
            "  adding: content/models/research/lfads/ (stored 0%)\n",
            "  adding: content/models/research/lfads/README.md (deflated 66%)\n",
            "  adding: content/models/research/lfads/synth_data/ (stored 0%)\n",
            "  adding: content/models/research/lfads/synth_data/generate_chaotic_rnn_data.py (deflated 63%)\n",
            "  adding: content/models/research/lfads/synth_data/generate_labeled_rnn_data.py (deflated 65%)\n",
            "  adding: content/models/research/lfads/synth_data/run_generate_synth_data.sh (deflated 73%)\n",
            "  adding: content/models/research/lfads/synth_data/synthetic_data_utils.py (deflated 63%)\n",
            "  adding: content/models/research/lfads/synth_data/generate_itb_data.py (deflated 67%)\n",
            "  adding: content/models/research/lfads/synth_data/trained_itb/ (stored 0%)\n",
            "  adding: content/models/research/lfads/synth_data/trained_itb/model-65000.meta (deflated 93%)\n",
            "  adding: content/models/research/lfads/synth_data/trained_itb/model-65000.data-00000-of-00001 (deflated 8%)\n",
            "  adding: content/models/research/lfads/synth_data/trained_itb/model-65000.index (deflated 32%)\n",
            "  adding: content/models/research/lfads/plot_lfads.py (deflated 69%)\n",
            "  adding: content/models/research/lfads/lfads.py (deflated 78%)\n",
            "  adding: content/models/research/lfads/run_lfads.py (deflated 69%)\n",
            "  adding: content/models/research/lfads/distributions.py (deflated 73%)\n",
            "  adding: content/models/research/lfads/utils.py (deflated 71%)\n",
            "  adding: content/models/research/ngrok (deflated 54%)\n",
            "  adding: content/models/research/pretrained_model/ (stored 0%)\n",
            "  adding: content/models/research/pretrained_model/model.ckpt.data-00000-of-00001 (deflated 7%)\n",
            "  adding: content/models/research/pretrained_model/pipeline.config (deflated 69%)\n",
            "  adding: content/models/research/pretrained_model/checkpoint (deflated 42%)\n",
            "  adding: content/models/research/pretrained_model/frozen_inference_graph.pb (deflated 10%)\n",
            "  adding: content/models/research/pretrained_model/model.ckpt.meta (deflated 95%)\n",
            "  adding: content/models/research/pretrained_model/saved_model/ (stored 0%)\n",
            "  adding: content/models/research/pretrained_model/saved_model/variables/ (stored 0%)\n",
            "  adding: content/models/research/pretrained_model/saved_model/saved_model.pb (deflated 11%)\n",
            "  adding: content/models/research/pretrained_model/model.ckpt.index (deflated 68%)\n",
            "  adding: content/models/research/deeplab/ (stored 0%)\n",
            "  adding: content/models/research/deeplab/input_preprocess.py (deflated 68%)\n",
            "  adding: content/models/research/deeplab/utils/ (stored 0%)\n",
            "  adding: content/models/research/deeplab/utils/get_dataset_colormap.py (deflated 72%)\n",
            "  adding: content/models/research/deeplab/utils/__init__.py (stored 0%)\n",
            "  adding: content/models/research/deeplab/utils/save_annotation.py (deflated 58%)\n",
            "  adding: content/models/research/deeplab/utils/train_utils.py (deflated 71%)\n",
            "  adding: content/models/research/deeplab/utils/get_dataset_colormap_test.py (deflated 69%)\n",
            "  adding: content/models/research/deeplab/README.md (deflated 62%)\n",
            "  adding: content/models/research/deeplab/vis.py (deflated 68%)\n",
            "  adding: content/models/research/deeplab/train.py (deflated 70%)\n",
            "  adding: content/models/research/deeplab/__init__.py (stored 0%)\n",
            "  adding: content/models/research/deeplab/deprecated/ (stored 0%)\n",
            "  adding: content/models/research/deeplab/deprecated/__init__.py (stored 0%)\n",
            "  adding: content/models/research/deeplab/deprecated/segmentation_dataset.py (deflated 63%)\n",
            "  adding: content/models/research/deeplab/common_test.py (deflated 64%)\n",
            "  adding: content/models/research/deeplab/deeplab_demo.ipynb (deflated 70%)\n",
            "  adding: content/models/research/deeplab/export_model.py (deflated 65%)\n",
            "  adding: content/models/research/deeplab/testing/ (stored 0%)\n",
            "  adding: content/models/research/deeplab/testing/info.md (deflated 35%)\n",
            "  adding: content/models/research/deeplab/testing/pascal_voc_seg/ (stored 0%)\n",
            "  adding: content/models/research/deeplab/testing/pascal_voc_seg/val-00000-of-00001.tfrecord (deflated 0%)\n",
            "  adding: content/models/research/deeplab/common.py (deflated 69%)\n",
            "  adding: content/models/research/deeplab/eval.py (deflated 67%)\n",
            "  adding: content/models/research/deeplab/model_test.py (deflated 69%)\n",
            "  adding: content/models/research/deeplab/evaluation/ (stored 0%)\n",
            "  adding: content/models/research/deeplab/evaluation/README.md (deflated 64%)\n",
            "  adding: content/models/research/deeplab/evaluation/panoptic_quality_test.py (deflated 82%)\n",
            "  adding: content/models/research/deeplab/evaluation/eval_coco_format.py (deflated 70%)\n",
            "  adding: content/models/research/deeplab/evaluation/base_metric.py (deflated 66%)\n",
            "  adding: content/models/research/deeplab/evaluation/__init__.py (stored 0%)\n",
            "  adding: content/models/research/deeplab/evaluation/streaming_metrics.py (deflated 77%)\n",
            "  adding: content/models/research/deeplab/evaluation/streaming_metrics_test.py (deflated 86%)\n",
            "  adding: content/models/research/deeplab/evaluation/test_utils_test.py (deflated 62%)\n",
            "  adding: content/models/research/deeplab/evaluation/parsing_covering.py (deflated 68%)\n",
            "  adding: content/models/research/deeplab/evaluation/panoptic_quality.py (deflated 70%)\n",
            "  adding: content/models/research/deeplab/evaluation/parsing_covering_test.py (deflated 73%)\n",
            "  adding: content/models/research/deeplab/evaluation/g3doc/ (stored 0%)\n",
            "  adding: content/models/research/deeplab/evaluation/g3doc/img/ (stored 0%)\n",
            "  adding: content/models/research/deeplab/evaluation/g3doc/img/equation_pc.png (deflated 8%)\n",
            "  adding: content/models/research/deeplab/evaluation/g3doc/img/equation_pq.png (deflated 5%)\n",
            "  adding: content/models/research/deeplab/evaluation/eval_coco_format_test.py (deflated 78%)\n",
            "  adding: content/models/research/deeplab/evaluation/testdata/ (stored 0%)\n",
            "  adding: content/models/research/deeplab/evaluation/testdata/bird_pred_class.png (deflated 1%)\n",
            "  adding: content/models/research/deeplab/evaluation/testdata/cat_pred_instance.png (deflated 12%)\n",
            "  adding: content/models/research/deeplab/evaluation/testdata/bird_pred_instance.png (deflated 1%)\n",
            "  adding: content/models/research/deeplab/evaluation/testdata/team_pred_instance.png (deflated 2%)\n",
            "  adding: content/models/research/deeplab/evaluation/testdata/README.md (deflated 48%)\n",
            "  adding: content/models/research/deeplab/evaluation/testdata/cat_pred_class.png (deflated 18%)\n",
            "  adding: content/models/research/deeplab/evaluation/testdata/bird_gt.png (stored 0%)\n",
            "  adding: content/models/research/deeplab/evaluation/testdata/team_pred_class.png (deflated 8%)\n",
            "  adding: content/models/research/deeplab/evaluation/testdata/coco_pred.json (deflated 82%)\n",
            "  adding: content/models/research/deeplab/evaluation/testdata/coco_gt/ (stored 0%)\n",
            "  adding: content/models/research/deeplab/evaluation/testdata/coco_gt/team.png (stored 0%)\n",
            "  adding: content/models/research/deeplab/evaluation/testdata/coco_gt/bird.png (deflated 1%)\n",
            "  adding: content/models/research/deeplab/evaluation/testdata/coco_gt/congress.png (deflated 6%)\n",
            "  adding: content/models/research/deeplab/evaluation/testdata/coco_gt/cat.png (deflated 1%)\n",
            "  adding: content/models/research/deeplab/evaluation/testdata/cat_gt.png (deflated 9%)\n",
            "  adding: content/models/research/deeplab/evaluation/testdata/coco_gt.json (deflated 82%)\n",
            "  adding: content/models/research/deeplab/evaluation/testdata/coco_pred/ (stored 0%)\n",
            "  adding: content/models/research/deeplab/evaluation/testdata/coco_pred/team.png (deflated 0%)\n",
            "  adding: content/models/research/deeplab/evaluation/testdata/coco_pred/bird.png (deflated 0%)\n",
            "  adding: content/models/research/deeplab/evaluation/testdata/coco_pred/congress.png (deflated 12%)\n",
            "  adding: content/models/research/deeplab/evaluation/testdata/coco_pred/cat.png (deflated 2%)\n",
            "  adding: content/models/research/deeplab/evaluation/testdata/team_gt_instance.png (deflated 1%)\n",
            "  adding: content/models/research/deeplab/evaluation/test_utils.py (deflated 62%)\n",
            "  adding: content/models/research/deeplab/local_test.sh (deflated 64%)\n",
            "  adding: content/models/research/deeplab/datasets/ (stored 0%)\n",
            "  adding: content/models/research/deeplab/datasets/build_ade20k_data.py (deflated 62%)\n",
            "  adding: content/models/research/deeplab/datasets/build_voc2012_data.py (deflated 63%)\n",
            "  adding: content/models/research/deeplab/datasets/convert_cityscapes.sh (deflated 52%)\n",
            "  adding: content/models/research/deeplab/datasets/remove_gt_colormap.py (deflated 61%)\n",
            "  adding: content/models/research/deeplab/datasets/__init__.py (stored 0%)\n",
            "  adding: content/models/research/deeplab/datasets/build_cityscapes_data.py (deflated 62%)\n",
            "  adding: content/models/research/deeplab/datasets/download_and_convert_ade20k.sh (deflated 56%)\n",
            "  adding: content/models/research/deeplab/datasets/data_generator.py (deflated 67%)\n",
            "  adding: content/models/research/deeplab/datasets/download_and_convert_voc2012.sh (deflated 56%)\n",
            "  adding: content/models/research/deeplab/datasets/build_data.py (deflated 66%)\n",
            "  adding: content/models/research/deeplab/datasets/data_generator_test.py (deflated 59%)\n",
            "  adding: content/models/research/deeplab/convert_to_tflite.py (deflated 60%)\n",
            "  adding: content/models/research/deeplab/g3doc/ (stored 0%)\n",
            "  adding: content/models/research/deeplab/g3doc/pascal.md (deflated 68%)\n",
            "  adding: content/models/research/deeplab/g3doc/faq.md (deflated 53%)\n",
            "  adding: content/models/research/deeplab/g3doc/img/ (stored 0%)\n",
            "  adding: content/models/research/deeplab/g3doc/img/vis2.png (deflated 1%)\n",
            "  adding: content/models/research/deeplab/g3doc/img/image3.jpg (deflated 0%)\n",
            "  adding: content/models/research/deeplab/g3doc/img/image1.jpg (deflated 0%)\n",
            "  adding: content/models/research/deeplab/g3doc/img/vis1.png (deflated 1%)\n",
            "  adding: content/models/research/deeplab/g3doc/img/vis3.png (deflated 0%)\n",
            "  adding: content/models/research/deeplab/g3doc/img/image_info.txt (deflated 37%)\n",
            "  adding: content/models/research/deeplab/g3doc/img/image2.jpg (deflated 0%)\n",
            "  adding: content/models/research/deeplab/g3doc/cityscapes.md (deflated 67%)\n",
            "  adding: content/models/research/deeplab/g3doc/installation.md (deflated 56%)\n",
            "  adding: content/models/research/deeplab/g3doc/model_zoo.md (deflated 71%)\n",
            "  adding: content/models/research/deeplab/g3doc/export_model.md (deflated 48%)\n",
            "  adding: content/models/research/deeplab/g3doc/ade20k.md (deflated 58%)\n",
            "  adding: content/models/research/deeplab/g3doc/quantize.md (deflated 63%)\n",
            "  adding: content/models/research/deeplab/core/ (stored 0%)\n",
            "  adding: content/models/research/deeplab/core/resnet_v1_beta.py (deflated 85%)\n",
            "  adding: content/models/research/deeplab/core/xception.py (deflated 81%)\n",
            "  adding: content/models/research/deeplab/core/dense_prediction_cell_branch5_top1_cityscapes.json (deflated 71%)\n",
            "  adding: content/models/research/deeplab/core/__init__.py (stored 0%)\n",
            "  adding: content/models/research/deeplab/core/preprocess_utils.py (deflated 71%)\n",
            "  adding: content/models/research/deeplab/core/preprocess_utils_test.py (deflated 85%)\n",
            "  adding: content/models/research/deeplab/core/resnet_v1_beta_test.py (deflated 88%)\n",
            "  adding: content/models/research/deeplab/core/nas_network.py (deflated 73%)\n",
            "  adding: content/models/research/deeplab/core/nas_genotypes.py (deflated 54%)\n",
            "  adding: content/models/research/deeplab/core/xception_test.py (deflated 84%)\n",
            "  adding: content/models/research/deeplab/core/utils_test.py (deflated 69%)\n",
            "  adding: content/models/research/deeplab/core/feature_extractor.py (deflated 79%)\n",
            "  adding: content/models/research/deeplab/core/utils.py (deflated 67%)\n",
            "  adding: content/models/research/deeplab/core/conv2d_ws_test.py (deflated 86%)\n",
            "  adding: content/models/research/deeplab/core/nas_network_test.py (deflated 62%)\n",
            "  adding: content/models/research/deeplab/core/conv2d_ws.py (deflated 70%)\n",
            "  adding: content/models/research/deeplab/core/nas_cell.py (deflated 70%)\n",
            "  adding: content/models/research/deeplab/core/dense_prediction_cell_test.py (deflated 75%)\n",
            "  adding: content/models/research/deeplab/core/dense_prediction_cell.py (deflated 72%)\n",
            "  adding: content/models/research/deeplab/model.py (deflated 78%)\n",
            "  adding: content/models/research/deeplab/local_test_mobilenetv2.sh (deflated 61%)\n",
            "  adding: content/models/research/marco/ (stored 0%)\n",
            "  adding: content/models/research/marco/README.md (deflated 55%)\n",
            "  adding: content/models/research/marco/request.json (deflated 25%)\n",
            "  adding: content/models/research/marco/jpeg2json.py (deflated 41%)\n",
            "  adding: content/models/research/marco/Automated_Marco.py (deflated 55%)\n",
            "  adding: content/models/research/tflite/ (stored 0%)\n",
            "  adding: content/models/research/tflite/detect.tflite (deflated 13%)\n",
            "  adding: content/models/research/tflite/tflite_graph.pb (deflated 9%)\n",
            "  adding: content/models/research/tflite/tflite_graph.pbtxt (deflated 56%)\n",
            "  adding: content/models/research/audioset/ (stored 0%)\n",
            "  adding: content/models/research/audioset/vggish/ (stored 0%)\n",
            "  adding: content/models/research/audioset/vggish/vggish_train_demo.py (deflated 60%)\n",
            "  adding: content/models/research/audioset/vggish/vggish_input.py (deflated 58%)\n",
            "  adding: content/models/research/audioset/vggish/vggish_slim.py (deflated 60%)\n",
            "  adding: content/models/research/audioset/vggish/mel_features.py (deflated 64%)\n",
            "  adding: content/models/research/audioset/vggish/vggish_smoke_test.py (deflated 56%)\n",
            "  adding: content/models/research/audioset/vggish/README.md (deflated 59%)\n",
            "  adding: content/models/research/audioset/vggish/vggish_inference_demo.py (deflated 62%)\n",
            "  adding: content/models/research/audioset/vggish/vggish_postprocess.py (deflated 60%)\n",
            "  adding: content/models/research/audioset/vggish/vggish_params.py (deflated 49%)\n",
            "  adding: content/models/research/audioset/vggish/vggish_export_tfhub.py (deflated 60%)\n",
            "  adding: content/models/research/audioset/README.md (deflated 55%)\n",
            "  adding: content/models/research/audioset/yamnet/ (stored 0%)\n",
            "  adding: content/models/research/audioset/yamnet/yamnet_test.py (deflated 59%)\n",
            "  adding: content/models/research/audioset/yamnet/yamnet_visualization.ipynb (deflated 28%)\n",
            "  adding: content/models/research/audioset/yamnet/README.md (deflated 53%)\n",
            "  adding: content/models/research/audioset/yamnet/export.py (deflated 69%)\n",
            "  adding: content/models/research/audioset/yamnet/params.py (deflated 50%)\n",
            "  adding: content/models/research/audioset/yamnet/inference.py (deflated 51%)\n",
            "  adding: content/models/research/audioset/yamnet/yamnet.py (deflated 69%)\n",
            "  adding: content/models/research/audioset/yamnet/yamnet_class_map.csv (deflated 51%)\n",
            "  adding: content/models/research/audioset/yamnet/features.py (deflated 67%)\n",
            "  adding: content/models/research/nst_blogpost/ (stored 0%)\n",
            "  adding: content/models/research/nst_blogpost/4_Neural_Style_Transfer_with_Eager_Execution.ipynb (deflated 77%)\n",
            "  adding: content/models/research/nst_blogpost/wave_turtle.png (deflated 0%)\n",
            "  adding: content/models/research/nst_blogpost/Green_Sea_Turtle_grazing_seagrass.jpg (deflated 1%)\n",
            "  adding: content/models/research/nst_blogpost/The_Great_Wave_off_Kanagawa.jpg (deflated 0%)\n",
            "  adding: content/models/research/seq_flow_lite/ (stored 0%)\n",
            "  adding: content/models/research/seq_flow_lite/demo/ (stored 0%)\n",
            "  adding: content/models/research/seq_flow_lite/demo/colab/ (stored 0%)\n",
            "  adding: content/models/research/seq_flow_lite/demo/colab/emotion_colab.ipynb (deflated 75%)\n",
            "  adding: content/models/research/seq_flow_lite/demo/colab/setup.py (deflated 49%)\n",
            "  adding: content/models/research/seq_flow_lite/demo/colab/move_ops.sh (deflated 63%)\n",
            "  adding: content/models/research/seq_flow_lite/demo/colab/setup_workspace.sh (deflated 42%)\n",
            "  adding: content/models/research/seq_flow_lite/demo/colab/BUILD (deflated 47%)\n",
            "  adding: content/models/research/seq_flow_lite/demo/prado/ (stored 0%)\n",
            "  adding: content/models/research/seq_flow_lite/demo/prado/prado_tflite_example.cc (deflated 63%)\n",
            "  adding: content/models/research/seq_flow_lite/demo/prado/data/ (stored 0%)\n",
            "  adding: content/models/research/seq_flow_lite/demo/prado/data/tflite.fb (deflated 88%)\n",
            "  adding: content/models/research/seq_flow_lite/demo/prado/BUILD (deflated 53%)\n",
            "  adding: content/models/research/seq_flow_lite/trainer_v2.py (deflated 58%)\n",
            "  adding: content/models/research/seq_flow_lite/utils/ (stored 0%)\n",
            "  adding: content/models/research/seq_flow_lite/utils/misc_utils.py (deflated 56%)\n",
            "  adding: content/models/research/seq_flow_lite/utils/tflite_utils.py (deflated 62%)\n",
            "  adding: content/models/research/seq_flow_lite/utils/BUILD (deflated 55%)\n",
            "  adding: content/models/research/seq_flow_lite/trainer.py (deflated 65%)\n",
            "  adding: content/models/research/seq_flow_lite/README.md (deflated 56%)\n",
            "  adding: content/models/research/seq_flow_lite/CONTRIBUTING.md (deflated 47%)\n",
            "  adding: content/models/research/seq_flow_lite/input_fn_reader.py (deflated 59%)\n",
            "  adding: content/models/research/seq_flow_lite/tf_ops/ (stored 0%)\n",
            "  adding: content/models/research/seq_flow_lite/tf_ops/projection_normalizer_util.cc (deflated 67%)\n",
            "  adding: content/models/research/seq_flow_lite/tf_ops/text_distorter.h (deflated 52%)\n",
            "  adding: content/models/research/seq_flow_lite/tf_ops/projection_tokenizer_util.h (deflated 56%)\n",
            "  adding: content/models/research/seq_flow_lite/tf_ops/text_distorter.cc (deflated 56%)\n",
            "  adding: content/models/research/seq_flow_lite/tf_ops/sequence_string_projection.cc (deflated 71%)\n",
            "  adding: content/models/research/seq_flow_lite/tf_ops/projection_tokenizer_util.cc (deflated 60%)\n",
            "  adding: content/models/research/seq_flow_lite/tf_ops/sequence_string_projection_op_v2_test.cc (deflated 81%)\n",
            "  adding: content/models/research/seq_flow_lite/tf_ops/projection_normalizer_util.h (deflated 58%)\n",
            "  adding: content/models/research/seq_flow_lite/tf_ops/build_def.bzl (deflated 58%)\n",
            "  adding: content/models/research/seq_flow_lite/tf_ops/repo.bzl (deflated 80%)\n",
            "  adding: content/models/research/seq_flow_lite/tf_ops/tf_custom_ops.cc (deflated 64%)\n",
            "  adding: content/models/research/seq_flow_lite/tf_ops/sequence_string_projection_op_v2.cc (deflated 69%)\n",
            "  adding: content/models/research/seq_flow_lite/tf_ops/sequence_string_projection_test.cc (deflated 89%)\n",
            "  adding: content/models/research/seq_flow_lite/tf_ops/projection_util.h (deflated 65%)\n",
            "  adding: content/models/research/seq_flow_lite/tf_ops/projection_util.cc (deflated 71%)\n",
            "  adding: content/models/research/seq_flow_lite/tf_ops/BUILD (deflated 82%)\n",
            "  adding: content/models/research/seq_flow_lite/.bazelrc (deflated 53%)\n",
            "  adding: content/models/research/seq_flow_lite/export_to_tflite.py (deflated 58%)\n",
            "  adding: content/models/research/seq_flow_lite/tflite_ops/ (stored 0%)\n",
            "  adding: content/models/research/seq_flow_lite/tflite_ops/expected_value.cc (deflated 65%)\n",
            "  adding: content/models/research/seq_flow_lite/tflite_ops/sequence_string_projection.cc (deflated 74%)\n",
            "  adding: content/models/research/seq_flow_lite/tflite_ops/layer_norm.cc (deflated 75%)\n",
            "  adding: content/models/research/seq_flow_lite/tflite_ops/tf_tflite_diff_test_util.cc (deflated 78%)\n",
            "  adding: content/models/research/seq_flow_lite/tflite_ops/expected_value.h (deflated 51%)\n",
            "  adding: content/models/research/seq_flow_lite/tflite_ops/layer_norm_test.cc (deflated 78%)\n",
            "  adding: content/models/research/seq_flow_lite/tflite_ops/sequence_string_projection_test.cc (deflated 90%)\n",
            "  adding: content/models/research/seq_flow_lite/tflite_ops/layer_norm.h (deflated 50%)\n",
            "  adding: content/models/research/seq_flow_lite/tflite_ops/sequence_string_projection.h (deflated 55%)\n",
            "  adding: content/models/research/seq_flow_lite/tflite_ops/tf_tflite_diff_test_util.h (deflated 66%)\n",
            "  adding: content/models/research/seq_flow_lite/tflite_ops/registerer.cc (deflated 65%)\n",
            "  adding: content/models/research/seq_flow_lite/tflite_ops/quantization_util.h (deflated 55%)\n",
            "  adding: content/models/research/seq_flow_lite/tflite_ops/BUILD (deflated 80%)\n",
            "  adding: content/models/research/seq_flow_lite/layers/ (stored 0%)\n",
            "  adding: content/models/research/seq_flow_lite/layers/dense_layers.py (deflated 68%)\n",
            "  adding: content/models/research/seq_flow_lite/layers/base_layers.py (deflated 64%)\n",
            "  adding: content/models/research/seq_flow_lite/layers/projection_layers.py (deflated 72%)\n",
            "  adding: content/models/research/seq_flow_lite/layers/normalization_layers.py (deflated 70%)\n",
            "  adding: content/models/research/seq_flow_lite/layers/quantization_layers.py (deflated 70%)\n",
            "  adding: content/models/research/seq_flow_lite/layers/conv_layers.py (deflated 67%)\n",
            "  adding: content/models/research/seq_flow_lite/layers/BUILD (deflated 82%)\n",
            "  adding: content/models/research/seq_flow_lite/metric_functions.py (deflated 57%)\n",
            "  adding: content/models/research/seq_flow_lite/models/ (stored 0%)\n",
            "  adding: content/models/research/seq_flow_lite/models/sgnn/ (stored 0%)\n",
            "  adding: content/models/research/seq_flow_lite/models/sgnn/sgnn_projection_test.cc (deflated 60%)\n",
            "  adding: content/models/research/seq_flow_lite/models/sgnn/sgnn_projection_op_resolver.h (deflated 51%)\n",
            "  adding: content/models/research/seq_flow_lite/models/sgnn/train.py (deflated 56%)\n",
            "  adding: content/models/research/seq_flow_lite/models/sgnn/sgnn_projection.h (deflated 51%)\n",
            "  adding: content/models/research/seq_flow_lite/models/sgnn/sgnn.py (deflated 65%)\n",
            "  adding: content/models/research/seq_flow_lite/models/sgnn/sgnn_test.py (deflated 60%)\n",
            "  adding: content/models/research/seq_flow_lite/models/sgnn/sgnn_projection.cc (deflated 63%)\n",
            "  adding: content/models/research/seq_flow_lite/models/sgnn/sgnn_projection_op_resolver.cc (deflated 50%)\n",
            "  adding: content/models/research/seq_flow_lite/models/sgnn/run_tflite.py (deflated 51%)\n",
            "  adding: content/models/research/seq_flow_lite/models/sgnn/BUILD (deflated 76%)\n",
            "  adding: content/models/research/seq_flow_lite/models/prado.py (deflated 72%)\n",
            "  adding: content/models/research/seq_flow_lite/models/BUILD (deflated 63%)\n",
            "  adding: content/models/research/seq_flow_lite/third_party/ (stored 0%)\n",
            "  adding: content/models/research/seq_flow_lite/third_party/python_runtime/ (stored 0%)\n",
            "  adding: content/models/research/seq_flow_lite/third_party/python_runtime/BUILD (deflated 25%)\n",
            "  adding: content/models/research/seq_flow_lite/third_party/utf.BUILD (deflated 76%)\n",
            "  adding: content/models/research/seq_flow_lite/third_party/py/ (stored 0%)\n",
            "  adding: content/models/research/seq_flow_lite/third_party/py/BUILD.tpl (deflated 57%)\n",
            "  adding: content/models/research/seq_flow_lite/third_party/py/python_configure.bzl (deflated 60%)\n",
            "  adding: content/models/research/seq_flow_lite/third_party/py/BUILD (stored 0%)\n",
            "  adding: content/models/research/seq_flow_lite/third_party/pybind11.BUILD (deflated 55%)\n",
            "  adding: content/models/research/seq_flow_lite/third_party/android/ (stored 0%)\n",
            "  adding: content/models/research/seq_flow_lite/third_party/android/android.bzl.tpl (deflated 35%)\n",
            "  adding: content/models/research/seq_flow_lite/third_party/android/android_configure.bzl (deflated 71%)\n",
            "  adding: content/models/research/seq_flow_lite/third_party/android/android_configure.BUILD.tpl (stored 0%)\n",
            "  adding: content/models/research/seq_flow_lite/third_party/android/BUILD (stored 0%)\n",
            "  adding: content/models/research/seq_flow_lite/third_party/repo.bzl (deflated 62%)\n",
            "  adding: content/models/research/seq_flow_lite/third_party/protobuf.BUILD (deflated 60%)\n",
            "  adding: content/models/research/seq_flow_lite/third_party/icu.BUILD (deflated 53%)\n",
            "  adding: content/models/research/seq_flow_lite/third_party/farmhash.BUILD (deflated 39%)\n",
            "  adding: content/models/research/seq_flow_lite/third_party/flatbuffers/ (stored 0%)\n",
            "  adding: content/models/research/seq_flow_lite/third_party/flatbuffers/build_defs.bzl (deflated 77%)\n",
            "  adding: content/models/research/seq_flow_lite/third_party/flatbuffers/workspace.bzl (deflated 52%)\n",
            "  adding: content/models/research/seq_flow_lite/third_party/flatbuffers/BUILD.bazel (deflated 76%)\n",
            "  adding: content/models/research/seq_flow_lite/third_party/flatbuffers/BUILD (deflated 5%)\n",
            "  adding: content/models/research/seq_flow_lite/third_party/BUILD (stored 0%)\n",
            "  adding: content/models/research/seq_flow_lite/WORKSPACE (deflated 65%)\n",
            "  adding: content/models/research/seq_flow_lite/BUILD (deflated 71%)\n",
            "  adding: content/models/research/seq_flow_lite/configs/ (stored 0%)\n",
            "  adding: content/models/research/seq_flow_lite/configs/civil_comments_prado.txt (deflated 52%)\n",
            "  adding: content/models/research/seq_flow_lite/configs/go_emotion_prado.txt (deflated 53%)\n",
            "  adding: content/models/research/lstm_object_detection/ (stored 0%)\n",
            "  adding: content/models/research/lstm_object_detection/inputs/ (stored 0%)\n",
            "  adding: content/models/research/lstm_object_detection/inputs/seq_dataset_builder.py (deflated 73%)\n",
            "  adding: content/models/research/lstm_object_detection/inputs/tf_sequence_example_decoder_test.py (deflated 70%)\n",
            "  adding: content/models/research/lstm_object_detection/inputs/__init__.py (stored 0%)\n",
            "  adding: content/models/research/lstm_object_detection/inputs/tf_sequence_example_decoder.py (deflated 72%)\n",
            "  adding: content/models/research/lstm_object_detection/inputs/seq_dataset_builder_test.py (deflated 74%)\n",
            "  adding: content/models/research/lstm_object_detection/utils/ (stored 0%)\n",
            "  adding: content/models/research/lstm_object_detection/utils/__init__.py (stored 0%)\n",
            "  adding: content/models/research/lstm_object_detection/utils/config_util.py (deflated 70%)\n",
            "  adding: content/models/research/lstm_object_detection/utils/config_util_test.py (deflated 71%)\n",
            "  adding: content/models/research/lstm_object_detection/builders/ (stored 0%)\n",
            "  adding: content/models/research/lstm_object_detection/builders/graph_rewriter_builder_test.py (deflated 71%)\n",
            "  adding: content/models/research/lstm_object_detection/builders/__init__.py (stored 0%)\n",
            "  adding: content/models/research/lstm_object_detection/builders/graph_rewriter_builder.py (deflated 65%)\n",
            "  adding: content/models/research/lstm_object_detection/export_tflite_lstd_graph_lib.py (deflated 72%)\n",
            "  adding: content/models/research/lstm_object_detection/trainer.py (deflated 70%)\n",
            "  adding: content/models/research/lstm_object_detection/README.md (deflated 49%)\n",
            "  adding: content/models/research/lstm_object_detection/train.py (deflated 66%)\n",
            "  adding: content/models/research/lstm_object_detection/__init__.py (stored 0%)\n",
            "  adding: content/models/research/lstm_object_detection/protos/ (stored 0%)\n",
            "  adding: content/models/research/lstm_object_detection/protos/input_reader_google.proto (deflated 51%)\n",
            "  adding: content/models/research/lstm_object_detection/protos/__init__.py (stored 0%)\n",
            "  adding: content/models/research/lstm_object_detection/protos/pipeline.proto (deflated 61%)\n",
            "  adding: content/models/research/lstm_object_detection/protos/quant_overrides.proto (deflated 58%)\n",
            "  adding: content/models/research/lstm_object_detection/model_builder_test.py (deflated 81%)\n",
            "  adding: content/models/research/lstm_object_detection/eval.py (deflated 64%)\n",
            "  adding: content/models/research/lstm_object_detection/tflite/ (stored 0%)\n",
            "  adding: content/models/research/lstm_object_detection/tflite/utils/ (stored 0%)\n",
            "  adding: content/models/research/lstm_object_detection/tflite/utils/file_utils.h (deflated 53%)\n",
            "  adding: content/models/research/lstm_object_detection/tflite/utils/ssd_utils.cc (deflated 80%)\n",
            "  adding: content/models/research/lstm_object_detection/tflite/utils/conversion_utils.h (deflated 52%)\n",
            "  adding: content/models/research/lstm_object_detection/tflite/utils/file_utils.cc (deflated 54%)\n",
            "  adding: content/models/research/lstm_object_detection/tflite/utils/ssd_utils.h (deflated 72%)\n",
            "  adding: content/models/research/lstm_object_detection/tflite/utils/conversion_utils_test.cc (deflated 79%)\n",
            "  adding: content/models/research/lstm_object_detection/tflite/utils/BUILD (deflated 71%)\n",
            "  adding: content/models/research/lstm_object_detection/tflite/utils/conversion_utils.cc (deflated 62%)\n",
            "  adding: content/models/research/lstm_object_detection/tflite/mobile_lstd_tflite_client.h (deflated 61%)\n",
            "  adding: content/models/research/lstm_object_detection/tflite/mobile_ssd_client.cc (deflated 70%)\n",
            "  adding: content/models/research/lstm_object_detection/tflite/protos/ (stored 0%)\n",
            "  adding: content/models/research/lstm_object_detection/tflite/protos/detections.proto (deflated 49%)\n",
            "  adding: content/models/research/lstm_object_detection/tflite/protos/box_encodings.proto (deflated 67%)\n",
            "  adding: content/models/research/lstm_object_detection/tflite/protos/anchor_generation_options.proto (deflated 56%)\n",
            "  adding: content/models/research/lstm_object_detection/tflite/protos/proto_config.asciipb (deflated 12%)\n",
            "  adding: content/models/research/lstm_object_detection/tflite/protos/mobile_ssd_client_options.proto (deflated 60%)\n",
            "  adding: content/models/research/lstm_object_detection/tflite/protos/labelmap.proto (deflated 52%)\n",
            "  adding: content/models/research/lstm_object_detection/tflite/protos/BUILD (deflated 78%)\n",
            "  adding: content/models/research/lstm_object_detection/tflite/mobile_ssd_client.h (deflated 65%)\n",
            "  adding: content/models/research/lstm_object_detection/tflite/mobile_ssd_tflite_client.h (deflated 61%)\n",
            "  adding: content/models/research/lstm_object_detection/tflite/mobile_ssd_tflite_client.cc (deflated 76%)\n",
            "  adding: content/models/research/lstm_object_detection/tflite/mobile_lstd_tflite_client.cc (deflated 77%)\n",
            "  adding: content/models/research/lstm_object_detection/tflite/WORKSPACE (deflated 67%)\n",
            "  adding: content/models/research/lstm_object_detection/tflite/BUILD (deflated 77%)\n",
            "  adding: content/models/research/lstm_object_detection/lstm/ (stored 0%)\n",
            "  adding: content/models/research/lstm_object_detection/lstm/rnn_decoder_test.py (deflated 84%)\n",
            "  adding: content/models/research/lstm_object_detection/lstm/__init__.py (stored 0%)\n",
            "  adding: content/models/research/lstm_object_detection/lstm/lstm_cells_test.py (deflated 90%)\n",
            "  adding: content/models/research/lstm_object_detection/lstm/rnn_decoder.py (deflated 71%)\n",
            "  adding: content/models/research/lstm_object_detection/lstm/lstm_cells.py (deflated 79%)\n",
            "  adding: content/models/research/lstm_object_detection/lstm/utils_test.py (deflated 82%)\n",
            "  adding: content/models/research/lstm_object_detection/lstm/utils.py (deflated 73%)\n",
            "  adding: content/models/research/lstm_object_detection/export_tflite_lstd_graph.py (deflated 64%)\n",
            "  adding: content/models/research/lstm_object_detection/g3doc/ (stored 0%)\n",
            "  adding: content/models/research/lstm_object_detection/g3doc/exporting_models.md (deflated 63%)\n",
            "  adding: content/models/research/lstm_object_detection/g3doc/Interleaved_Intro.png (deflated 1%)\n",
            "  adding: content/models/research/lstm_object_detection/g3doc/lstm_ssd_intro.png (deflated 1%)\n",
            "  adding: content/models/research/lstm_object_detection/model_builder.py (deflated 74%)\n",
            "  adding: content/models/research/lstm_object_detection/models/ (stored 0%)\n",
            "  adding: content/models/research/lstm_object_detection/models/lstm_ssd_interleaved_mobilenet_v2_feature_extractor_test.py (deflated 80%)\n",
            "  adding: content/models/research/lstm_object_detection/models/lstm_ssd_mobilenet_v1_feature_extractor.py (deflated 69%)\n",
            "  adding: content/models/research/lstm_object_detection/models/mobilenet_defs_test.py (deflated 79%)\n",
            "  adding: content/models/research/lstm_object_detection/models/__init__.py (stored 0%)\n",
            "  adding: content/models/research/lstm_object_detection/models/lstm_ssd_mobilenet_v1_feature_extractor_test.py (deflated 70%)\n",
            "  adding: content/models/research/lstm_object_detection/models/mobilenet_defs.py (deflated 72%)\n",
            "  adding: content/models/research/lstm_object_detection/models/lstm_ssd_interleaved_mobilenet_v2_feature_extractor.py (deflated 72%)\n",
            "  adding: content/models/research/lstm_object_detection/meta_architectures/ (stored 0%)\n",
            "  adding: content/models/research/lstm_object_detection/meta_architectures/__init__.py (stored 0%)\n",
            "  adding: content/models/research/lstm_object_detection/meta_architectures/lstm_ssd_meta_arch.py (deflated 74%)\n",
            "  adding: content/models/research/lstm_object_detection/meta_architectures/lstm_ssd_meta_arch_test.py (deflated 76%)\n",
            "  adding: content/models/research/lstm_object_detection/export_tflite_lstd_model.py (deflated 56%)\n",
            "  adding: content/models/research/lstm_object_detection/test_tflite_model.py (deflated 52%)\n",
            "  adding: content/models/research/lstm_object_detection/metrics/ (stored 0%)\n",
            "  adding: content/models/research/lstm_object_detection/metrics/__init__.py (stored 0%)\n",
            "  adding: content/models/research/lstm_object_detection/metrics/coco_evaluation_all_frames_test.py (deflated 82%)\n",
            "  adding: content/models/research/lstm_object_detection/metrics/coco_evaluation_all_frames.py (deflated 71%)\n",
            "  adding: content/models/research/lstm_object_detection/evaluator.py (deflated 71%)\n",
            "  adding: content/models/research/lstm_object_detection/configs/ (stored 0%)\n",
            "  adding: content/models/research/lstm_object_detection/configs/lstm_ssd_interleaved_mobilenet_v2_imagenet.config (deflated 67%)\n",
            "  adding: content/models/research/lstm_object_detection/configs/lstm_ssd_mobilenet_v1_imagenet.config (deflated 66%)\n",
            "  adding: content/models/research/object_detection/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/predictors/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/predictors/convolutional_keras_box_predictor.py (deflated 77%)\n",
            "  adding: content/models/research/object_detection/predictors/__pycache__/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/predictors/__pycache__/rfcn_keras_box_predictor.cpython-37.pyc (deflated 53%)\n",
            "  adding: content/models/research/object_detection/predictors/__pycache__/convolutional_keras_box_predictor.cpython-37.pyc (deflated 61%)\n",
            "  adding: content/models/research/object_detection/predictors/__pycache__/mask_rcnn_keras_box_predictor.cpython-37.pyc (deflated 55%)\n",
            "  adding: content/models/research/object_detection/predictors/__pycache__/rfcn_box_predictor.cpython-37.pyc (deflated 53%)\n",
            "  adding: content/models/research/object_detection/predictors/__pycache__/mask_rcnn_box_predictor.cpython-37.pyc (deflated 55%)\n",
            "  adding: content/models/research/object_detection/predictors/__pycache__/convolutional_box_predictor.cpython-37.pyc (deflated 61%)\n",
            "  adding: content/models/research/object_detection/predictors/__pycache__/__init__.cpython-37.pyc (deflated 21%)\n",
            "  adding: content/models/research/object_detection/predictors/heads/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/predictors/heads/keras_box_head.py (deflated 78%)\n",
            "  adding: content/models/research/object_detection/predictors/heads/keypoint_head_tf1_test.py (deflated 56%)\n",
            "  adding: content/models/research/object_detection/predictors/heads/__pycache__/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/predictors/heads/__pycache__/mask_head.cpython-37.pyc (deflated 63%)\n",
            "  adding: content/models/research/object_detection/predictors/heads/__pycache__/keras_mask_head.cpython-37.pyc (deflated 64%)\n",
            "  adding: content/models/research/object_detection/predictors/heads/__pycache__/keras_class_head.cpython-37.pyc (deflated 66%)\n",
            "  adding: content/models/research/object_detection/predictors/heads/__pycache__/box_head.cpython-37.pyc (deflated 61%)\n",
            "  adding: content/models/research/object_detection/predictors/heads/__pycache__/__init__.cpython-37.pyc (deflated 20%)\n",
            "  adding: content/models/research/object_detection/predictors/heads/__pycache__/class_head.cpython-37.pyc (deflated 64%)\n",
            "  adding: content/models/research/object_detection/predictors/heads/__pycache__/keras_box_head.cpython-37.pyc (deflated 64%)\n",
            "  adding: content/models/research/object_detection/predictors/heads/__pycache__/head.cpython-37.pyc (deflated 56%)\n",
            "  adding: content/models/research/object_detection/predictors/heads/keypoint_head.py (deflated 64%)\n",
            "  adding: content/models/research/object_detection/predictors/heads/box_head.py (deflated 75%)\n",
            "  adding: content/models/research/object_detection/predictors/heads/keras_mask_head_tf2_test.py (deflated 84%)\n",
            "  adding: content/models/research/object_detection/predictors/heads/keras_class_head.py (deflated 80%)\n",
            "  adding: content/models/research/object_detection/predictors/heads/box_head_tf1_test.py (deflated 73%)\n",
            "  adding: content/models/research/object_detection/predictors/heads/__init__.py (stored 0%)\n",
            "  adding: content/models/research/object_detection/predictors/heads/keras_class_head_tf2_test.py (deflated 82%)\n",
            "  adding: content/models/research/object_detection/predictors/heads/class_head.py (deflated 78%)\n",
            "  adding: content/models/research/object_detection/predictors/heads/head.py (deflated 57%)\n",
            "  adding: content/models/research/object_detection/predictors/heads/keras_box_head_tf2_test.py (deflated 81%)\n",
            "  adding: content/models/research/object_detection/predictors/heads/mask_head_tf1_test.py (deflated 80%)\n",
            "  adding: content/models/research/object_detection/predictors/heads/class_head_tf1_test.py (deflated 80%)\n",
            "  adding: content/models/research/object_detection/predictors/heads/keras_mask_head.py (deflated 78%)\n",
            "  adding: content/models/research/object_detection/predictors/heads/mask_head.py (deflated 76%)\n",
            "  adding: content/models/research/object_detection/predictors/mask_rcnn_keras_box_predictor_tf2_test.py (deflated 75%)\n",
            "  adding: content/models/research/object_detection/predictors/__init__.py (stored 0%)\n",
            "  adding: content/models/research/object_detection/predictors/mask_rcnn_keras_box_predictor.py (deflated 63%)\n",
            "  adding: content/models/research/object_detection/predictors/mask_rcnn_box_predictor_tf1_test.py (deflated 76%)\n",
            "  adding: content/models/research/object_detection/predictors/convolutional_box_predictor.py (deflated 76%)\n",
            "  adding: content/models/research/object_detection/predictors/rfcn_keras_box_predictor_tf2_test.py (deflated 60%)\n",
            "  adding: content/models/research/object_detection/predictors/rfcn_keras_box_predictor.py (deflated 70%)\n",
            "  adding: content/models/research/object_detection/predictors/convolutional_box_predictor_tf1_test.py (deflated 91%)\n",
            "  adding: content/models/research/object_detection/predictors/rfcn_box_predictor.py (deflated 68%)\n",
            "  adding: content/models/research/object_detection/predictors/mask_rcnn_box_predictor.py (deflated 65%)\n",
            "  adding: content/models/research/object_detection/predictors/rfcn_box_predictor_tf1_test.py (deflated 60%)\n",
            "  adding: content/models/research/object_detection/predictors/convolutional_keras_box_predictor_tf2_test.py (deflated 92%)\n",
            "  adding: content/models/research/object_detection/model_hparams.py (deflated 52%)\n",
            "  adding: content/models/research/object_detection/exporter.py (deflated 76%)\n",
            "  adding: content/models/research/object_detection/anchor_generators/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/anchor_generators/__pycache__/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/anchor_generators/__pycache__/multiple_grid_anchor_generator.cpython-37.pyc (deflated 63%)\n",
            "  adding: content/models/research/object_detection/anchor_generators/__pycache__/__init__.cpython-37.pyc (deflated 20%)\n",
            "  adding: content/models/research/object_detection/anchor_generators/__pycache__/flexible_grid_anchor_generator.cpython-37.pyc (deflated 59%)\n",
            "  adding: content/models/research/object_detection/anchor_generators/__pycache__/multiscale_grid_anchor_generator.cpython-37.pyc (deflated 54%)\n",
            "  adding: content/models/research/object_detection/anchor_generators/__pycache__/grid_anchor_generator.cpython-37.pyc (deflated 58%)\n",
            "  adding: content/models/research/object_detection/anchor_generators/multiscale_grid_anchor_generator_test.py (deflated 85%)\n",
            "  adding: content/models/research/object_detection/anchor_generators/__init__.py (stored 0%)\n",
            "  adding: content/models/research/object_detection/anchor_generators/grid_anchor_generator_test.py (deflated 74%)\n",
            "  adding: content/models/research/object_detection/anchor_generators/flexible_grid_anchor_generator.py (deflated 66%)\n",
            "  adding: content/models/research/object_detection/anchor_generators/multiscale_grid_anchor_generator.py (deflated 65%)\n",
            "  adding: content/models/research/object_detection/anchor_generators/multiple_grid_anchor_generator.py (deflated 73%)\n",
            "  adding: content/models/research/object_detection/anchor_generators/grid_anchor_generator.py (deflated 69%)\n",
            "  adding: content/models/research/object_detection/anchor_generators/flexible_grid_anchor_generator_test.py (deflated 85%)\n",
            "  adding: content/models/research/object_detection/anchor_generators/multiple_grid_anchor_generator_test.py (deflated 83%)\n",
            "  adding: content/models/research/object_detection/model_lib_tf1_test.py (deflated 83%)\n",
            "  adding: content/models/research/object_detection/inference/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/inference/infer_detections.py (deflated 61%)\n",
            "  adding: content/models/research/object_detection/inference/__init__.py (stored 0%)\n",
            "  adding: content/models/research/object_detection/inference/detection_inference_tf1_test.py (deflated 73%)\n",
            "  adding: content/models/research/object_detection/inference/detection_inference.py (deflated 71%)\n",
            "  adding: content/models/research/object_detection/utils/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/utils/context_manager_test.py (deflated 49%)\n",
            "  adding: content/models/research/object_detection/utils/np_box_list_ops.py (deflated 73%)\n",
            "  adding: content/models/research/object_detection/utils/dataset_util.py (deflated 59%)\n",
            "  adding: content/models/research/object_detection/utils/dataset_util_test.py (deflated 50%)\n",
            "  adding: content/models/research/object_detection/utils/static_shape_test.py (deflated 63%)\n",
            "  adding: content/models/research/object_detection/utils/test_case_test.py (deflated 67%)\n",
            "  adding: content/models/research/object_detection/utils/__pycache__/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/utils/__pycache__/np_mask_ops.cpython-37.pyc (deflated 65%)\n",
            "  adding: content/models/research/object_detection/utils/__pycache__/np_box_list_ops.cpython-37.pyc (deflated 59%)\n",
            "  adding: content/models/research/object_detection/utils/__pycache__/np_box_list.cpython-37.pyc (deflated 56%)\n",
            "  adding: content/models/research/object_detection/utils/__pycache__/target_assigner_utils.cpython-37.pyc (deflated 62%)\n",
            "  adding: content/models/research/object_detection/utils/__pycache__/spatial_transform_ops.cpython-37.pyc (deflated 66%)\n",
            "  adding: content/models/research/object_detection/utils/__pycache__/variables_helper.cpython-37.pyc (deflated 55%)\n",
            "  adding: content/models/research/object_detection/utils/__pycache__/label_map_util.cpython-37.pyc (deflated 59%)\n",
            "  adding: content/models/research/object_detection/utils/__pycache__/ops.cpython-37.pyc (deflated 62%)\n",
            "  adding: content/models/research/object_detection/utils/__pycache__/np_box_ops.cpython-37.pyc (deflated 58%)\n",
            "  adding: content/models/research/object_detection/utils/__pycache__/np_box_mask_list_ops.cpython-37.pyc (deflated 61%)\n",
            "  adding: content/models/research/object_detection/utils/__pycache__/tf_version.cpython-37.pyc (deflated 42%)\n",
            "  adding: content/models/research/object_detection/utils/__pycache__/learning_schedules.cpython-37.pyc (deflated 63%)\n",
            "  adding: content/models/research/object_detection/utils/__pycache__/context_manager.cpython-37.pyc (deflated 41%)\n",
            "  adding: content/models/research/object_detection/utils/__pycache__/visualization_utils.cpython-37.pyc (deflated 65%)\n",
            "  adding: content/models/research/object_detection/utils/__pycache__/config_util.cpython-37.pyc (deflated 68%)\n",
            "  adding: content/models/research/object_detection/utils/__pycache__/__init__.cpython-37.pyc (deflated 23%)\n",
            "  adding: content/models/research/object_detection/utils/__pycache__/object_detection_evaluation.cpython-37.pyc (deflated 71%)\n",
            "  adding: content/models/research/object_detection/utils/__pycache__/np_box_mask_list.cpython-37.pyc (deflated 49%)\n",
            "  adding: content/models/research/object_detection/utils/__pycache__/autoaugment_utils.cpython-37.pyc (deflated 67%)\n",
            "  adding: content/models/research/object_detection/utils/__pycache__/metrics.cpython-37.pyc (deflated 57%)\n",
            "  adding: content/models/research/object_detection/utils/__pycache__/json_utils.cpython-37.pyc (deflated 52%)\n",
            "  adding: content/models/research/object_detection/utils/__pycache__/shape_utils.cpython-37.pyc (deflated 63%)\n",
            "  adding: content/models/research/object_detection/utils/__pycache__/patch_ops.cpython-37.pyc (deflated 48%)\n",
            "  adding: content/models/research/object_detection/utils/__pycache__/per_image_evaluation.cpython-37.pyc (deflated 73%)\n",
            "  adding: content/models/research/object_detection/utils/__pycache__/static_shape.cpython-37.pyc (deflated 61%)\n",
            "  adding: content/models/research/object_detection/utils/__pycache__/test_case.cpython-37.pyc (deflated 69%)\n",
            "  adding: content/models/research/object_detection/utils/bifpn_utils.py (deflated 75%)\n",
            "  adding: content/models/research/object_detection/utils/tf_version.py (deflated 48%)\n",
            "  adding: content/models/research/object_detection/utils/np_box_list_test.py (deflated 76%)\n",
            "  adding: content/models/research/object_detection/utils/learning_schedules_test.py (deflated 80%)\n",
            "  adding: content/models/research/object_detection/utils/np_box_mask_list_test.py (deflated 81%)\n",
            "  adding: content/models/research/object_detection/utils/np_mask_ops.py (deflated 72%)\n",
            "  adding: content/models/research/object_detection/utils/np_box_list.py (deflated 64%)\n",
            "  adding: content/models/research/object_detection/utils/model_util_tf2_test.py (deflated 56%)\n",
            "  adding: content/models/research/object_detection/utils/patch_ops.py (deflated 60%)\n",
            "  adding: content/models/research/object_detection/utils/per_image_evaluation_test.py (deflated 92%)\n",
            "  adding: content/models/research/object_detection/utils/__init__.py (stored 0%)\n",
            "  adding: content/models/research/object_detection/utils/np_box_list_ops_test.py (deflated 85%)\n",
            "  adding: content/models/research/object_detection/utils/per_image_vrd_evaluation_test.py (deflated 72%)\n",
            "  adding: content/models/research/object_detection/utils/colab_utils.py (deflated 76%)\n",
            "  adding: content/models/research/object_detection/utils/patch_ops_test.py (deflated 76%)\n",
            "  adding: content/models/research/object_detection/utils/np_box_mask_list_ops.py (deflated 73%)\n",
            "  adding: content/models/research/object_detection/utils/np_box_ops.py (deflated 67%)\n",
            "  adding: content/models/research/object_detection/utils/variables_helper.py (deflated 67%)\n",
            "  adding: content/models/research/object_detection/utils/model_util.py (deflated 64%)\n",
            "  adding: content/models/research/object_detection/utils/vrd_evaluation_test.py (deflated 86%)\n",
            "  adding: content/models/research/object_detection/utils/spatial_transform_ops_test.py (deflated 87%)\n",
            "  adding: content/models/research/object_detection/utils/visualization_utils.py (deflated 79%)\n",
            "  adding: content/models/research/object_detection/utils/context_manager.py (deflated 48%)\n",
            "  adding: content/models/research/object_detection/utils/autoaugment_utils.py (deflated 77%)\n",
            "  adding: content/models/research/object_detection/utils/test_utils_test.py (deflated 66%)\n",
            "  adding: content/models/research/object_detection/utils/shape_utils_test.py (deflated 83%)\n",
            "  adding: content/models/research/object_detection/utils/category_util.py (deflated 56%)\n",
            "  adding: content/models/research/object_detection/utils/label_map_util.py (deflated 73%)\n",
            "  adding: content/models/research/object_detection/utils/category_util_test.py (deflated 59%)\n",
            "  adding: content/models/research/object_detection/utils/shape_utils.py (deflated 71%)\n",
            "  adding: content/models/research/object_detection/utils/np_box_ops_test.py (deflated 65%)\n",
            "  adding: content/models/research/object_detection/utils/vrd_evaluation.py (deflated 81%)\n",
            "  adding: content/models/research/object_detection/utils/np_mask_ops_test.py (deflated 74%)\n",
            "  adding: content/models/research/object_detection/utils/np_box_mask_list_ops_test.py (deflated 79%)\n",
            "  adding: content/models/research/object_detection/utils/metrics.py (deflated 69%)\n",
            "  adding: content/models/research/object_detection/utils/config_util.py (deflated 81%)\n",
            "  adding: content/models/research/object_detection/utils/target_assigner_utils_test.py (deflated 79%)\n",
            "  adding: content/models/research/object_detection/utils/spatial_transform_ops.py (deflated 76%)\n",
            "  adding: content/models/research/object_detection/utils/visualization_utils_test.py (deflated 81%)\n",
            "  adding: content/models/research/object_detection/utils/json_utils_test.py (deflated 73%)\n",
            "  adding: content/models/research/object_detection/utils/json_utils.py (deflated 60%)\n",
            "  adding: content/models/research/object_detection/utils/np_box_mask_list.py (deflated 57%)\n",
            "  adding: content/models/research/object_detection/utils/ops_test.py (deflated 87%)\n",
            "  adding: content/models/research/object_detection/utils/variables_helper_tf1_test.py (deflated 82%)\n",
            "  adding: content/models/research/object_detection/utils/per_image_evaluation.py (deflated 84%)\n",
            "  adding: content/models/research/object_detection/utils/metrics_test.py (deflated 77%)\n",
            "  adding: content/models/research/object_detection/utils/config_util_test.py (deflated 88%)\n",
            "  adding: content/models/research/object_detection/utils/learning_schedules.py (deflated 76%)\n",
            "  adding: content/models/research/object_detection/utils/object_detection_evaluation_test.py (deflated 89%)\n",
            "  adding: content/models/research/object_detection/utils/test_utils.py (deflated 69%)\n",
            "  adding: content/models/research/object_detection/utils/test_case.py (deflated 80%)\n",
            "  adding: content/models/research/object_detection/utils/target_assigner_utils.py (deflated 73%)\n",
            "  adding: content/models/research/object_detection/utils/label_map_util_test.py (deflated 84%)\n",
            "  adding: content/models/research/object_detection/utils/per_image_vrd_evaluation.py (deflated 78%)\n",
            "  adding: content/models/research/object_detection/utils/ops.py (deflated 74%)\n",
            "  adding: content/models/research/object_detection/utils/object_detection_evaluation.py (deflated 83%)\n",
            "  adding: content/models/research/object_detection/utils/static_shape.py (deflated 66%)\n",
            "  adding: content/models/research/object_detection/__pycache__/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/__pycache__/exporter.cpython-37.pyc (deflated 57%)\n",
            "  adding: content/models/research/object_detection/__pycache__/inputs.cpython-37.pyc (deflated 65%)\n",
            "  adding: content/models/research/object_detection/__pycache__/model_lib.cpython-37.pyc (deflated 60%)\n",
            "  adding: content/models/research/object_detection/__pycache__/__init__.cpython-37.pyc (deflated 23%)\n",
            "  adding: content/models/research/object_detection/__pycache__/eval_util.cpython-37.pyc (deflated 65%)\n",
            "  adding: content/models/research/object_detection/__pycache__/export_tflite_ssd_graph_lib.cpython-37.pyc (deflated 55%)\n",
            "  adding: content/models/research/object_detection/builders/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/builders/target_assigner_builder.py (deflated 60%)\n",
            "  adding: content/models/research/object_detection/builders/optimizer_builder_tf2_test.py (deflated 71%)\n",
            "  adding: content/models/research/object_detection/builders/preprocessor_builder.py (deflated 81%)\n",
            "  adding: content/models/research/object_detection/builders/graph_rewriter_builder_tf1_test.py (deflated 66%)\n",
            "  adding: content/models/research/object_detection/builders/post_processing_builder_test.py (deflated 82%)\n",
            "  adding: content/models/research/object_detection/builders/preprocessor_builder_test.py (deflated 89%)\n",
            "  adding: content/models/research/object_detection/builders/dataset_builder_test.py (deflated 82%)\n",
            "  adding: content/models/research/object_detection/builders/decoder_builder.py (deflated 67%)\n",
            "  adding: content/models/research/object_detection/builders/__pycache__/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/builders/__pycache__/anchor_generator_builder.cpython-37.pyc (deflated 53%)\n",
            "  adding: content/models/research/object_detection/builders/__pycache__/box_coder_builder.cpython-37.pyc (deflated 47%)\n",
            "  adding: content/models/research/object_detection/builders/__pycache__/image_resizer_builder.cpython-37.pyc (deflated 54%)\n",
            "  adding: content/models/research/object_detection/builders/__pycache__/calibration_builder.cpython-37.pyc (deflated 60%)\n",
            "  adding: content/models/research/object_detection/builders/__pycache__/dataset_builder.cpython-37.pyc (deflated 56%)\n",
            "  adding: content/models/research/object_detection/builders/__pycache__/__init__.cpython-37.pyc (deflated 21%)\n",
            "  adding: content/models/research/object_detection/builders/__pycache__/model_builder.cpython-37.pyc (deflated 63%)\n",
            "  adding: content/models/research/object_detection/builders/__pycache__/graph_rewriter_builder.cpython-37.pyc (deflated 41%)\n",
            "  adding: content/models/research/object_detection/builders/__pycache__/box_predictor_builder.cpython-37.pyc (deflated 76%)\n",
            "  adding: content/models/research/object_detection/builders/__pycache__/losses_builder.cpython-37.pyc (deflated 61%)\n",
            "  adding: content/models/research/object_detection/builders/__pycache__/matcher_builder.cpython-37.pyc (deflated 43%)\n",
            "  adding: content/models/research/object_detection/builders/__pycache__/hyperparams_builder.cpython-37.pyc (deflated 63%)\n",
            "  adding: content/models/research/object_detection/builders/__pycache__/region_similarity_calculator_builder.cpython-37.pyc (deflated 56%)\n",
            "  adding: content/models/research/object_detection/builders/__pycache__/preprocessor_builder.cpython-37.pyc (deflated 63%)\n",
            "  adding: content/models/research/object_detection/builders/__pycache__/optimizer_builder.cpython-37.pyc (deflated 58%)\n",
            "  adding: content/models/research/object_detection/builders/__pycache__/decoder_builder.cpython-37.pyc (deflated 45%)\n",
            "  adding: content/models/research/object_detection/builders/__pycache__/post_processing_builder.cpython-37.pyc (deflated 59%)\n",
            "  adding: content/models/research/object_detection/builders/target_assigner_builder_test.py (deflated 56%)\n",
            "  adding: content/models/research/object_detection/builders/box_coder_builder_test.py (deflated 80%)\n",
            "  adding: content/models/research/object_detection/builders/image_resizer_builder.py (deflated 73%)\n",
            "  adding: content/models/research/object_detection/builders/model_builder_tf2_test.py (deflated 81%)\n",
            "  adding: content/models/research/object_detection/builders/__init__.py (stored 0%)\n",
            "  adding: content/models/research/object_detection/builders/optimizer_builder_tf1_test.py (deflated 79%)\n",
            "  adding: content/models/research/object_detection/builders/post_processing_builder.py (deflated 70%)\n",
            "  adding: content/models/research/object_detection/builders/graph_rewriter_builder.py (deflated 55%)\n",
            "  adding: content/models/research/object_detection/builders/dataset_builder.py (deflated 71%)\n",
            "  adding: content/models/research/object_detection/builders/matcher_builder.py (deflated 61%)\n",
            "  adding: content/models/research/object_detection/builders/hyperparams_builder.py (deflated 75%)\n",
            "  adding: content/models/research/object_detection/builders/box_predictor_builder.py (deflated 88%)\n",
            "  adding: content/models/research/object_detection/builders/hyperparams_builder_test.py (deflated 92%)\n",
            "  adding: content/models/research/object_detection/builders/input_reader_builder_tf1_test.py (deflated 80%)\n",
            "  adding: content/models/research/object_detection/builders/model_builder_test.py (deflated 80%)\n",
            "  adding: content/models/research/object_detection/builders/box_coder_builder.py (deflated 69%)\n",
            "  adding: content/models/research/object_detection/builders/image_resizer_builder_test.py (deflated 82%)\n",
            "  adding: content/models/research/object_detection/builders/box_predictor_builder_test.py (deflated 90%)\n",
            "  adding: content/models/research/object_detection/builders/calibration_builder_test.py (deflated 78%)\n",
            "  adding: content/models/research/object_detection/builders/losses_builder_test.py (deflated 90%)\n",
            "  adding: content/models/research/object_detection/builders/model_builder_tf1_test.py (deflated 57%)\n",
            "  adding: content/models/research/object_detection/builders/anchor_generator_builder_test.py (deflated 85%)\n",
            "  adding: content/models/research/object_detection/builders/input_reader_builder.py (deflated 65%)\n",
            "  adding: content/models/research/object_detection/builders/anchor_generator_builder.py (deflated 75%)\n",
            "  adding: content/models/research/object_detection/builders/decoder_builder_test.py (deflated 75%)\n",
            "  adding: content/models/research/object_detection/builders/matcher_builder_test.py (deflated 74%)\n",
            "  adding: content/models/research/object_detection/builders/model_builder.py (deflated 83%)\n",
            "  adding: content/models/research/object_detection/builders/losses_builder.py (deflated 79%)\n",
            "  adding: content/models/research/object_detection/builders/region_similarity_calculator_builder.py (deflated 67%)\n",
            "  adding: content/models/research/object_detection/builders/optimizer_builder.py (deflated 79%)\n",
            "  adding: content/models/research/object_detection/builders/region_similarity_calculator_builder_test.py (deflated 72%)\n",
            "  adding: content/models/research/object_detection/builders/calibration_builder.py (deflated 73%)\n",
            "  adding: content/models/research/object_detection/README.md (deflated 56%)\n",
            "  adding: content/models/research/object_detection/model_main_tf2.py (deflated 63%)\n",
            "  adding: content/models/research/object_detection/box_coders/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/box_coders/keypoint_box_coder.py (deflated 68%)\n",
            "  adding: content/models/research/object_detection/box_coders/keypoint_box_coder_test.py (deflated 80%)\n",
            "  adding: content/models/research/object_detection/box_coders/__pycache__/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/box_coders/__pycache__/mean_stddev_box_coder.cpython-37.pyc (deflated 55%)\n",
            "  adding: content/models/research/object_detection/box_coders/__pycache__/__init__.cpython-37.pyc (deflated 22%)\n",
            "  adding: content/models/research/object_detection/box_coders/__pycache__/faster_rcnn_box_coder.cpython-37.pyc (deflated 49%)\n",
            "  adding: content/models/research/object_detection/box_coders/__pycache__/keypoint_box_coder.cpython-37.pyc (deflated 52%)\n",
            "  adding: content/models/research/object_detection/box_coders/__pycache__/square_box_coder.cpython-37.pyc (deflated 49%)\n",
            "  adding: content/models/research/object_detection/box_coders/faster_rcnn_box_coder_test.py (deflated 77%)\n",
            "  adding: content/models/research/object_detection/box_coders/faster_rcnn_box_coder.py (deflated 61%)\n",
            "  adding: content/models/research/object_detection/box_coders/__init__.py (stored 0%)\n",
            "  adding: content/models/research/object_detection/box_coders/mean_stddev_box_coder_test.py (deflated 64%)\n",
            "  adding: content/models/research/object_detection/box_coders/square_box_coder_test.py (deflated 76%)\n",
            "  adding: content/models/research/object_detection/box_coders/square_box_coder.py (deflated 61%)\n",
            "  adding: content/models/research/object_detection/box_coders/mean_stddev_box_coder.py (deflated 62%)\n",
            "  adding: content/models/research/object_detection/tpu_exporters/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/tpu_exporters/__init__.py (stored 0%)\n",
            "  adding: content/models/research/object_detection/tpu_exporters/export_saved_model_tpu_lib.py (deflated 73%)\n",
            "  adding: content/models/research/object_detection/tpu_exporters/faster_rcnn.py (deflated 69%)\n",
            "  adding: content/models/research/object_detection/tpu_exporters/utils_test.py (deflated 58%)\n",
            "  adding: content/models/research/object_detection/tpu_exporters/utils.py (deflated 54%)\n",
            "  adding: content/models/research/object_detection/tpu_exporters/testdata/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/tpu_exporters/testdata/faster_rcnn/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/tpu_exporters/testdata/faster_rcnn/faster_rcnn_resnet101_atrous_coco.config (deflated 64%)\n",
            "  adding: content/models/research/object_detection/tpu_exporters/testdata/__init__.py (stored 0%)\n",
            "  adding: content/models/research/object_detection/tpu_exporters/testdata/ssd/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/tpu_exporters/testdata/ssd/ssd_pipeline.config (deflated 68%)\n",
            "  adding: content/models/research/object_detection/tpu_exporters/export_saved_model_tpu.py (deflated 56%)\n",
            "  adding: content/models/research/object_detection/tpu_exporters/ssd.py (deflated 70%)\n",
            "  adding: content/models/research/object_detection/tpu_exporters/export_saved_model_tpu_lib_tf1_test.py (deflated 56%)\n",
            "  adding: content/models/research/object_detection/exporter_lib_tf2_test.py (deflated 80%)\n",
            "  adding: content/models/research/object_detection/export_tflite_ssd_graph_lib.py (deflated 72%)\n",
            "  adding: content/models/research/object_detection/CONTRIBUTING.md (deflated 48%)\n",
            "  adding: content/models/research/object_detection/__init__.py (stored 0%)\n",
            "  adding: content/models/research/object_detection/export_tflite_ssd_graph.py (deflated 64%)\n",
            "  adding: content/models/research/object_detection/matchers/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/matchers/argmax_matcher_test.py (deflated 87%)\n",
            "  adding: content/models/research/object_detection/matchers/bipartite_matcher.py (deflated 58%)\n",
            "  adding: content/models/research/object_detection/matchers/__pycache__/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/matchers/__pycache__/bipartite_matcher.cpython-37.pyc (deflated 46%)\n",
            "  adding: content/models/research/object_detection/matchers/__pycache__/argmax_matcher.cpython-37.pyc (deflated 57%)\n",
            "  adding: content/models/research/object_detection/matchers/__pycache__/hungarian_matcher.cpython-37.pyc (deflated 46%)\n",
            "  adding: content/models/research/object_detection/matchers/__pycache__/__init__.cpython-37.pyc (deflated 21%)\n",
            "  adding: content/models/research/object_detection/matchers/argmax_matcher.py (deflated 71%)\n",
            "  adding: content/models/research/object_detection/matchers/hungarian_matcher_tf2_test.py (deflated 77%)\n",
            "  adding: content/models/research/object_detection/matchers/__init__.py (stored 0%)\n",
            "  adding: content/models/research/object_detection/matchers/bipartite_matcher_tf1_test.py (deflated 77%)\n",
            "  adding: content/models/research/object_detection/matchers/hungarian_matcher.py (deflated 55%)\n",
            "  adding: content/models/research/object_detection/eval_util.py (deflated 78%)\n",
            "  adding: content/models/research/object_detection/exporter_main_v2.py (deflated 68%)\n",
            "  adding: content/models/research/object_detection/export_tflite_graph_tf2.py (deflated 65%)\n",
            "  adding: content/models/research/object_detection/protos/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/protos/pipeline_pb2.py (deflated 79%)\n",
            "  adding: content/models/research/object_detection/protos/grid_anchor_generator.proto (deflated 63%)\n",
            "  adding: content/models/research/object_detection/protos/center_net_pb2.py (deflated 91%)\n",
            "  adding: content/models/research/object_detection/protos/box_coder.proto (deflated 60%)\n",
            "  adding: content/models/research/object_detection/protos/ssd_anchor_generator_pb2.py (deflated 82%)\n",
            "  adding: content/models/research/object_detection/protos/string_int_label_map.proto (deflated 53%)\n",
            "  adding: content/models/research/object_detection/protos/target_assigner_pb2.py (deflated 74%)\n",
            "  adding: content/models/research/object_detection/protos/losses_pb2.py (deflated 90%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/flexible_grid_anchor_generator_pb2.cpython-37.pyc (deflated 58%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/square_box_coder_pb2.cpython-37.pyc (deflated 50%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/losses_pb2.cpython-37.pyc (deflated 74%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/post_processing_pb2.cpython-37.pyc (deflated 63%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/image_resizer_pb2.cpython-37.pyc (deflated 68%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/fpn_pb2.cpython-37.pyc (deflated 59%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/argmax_matcher_pb2.cpython-37.pyc (deflated 55%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/box_predictor_pb2.cpython-37.pyc (deflated 75%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/region_similarity_calculator_pb2.cpython-37.pyc (deflated 62%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/multiscale_anchor_generator_pb2.cpython-37.pyc (deflated 55%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/center_net_pb2.cpython-37.pyc (deflated 76%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/anchor_generator_pb2.cpython-37.pyc (deflated 62%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/model_pb2.cpython-37.pyc (deflated 57%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/hyperparams_pb2.cpython-37.pyc (deflated 69%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/keypoint_box_coder_pb2.cpython-37.pyc (deflated 53%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/ssd_anchor_generator_pb2.cpython-37.pyc (deflated 61%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/optimizer_pb2.cpython-37.pyc (deflated 72%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/train_pb2.cpython-37.pyc (deflated 66%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/box_coder_pb2.cpython-37.pyc (deflated 59%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/__init__.cpython-37.pyc (deflated 22%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/bipartite_matcher_pb2.cpython-37.pyc (deflated 47%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/faster_rcnn_box_coder_pb2.cpython-37.pyc (deflated 53%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/graph_rewriter_pb2.cpython-37.pyc (deflated 52%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/ssd_pb2.cpython-37.pyc (deflated 69%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/matcher_pb2.cpython-37.pyc (deflated 53%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/faster_rcnn_pb2.cpython-37.pyc (deflated 71%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/eval_pb2.cpython-37.pyc (deflated 69%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/input_reader_pb2.cpython-37.pyc (deflated 67%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/string_int_label_map_pb2.cpython-37.pyc (deflated 60%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/grid_anchor_generator_pb2.cpython-37.pyc (deflated 58%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/mean_stddev_box_coder_pb2.cpython-37.pyc (deflated 46%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/pipeline_pb2.cpython-37.pyc (deflated 59%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/calibration_pb2.cpython-37.pyc (deflated 69%)\n",
            "  adding: content/models/research/object_detection/protos/__pycache__/preprocessor_pb2.cpython-37.pyc (deflated 78%)\n",
            "  adding: content/models/research/object_detection/protos/target_assigner.proto (deflated 52%)\n",
            "  adding: content/models/research/object_detection/protos/mean_stddev_box_coder_pb2.py (deflated 63%)\n",
            "  adding: content/models/research/object_detection/protos/flexible_grid_anchor_generator.proto (deflated 60%)\n",
            "  adding: content/models/research/object_detection/protos/fpn.proto (deflated 67%)\n",
            "  adding: content/models/research/object_detection/protos/string_int_label_map_pb2.py (deflated 83%)\n",
            "  adding: content/models/research/object_detection/protos/faster_rcnn_pb2.py (deflated 88%)\n",
            "  adding: content/models/research/object_detection/protos/matcher.proto (deflated 49%)\n",
            "  adding: content/models/research/object_detection/protos/train.proto (deflated 64%)\n",
            "  adding: content/models/research/object_detection/protos/model_pb2.py (deflated 80%)\n",
            "  adding: content/models/research/object_detection/protos/__init__.py (stored 0%)\n",
            "  adding: content/models/research/object_detection/protos/eval_pb2.py (deflated 88%)\n",
            "  adding: content/models/research/object_detection/protos/multiscale_anchor_generator.proto (deflated 50%)\n",
            "  adding: content/models/research/object_detection/protos/mean_stddev_box_coder.proto (deflated 32%)\n",
            "  adding: content/models/research/object_detection/protos/post_processing_pb2.py (deflated 84%)\n",
            "  adding: content/models/research/object_detection/protos/ssd.proto (deflated 67%)\n",
            "  adding: content/models/research/object_detection/protos/anchor_generator.proto (deflated 65%)\n",
            "  adding: content/models/research/object_detection/protos/bipartite_matcher.proto (deflated 37%)\n",
            "  adding: content/models/research/object_detection/protos/eval.proto (deflated 65%)\n",
            "  adding: content/models/research/object_detection/protos/flexible_grid_anchor_generator_pb2.py (deflated 80%)\n",
            "  adding: content/models/research/object_detection/protos/graph_rewriter.proto (deflated 56%)\n",
            "  adding: content/models/research/object_detection/protos/argmax_matcher.proto (deflated 59%)\n",
            "  adding: content/models/research/object_detection/protos/losses.proto (deflated 70%)\n",
            "  adding: content/models/research/object_detection/protos/fpn_pb2.py (deflated 81%)\n",
            "  adding: content/models/research/object_detection/protos/box_predictor.proto (deflated 74%)\n",
            "  adding: content/models/research/object_detection/protos/matcher_pb2.py (deflated 73%)\n",
            "  adding: content/models/research/object_detection/protos/square_box_coder.proto (deflated 49%)\n",
            "  adding: content/models/research/object_detection/protos/multiscale_anchor_generator_pb2.py (deflated 76%)\n",
            "  adding: content/models/research/object_detection/protos/box_predictor_pb2.py (deflated 90%)\n",
            "  adding: content/models/research/object_detection/protos/image_resizer.proto (deflated 69%)\n",
            "  adding: content/models/research/object_detection/protos/model.proto (deflated 49%)\n",
            "  adding: content/models/research/object_detection/protos/input_reader.proto (deflated 65%)\n",
            "  adding: content/models/research/object_detection/protos/argmax_matcher_pb2.py (deflated 76%)\n",
            "  adding: content/models/research/object_detection/protos/graph_rewriter_pb2.py (deflated 76%)\n",
            "  adding: content/models/research/object_detection/protos/hyperparams_pb2.py (deflated 89%)\n",
            "  adding: content/models/research/object_detection/protos/pipeline.proto (deflated 57%)\n",
            "  adding: content/models/research/object_detection/protos/preprocessor.proto (deflated 78%)\n",
            "  adding: content/models/research/object_detection/protos/faster_rcnn_box_coder.proto (deflated 55%)\n",
            "  adding: content/models/research/object_detection/protos/ssd_pb2.py (deflated 88%)\n",
            "  adding: content/models/research/object_detection/protos/grid_anchor_generator_pb2.py (deflated 79%)\n",
            "  adding: content/models/research/object_detection/protos/calibration_pb2.py (deflated 88%)\n",
            "  adding: content/models/research/object_detection/protos/image_resizer_pb2.py (deflated 87%)\n",
            "  adding: content/models/research/object_detection/protos/region_similarity_calculator.proto (deflated 63%)\n",
            "  adding: content/models/research/object_detection/protos/faster_rcnn.proto (deflated 69%)\n",
            "  adding: content/models/research/object_detection/protos/faster_rcnn_box_coder_pb2.py (deflated 74%)\n",
            "  adding: content/models/research/object_detection/protos/optimizer.proto (deflated 73%)\n",
            "  adding: content/models/research/object_detection/protos/ssd_anchor_generator.proto (deflated 66%)\n",
            "  adding: content/models/research/object_detection/protos/region_similarity_calculator_pb2.py (deflated 85%)\n",
            "  adding: content/models/research/object_detection/protos/keypoint_box_coder_pb2.py (deflated 75%)\n",
            "  adding: content/models/research/object_detection/protos/center_net.proto (deflated 73%)\n",
            "  adding: content/models/research/object_detection/protos/keypoint_box_coder.proto (deflated 56%)\n",
            "  adding: content/models/research/object_detection/protos/box_coder_pb2.py (deflated 79%)\n",
            "  adding: content/models/research/object_detection/protos/optimizer_pb2.py (deflated 90%)\n",
            "  adding: content/models/research/object_detection/protos/calibration.proto (deflated 67%)\n",
            "  adding: content/models/research/object_detection/protos/input_reader_pb2.py (deflated 87%)\n",
            "  adding: content/models/research/object_detection/protos/hyperparams.proto (deflated 68%)\n",
            "  adding: content/models/research/object_detection/protos/post_processing.proto (deflated 61%)\n",
            "  adding: content/models/research/object_detection/protos/preprocessor_pb2.py (deflated 92%)\n",
            "  adding: content/models/research/object_detection/protos/train_pb2.py (deflated 85%)\n",
            "  adding: content/models/research/object_detection/protos/bipartite_matcher_pb2.py (deflated 63%)\n",
            "  adding: content/models/research/object_detection/protos/square_box_coder_pb2.py (deflated 71%)\n",
            "  adding: content/models/research/object_detection/protos/anchor_generator_pb2.py (deflated 81%)\n",
            "  adding: content/models/research/object_detection/samples/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/samples/cloud/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/samples/cloud/cloud.yml (deflated 36%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssd_inception_v2_pets.config (deflated 66%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssdlite_mobiledet_edgetpu_320x320_coco_sync_4x4.config (deflated 66%)\n",
            "  adding: content/models/research/object_detection/samples/configs/faster_rcnn_resnet101_fgvc.config (deflated 66%)\n",
            "  adding: content/models/research/object_detection/samples/configs/faster_rcnn_resnet101_kitti.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/samples/configs/faster_rcnn_resnet50_coco.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/samples/configs/rfcn_resnet101_coco.config (deflated 66%)\n",
            "  adding: content/models/research/object_detection/samples/configs/faster_rcnn_resnet101_voc07.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssd_inception_v3_pets.config (deflated 66%)\n",
            "  adding: content/models/research/object_detection/samples/configs/faster_rcnn_resnet101_coco.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssdlite_mobilenet_edgetpu_320x320_coco_quant.config (deflated 66%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssd_inception_v2_coco.config (deflated 66%)\n",
            "  adding: content/models/research/object_detection/samples/configs/embedded_ssd_mobilenet_v1_coco.config (deflated 68%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config (deflated 67%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssd_mobilenet_v1_coco.config (deflated 67%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssdlite_mobilenet_v2_coco.config (deflated 67%)\n",
            "  adding: content/models/research/object_detection/samples/configs/mask_rcnn_resnet101_pets.config (deflated 66%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssd_mobilenet_v1_300x300_coco14_sync.config (deflated 67%)\n",
            "  adding: content/models/research/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_cosine_lr_coco.config (deflated 64%)\n",
            "  adding: content/models/research/object_detection/samples/configs/faster_rcnn_resnet101_ava_v2.1.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/samples/configs/faster_rcnn_resnet50_fgvc.config (deflated 66%)\n",
            "  adding: content/models/research/object_detection/samples/configs/context_rcnn_resnet101_snapshot_serengeti.config (deflated 66%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_quantized_300x300_coco14_sync.config (deflated 66%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssd_resnet101_v1_fpn_shared_box_predictor_oid_512x512_sync.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync.config (deflated 64%)\n",
            "  adding: content/models/research/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_pets.config (deflated 64%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssdlite_mobilenet_v1_coco.config (deflated 67%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssdlite_mobilenet_v3_large_320x320_coco.config (deflated 67%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssdlite_mobiledet_cpu_320x320_coco_sync_4x4.config (deflated 66%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssdlite_mobiledet_dsp_320x320_coco_sync_4x4.config (deflated 66%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssd_mobilenet_v2_fpnlite_quantized_shared_box_predictor_256x256_depthmultiplier_75_coco14_sync.config (deflated 66%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_quantized_300x300_pets_sync.config (deflated 67%)\n",
            "  adding: content/models/research/object_detection/samples/configs/mask_rcnn_resnet50_atrous_coco.config (deflated 67%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssdlite_mobiledet_gpu_320x320_coco_sync_4x4.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/samples/configs/faster_rcnn_resnet50_pets.config (deflated 64%)\n",
            "  adding: content/models/research/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_oid.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssd_mobilenet_v1_pets.config (deflated 67%)\n",
            "  adding: content/models/research/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_oid_v4.config (deflated 66%)\n",
            "  adding: content/models/research/object_detection/samples/configs/faster_rcnn_nas_coco.config (deflated 64%)\n",
            "  adding: content/models/research/object_detection/samples/configs/faster_rcnn_resnet101_atrous_coco.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/samples/configs/mask_rcnn_inception_resnet_v2_atrous_coco.config (deflated 67%)\n",
            "  adding: content/models/research/object_detection/samples/configs/faster_rcnn_inception_v2_pets.config (deflated 64%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssd_mobilenet_v2_pets_keras.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssd_mobilenet_v2_fullyconv_coco.config (deflated 68%)\n",
            "  adding: content/models/research/object_detection/samples/configs/faster_rcnn_resnet101_pets.config (deflated 64%)\n",
            "  adding: content/models/research/object_detection/samples/configs/mask_rcnn_resnet101_atrous_coco.config (deflated 67%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssdlite_mobilenet_v3_small_320x320_coco.config (deflated 67%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssd_mobilenet_v1_focal_loss_pets_inference.config (deflated 66%)\n",
            "  adding: content/models/research/object_detection/samples/configs/faster_rcnn_inception_v2_coco.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/samples/configs/facessd_mobilenet_v2_quantized_320x320_open_image_v4.config (deflated 69%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssd_mobilenet_v2_oid_v4.config (deflated 68%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssd_mobilenet_v1_focal_loss_pets.config (deflated 66%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssd_mobilenet_v2_quantized_300x300_coco.config (deflated 67%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssd_mobilenet_v2_mnasfpn_shared_box_predictor_320x320_coco_sync.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/samples/configs/mask_rcnn_inception_v2_coco.config (deflated 67%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync.config (deflated 67%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_300x300_coco14_sync.config (deflated 66%)\n",
            "  adding: content/models/research/object_detection/samples/configs/rfcn_resnet101_pets.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/samples/configs/context_rcnn_resnet101_snapshot_serengeti_sync.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssd_mobilenet_v1_quantized_300x300_coco14_sync.config (deflated 67%)\n",
            "  adding: content/models/research/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_coco.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/samples/configs/faster_rcnn_resnet152_coco.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/samples/configs/faster_rcnn_resnet152_pets.config (deflated 64%)\n",
            "  adding: content/models/research/object_detection/samples/configs/ssdlite_mobilenet_edgetpu_320x320_coco.config (deflated 67%)\n",
            "  adding: content/models/research/object_detection/test_images/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/test_images/image3.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/image1.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/snapshot_serengeti/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/test_images/snapshot_serengeti/context_rcnn_demo_metadata.json (deflated 71%)\n",
            "  adding: content/models/research/object_detection/test_images/snapshot_serengeti/README.md (deflated 39%)\n",
            "  adding: content/models/research/object_detection/test_images/snapshot_serengeti/S1_E03_R3_PICT0041.jpeg (deflated 43%)\n",
            "  adding: content/models/research/object_detection/test_images/snapshot_serengeti/S1_E03_R3_PICT0040.jpeg (deflated 44%)\n",
            "  adding: content/models/research/object_detection/test_images/snapshot_serengeti/S1_E03_R3_PICT0038.jpeg (deflated 44%)\n",
            "  adding: content/models/research/object_detection/test_images/snapshot_serengeti/S1_E03_R3_PICT0039.jpeg (deflated 44%)\n",
            "  adding: content/models/research/object_detection/test_images/image_info.txt (deflated 29%)\n",
            "  adding: content/models/research/object_detection/test_images/image2.jpg (deflated 1%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/train/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/train/robertducky5.jpg (deflated 1%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/train/robertducky3.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/train/robertducky2.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/train/robertducky4.jpg (deflated 1%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/train/robertducky1.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out34.jpg (deflated 1%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out16.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out8.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out49.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out14.jpg (deflated 1%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out42.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out43.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out10.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out22.jpg (deflated 1%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out24.jpg (deflated 1%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out13.jpg (deflated 1%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out36.jpg (deflated 1%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out26.jpg (deflated 1%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out27.jpg (deflated 1%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out3.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out28.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out1.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out9.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out41.jpg (deflated 1%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out40.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out30.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out5.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out20.jpg (deflated 1%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out21.jpg (deflated 1%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out4.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out15.jpg (deflated 1%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out6.jpg (deflated 1%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out35.jpg (deflated 1%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out7.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out46.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out18.jpg (deflated 1%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out2.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out17.jpg (deflated 1%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out48.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out39.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out44.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out29.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out12.jpg (deflated 1%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out32.jpg (deflated 1%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out33.jpg (deflated 1%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out47.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out25.jpg (deflated 1%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out31.jpg (deflated 1%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out23.jpg (deflated 1%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out37.jpg (deflated 1%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out19.jpg (deflated 1%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out45.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out38.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/test_images/ducky/test/out11.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/exporter_lib_v2.py (deflated 74%)\n",
            "  adding: content/models/research/object_detection/dockerfiles/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/dockerfiles/tf2/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/dockerfiles/tf2/README.md (deflated 30%)\n",
            "  adding: content/models/research/object_detection/dockerfiles/tf2/Dockerfile (deflated 50%)\n",
            "  adding: content/models/research/object_detection/dockerfiles/android/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/dockerfiles/android/README.md (deflated 55%)\n",
            "  adding: content/models/research/object_detection/dockerfiles/android/Dockerfile (deflated 61%)\n",
            "  adding: content/models/research/object_detection/dockerfiles/tf1/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/dockerfiles/tf1/README.md (deflated 30%)\n",
            "  adding: content/models/research/object_detection/dockerfiles/tf1/Dockerfile (deflated 50%)\n",
            "  adding: content/models/research/object_detection/dockerfiles/tf2_ai_platform/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/dockerfiles/tf2_ai_platform/Dockerfile (deflated 54%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/seq_example_util_test.py (deflated 87%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/create_coco_tf_record.py (deflated 77%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/create_pascal_tf_record_test.py (deflated 69%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/create_kitti_tf_record_test.py (deflated 73%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/create_kitti_tf_record.py (deflated 72%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/__init__.py (stored 0%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/oid_hierarchical_labels_expansion_test.py (deflated 72%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/download_and_preprocess_mscoco.sh (deflated 61%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/download_and_preprocess_ava.sh (deflated 51%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/tf_record_creation_util.py (deflated 50%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/tf_record_creation_util_test.py (deflated 52%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/create_ava_actions_tf_record.py (deflated 74%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/context_rcnn/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/context_rcnn/generate_embedding_data.py (deflated 71%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/context_rcnn/generate_detection_data.py (deflated 72%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/context_rcnn/__init__.py (stored 0%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/context_rcnn/generate_embedding_data_tf2_test.py (deflated 75%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/context_rcnn/generate_detection_data_tf2_test.py (deflated 71%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/context_rcnn/add_context_to_examples_tf2_test.py (deflated 80%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_main.py (deflated 70%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/context_rcnn/add_context_to_examples.py (deflated 80%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_tf2_test.py (deflated 76%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/seq_example_util.py (deflated 76%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/densepose/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/densepose/UV_symmetry_transforms.mat (deflated 96%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/create_pycocotools_package.sh (deflated 54%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/oid_hierarchical_labels_expansion.py (deflated 70%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/create_pet_tf_record.py (deflated 69%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/oid_tfrecord_creation_test.py (deflated 82%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/oid_tfrecord_creation.py (deflated 74%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/create_pascal_tf_record.py (deflated 65%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/create_coco_tf_record_test.py (deflated 84%)\n",
            "  adding: content/models/research/object_detection/dataset_tools/create_oid_tf_record.py (deflated 63%)\n",
            "  adding: content/models/research/object_detection/export_tflite_graph_lib_tf2_test.py (deflated 77%)\n",
            "  adding: content/models/research/object_detection/inputs_test.py (deflated 90%)\n",
            "  adding: content/models/research/object_detection/eval_util_test.py (deflated 83%)\n",
            "  adding: content/models/research/object_detection/g3doc/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/g3doc/instance_segmentation.md (deflated 59%)\n",
            "  adding: content/models/research/object_detection/g3doc/exporting_models.md (deflated 53%)\n",
            "  adding: content/models/research/object_detection/g3doc/running_on_mobile_tf2.md (deflated 61%)\n",
            "  adding: content/models/research/object_detection/g3doc/context_rcnn.md (deflated 65%)\n",
            "  adding: content/models/research/object_detection/g3doc/challenge_evaluation.md (deflated 76%)\n",
            "  adding: content/models/research/object_detection/g3doc/deepmac.md (deflated 57%)\n",
            "  adding: content/models/research/object_detection/g3doc/faq.md (deflated 49%)\n",
            "  adding: content/models/research/object_detection/g3doc/img/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/g3doc/img/kites_detections_output.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/g3doc/img/example_cat.jpg (deflated 2%)\n",
            "  adding: content/models/research/object_detection/g3doc/img/mask_improvement.png (deflated 0%)\n",
            "  adding: content/models/research/object_detection/g3doc/img/kites_with_segment_overlay.png (deflated 0%)\n",
            "  adding: content/models/research/object_detection/g3doc/img/oid_bus_72e19c28aac34ed8.jpg (deflated 3%)\n",
            "  adding: content/models/research/object_detection/g3doc/img/tf-od-api-logo.png (deflated 17%)\n",
            "  adding: content/models/research/object_detection/g3doc/img/dogs_detections_output.jpg (deflated 0%)\n",
            "  adding: content/models/research/object_detection/g3doc/img/groupof_case_eval.png (deflated 0%)\n",
            "  adding: content/models/research/object_detection/g3doc/img/oid_monkey_3b4168c89cecbc5b.jpg (deflated 1%)\n",
            "  adding: content/models/research/object_detection/g3doc/img/nongroupof_case_eval.png (deflated 0%)\n",
            "  adding: content/models/research/object_detection/g3doc/img/tensorboard2.png (deflated 4%)\n",
            "  adding: content/models/research/object_detection/g3doc/img/oxford_pet.png (deflated 0%)\n",
            "  adding: content/models/research/object_detection/g3doc/img/tensorboard.png (deflated 9%)\n",
            "  adding: content/models/research/object_detection/g3doc/preparing_inputs.md (deflated 69%)\n",
            "  adding: content/models/research/object_detection/g3doc/configuring_jobs.md (deflated 63%)\n",
            "  adding: content/models/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md (deflated 64%)\n",
            "  adding: content/models/research/object_detection/g3doc/tf1_training_and_evaluation.md (deflated 66%)\n",
            "  adding: content/models/research/object_detection/g3doc/running_notebook.md (deflated 53%)\n",
            "  adding: content/models/research/object_detection/g3doc/oid_inference_and_evaluation.md (deflated 64%)\n",
            "  adding: content/models/research/object_detection/g3doc/tf2_training_and_evaluation.md (deflated 73%)\n",
            "  adding: content/models/research/object_detection/g3doc/tpu_compatibility.md (deflated 65%)\n",
            "  adding: content/models/research/object_detection/g3doc/defining_your_own_model.md (deflated 60%)\n",
            "  adding: content/models/research/object_detection/g3doc/tf2_classification_zoo.md (deflated 79%)\n",
            "  adding: content/models/research/object_detection/g3doc/release_notes.md (deflated 63%)\n",
            "  adding: content/models/research/object_detection/g3doc/tf2.md (deflated 58%)\n",
            "  adding: content/models/research/object_detection/g3doc/tf1_detection_zoo.md (deflated 80%)\n",
            "  adding: content/models/research/object_detection/g3doc/running_pets.md (deflated 66%)\n",
            "  adding: content/models/research/object_detection/g3doc/using_your_own_dataset.md (deflated 67%)\n",
            "  adding: content/models/research/object_detection/g3doc/evaluation_protocols.md (deflated 68%)\n",
            "  adding: content/models/research/object_detection/g3doc/tf1.md (deflated 61%)\n",
            "  adding: content/models/research/object_detection/g3doc/tpu_exporters.md (deflated 46%)\n",
            "  adding: content/models/research/object_detection/g3doc/tf2_detection_zoo.md (deflated 84%)\n",
            "  adding: content/models/research/object_detection/export_inference_graph.py (deflated 71%)\n",
            "  adding: content/models/research/object_detection/exporter_tf1_test.py (deflated 90%)\n",
            "  adding: content/models/research/object_detection/model_tpu_main.py (deflated 64%)\n",
            "  adding: content/models/research/object_detection/test_data/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/test_data/context_rcnn_camera_trap.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/test_data/ssd_mobilenet_v1_fpp.config (deflated 74%)\n",
            "  adding: content/models/research/object_detection/test_data/snapshot_serengeti_sequence_examples.record (deflated 14%)\n",
            "  adding: content/models/research/object_detection/test_data/pets_examples.record (deflated 1%)\n",
            "  adding: content/models/research/object_detection/model_lib_tf2_test.py (deflated 71%)\n",
            "  adding: content/models/research/object_detection/colab_tutorials/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/colab_tutorials/inference_tf2_colab.ipynb (deflated 74%)\n",
            "  adding: content/models/research/object_detection/colab_tutorials/eager_few_shot_od_training_tflite.ipynb (deflated 74%)\n",
            "  adding: content/models/research/object_detection/colab_tutorials/convert_odt_model_to_TFLite.ipynb (deflated 73%)\n",
            "  adding: content/models/research/object_detection/colab_tutorials/context_rcnn_tutorial.ipynb (deflated 30%)\n",
            "  adding: content/models/research/object_detection/colab_tutorials/centernet_on_device.ipynb (deflated 78%)\n",
            "  adding: content/models/research/object_detection/colab_tutorials/generate_ssd_anchor_box_aspect_ratios_using_k_means_clustering.ipynb (deflated 72%)\n",
            "  adding: content/models/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb (deflated 76%)\n",
            "  adding: content/models/research/object_detection/colab_tutorials/inference_from_saved_model_tf2_colab.ipynb (deflated 74%)\n",
            "  adding: content/models/research/object_detection/colab_tutorials/eager_few_shot_od_training_tf2_colab.ipynb (deflated 74%)\n",
            "  adding: content/models/research/object_detection/colab_tutorials/deepmac_colab.ipynb (deflated 72%)\n",
            "  adding: content/models/research/object_detection/models/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/models/ssd_mobiledet_feature_extractor_tf1_test.py (deflated 77%)\n",
            "  adding: content/models/research/object_detection/models/faster_rcnn_resnet_v1_feature_extractor_tf1_test.py (deflated 77%)\n",
            "  adding: content/models/research/object_detection/models/faster_rcnn_inception_v2_feature_extractor.py (deflated 77%)\n",
            "  adding: content/models/research/object_detection/models/ssd_feature_extractor_test.py (deflated 77%)\n",
            "  adding: content/models/research/object_detection/models/faster_rcnn_resnet_v1_fpn_keras_feature_extractor_tf2_test.py (deflated 70%)\n",
            "  adding: content/models/research/object_detection/models/center_net_hourglass_feature_extractor_tf2_test.py (deflated 52%)\n",
            "  adding: content/models/research/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor.py (deflated 70%)\n",
            "  adding: content/models/research/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_tf1_test.py (deflated 59%)\n",
            "  adding: content/models/research/object_detection/models/ssd_mobilenet_v1_keras_feature_extractor.py (deflated 68%)\n",
            "  adding: content/models/research/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_testbase.py (deflated 78%)\n",
            "  adding: content/models/research/object_detection/models/bidirectional_feature_pyramid_generators.py (deflated 76%)\n",
            "  adding: content/models/research/object_detection/models/center_net_mobilenet_v2_fpn_feature_extractor_tf2_test.py (deflated 73%)\n",
            "  adding: content/models/research/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor.py (deflated 71%)\n",
            "  adding: content/models/research/object_detection/models/ssd_mobilenet_v3_feature_extractor_testbase.py (deflated 74%)\n",
            "  adding: content/models/research/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor.py (deflated 62%)\n",
            "  adding: content/models/research/object_detection/models/__pycache__/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/models/__pycache__/ssd_mobilenet_v1_fpn_feature_extractor.cpython-37.pyc (deflated 54%)\n",
            "  adding: content/models/research/object_detection/models/__pycache__/ssd_mobiledet_feature_extractor.cpython-37.pyc (deflated 64%)\n",
            "  adding: content/models/research/object_detection/models/__pycache__/ssd_mobilenet_v1_ppn_feature_extractor.cpython-37.pyc (deflated 51%)\n",
            "  adding: content/models/research/object_detection/models/__pycache__/faster_rcnn_pnas_feature_extractor.cpython-37.pyc (deflated 54%)\n",
            "  adding: content/models/research/object_detection/models/__pycache__/ssd_mobilenet_v1_feature_extractor.cpython-37.pyc (deflated 54%)\n",
            "  adding: content/models/research/object_detection/models/__pycache__/ssd_mobilenet_v3_feature_extractor.cpython-37.pyc (deflated 59%)\n",
            "  adding: content/models/research/object_detection/models/__pycache__/ssd_inception_v3_feature_extractor.cpython-37.pyc (deflated 56%)\n",
            "  adding: content/models/research/object_detection/models/__pycache__/embedded_ssd_mobilenet_v1_feature_extractor.cpython-37.pyc (deflated 55%)\n",
            "  adding: content/models/research/object_detection/models/__pycache__/__init__.cpython-37.pyc (deflated 26%)\n",
            "  adding: content/models/research/object_detection/models/__pycache__/ssd_resnet_v1_fpn_feature_extractor.cpython-37.pyc (deflated 71%)\n",
            "  adding: content/models/research/object_detection/models/__pycache__/ssd_pnasnet_feature_extractor.cpython-37.pyc (deflated 54%)\n",
            "  adding: content/models/research/object_detection/models/__pycache__/ssd_mobilenet_edgetpu_feature_extractor.cpython-37.pyc (deflated 43%)\n",
            "  adding: content/models/research/object_detection/models/__pycache__/ssd_mobilenet_v2_fpn_feature_extractor.cpython-37.pyc (deflated 53%)\n",
            "  adding: content/models/research/object_detection/models/__pycache__/ssd_mobilenet_v2_feature_extractor.cpython-37.pyc (deflated 54%)\n",
            "  adding: content/models/research/object_detection/models/__pycache__/faster_rcnn_nas_feature_extractor.cpython-37.pyc (deflated 54%)\n",
            "  adding: content/models/research/object_detection/models/__pycache__/feature_map_generators.cpython-37.pyc (deflated 66%)\n",
            "  adding: content/models/research/object_detection/models/__pycache__/faster_rcnn_inception_v2_feature_extractor.cpython-37.pyc (deflated 58%)\n",
            "  adding: content/models/research/object_detection/models/__pycache__/ssd_inception_v2_feature_extractor.cpython-37.pyc (deflated 56%)\n",
            "  adding: content/models/research/object_detection/models/__pycache__/ssd_resnet_v1_ppn_feature_extractor.cpython-37.pyc (deflated 70%)\n",
            "  adding: content/models/research/object_detection/models/__pycache__/faster_rcnn_resnet_v1_feature_extractor.cpython-37.pyc (deflated 64%)\n",
            "  adding: content/models/research/object_detection/models/__pycache__/ssd_mobilenet_v2_mnasfpn_feature_extractor.cpython-37.pyc (deflated 52%)\n",
            "  adding: content/models/research/object_detection/models/__pycache__/ssd_spaghettinet_feature_extractor.cpython-37.pyc (deflated 60%)\n",
            "  adding: content/models/research/object_detection/models/__pycache__/faster_rcnn_inception_resnet_v2_feature_extractor.cpython-37.pyc (deflated 57%)\n",
            "  adding: content/models/research/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor.py (deflated 70%)\n",
            "  adding: content/models/research/object_detection/models/keras_models/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/models/keras_models/nonlocal_block.py (deflated 68%)\n",
            "  adding: content/models/research/object_detection/models/keras_models/__pycache__/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/models/keras_models/__pycache__/model_utils.cpython-37.pyc (deflated 39%)\n",
            "  adding: content/models/research/object_detection/models/keras_models/__pycache__/resnet_v1.cpython-37.pyc (deflated 68%)\n",
            "  adding: content/models/research/object_detection/models/keras_models/__pycache__/__init__.cpython-37.pyc (deflated 27%)\n",
            "  adding: content/models/research/object_detection/models/keras_models/__pycache__/hourglass_network.cpython-37.pyc (deflated 63%)\n",
            "  adding: content/models/research/object_detection/models/keras_models/hourglass_network.py (deflated 79%)\n",
            "  adding: content/models/research/object_detection/models/keras_models/model_utils.py (deflated 52%)\n",
            "  adding: content/models/research/object_detection/models/keras_models/__init__.py (stored 0%)\n",
            "  adding: content/models/research/object_detection/models/keras_models/inception_resnet_v2_tf2_test.py (deflated 72%)\n",
            "  adding: content/models/research/object_detection/models/keras_models/mobilenet_v2.py (deflated 74%)\n",
            "  adding: content/models/research/object_detection/models/keras_models/mobilenet_v1.py (deflated 74%)\n",
            "  adding: content/models/research/object_detection/models/keras_models/mobilenet_v1_tf2_test.py (deflated 75%)\n",
            "  adding: content/models/research/object_detection/models/keras_models/mobilenet_v2_tf2_test.py (deflated 77%)\n",
            "  adding: content/models/research/object_detection/models/keras_models/inception_resnet_v2.py (deflated 72%)\n",
            "  adding: content/models/research/object_detection/models/keras_models/base_models/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/models/keras_models/base_models/original_mobilenet_v2.py (deflated 73%)\n",
            "  adding: content/models/research/object_detection/models/keras_models/convert_keras_models.py (deflated 57%)\n",
            "  adding: content/models/research/object_detection/models/keras_models/nonlocal_block_tf2_test.py (deflated 63%)\n",
            "  adding: content/models/research/object_detection/models/keras_models/resnet_v1_tf2_test.py (deflated 72%)\n",
            "  adding: content/models/research/object_detection/models/keras_models/test_utils.py (deflated 86%)\n",
            "  adding: content/models/research/object_detection/models/keras_models/hourglass_network_tf2_test.py (deflated 78%)\n",
            "  adding: content/models/research/object_detection/models/keras_models/resnet_v1.py (deflated 79%)\n",
            "  adding: content/models/research/object_detection/models/center_net_resnet_feature_extractor_tf2_test.py (deflated 59%)\n",
            "  adding: content/models/research/object_detection/models/ssd_mobilenet_v1_feature_extractor.py (deflated 68%)\n",
            "  adding: content/models/research/object_detection/models/ssd_efficientnet_bifpn_feature_extractor.py (deflated 91%)\n",
            "  adding: content/models/research/object_detection/models/faster_rcnn_resnet_keras_feature_extractor_tf2_test.py (deflated 65%)\n",
            "  adding: content/models/research/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor_tf2_test.py (deflated 70%)\n",
            "  adding: content/models/research/object_detection/models/ssd_inception_v3_feature_extractor_tf1_test.py (deflated 77%)\n",
            "  adding: content/models/research/object_detection/models/center_net_mobilenet_v2_feature_extractor_tf2_test.py (deflated 52%)\n",
            "  adding: content/models/research/object_detection/models/faster_rcnn_nas_feature_extractor.py (deflated 69%)\n",
            "  adding: content/models/research/object_detection/models/faster_rcnn_resnet_v1_fpn_keras_feature_extractor.py (deflated 79%)\n",
            "  adding: content/models/research/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_tf1_test.py (deflated 82%)\n",
            "  adding: content/models/research/object_detection/models/center_net_mobilenet_v2_fpn_feature_extractor.py (deflated 65%)\n",
            "  adding: content/models/research/object_detection/models/__init__.py (stored 0%)\n",
            "  adding: content/models/research/object_detection/models/ssd_mobilenet_v1_feature_extractor_tf2_test.py (deflated 80%)\n",
            "  adding: content/models/research/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_tf1_test.py (deflated 79%)\n",
            "  adding: content/models/research/object_detection/models/ssd_resnet_v1_fpn_keras_feature_extractor.py (deflated 83%)\n",
            "  adding: content/models/research/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_testbase.py (deflated 69%)\n",
            "  adding: content/models/research/object_detection/models/center_net_hourglass_feature_extractor.py (deflated 70%)\n",
            "  adding: content/models/research/object_detection/models/ssd_efficientnet_bifpn_feature_extractor_tf2_test.py (deflated 75%)\n",
            "  adding: content/models/research/object_detection/models/ssd_mobiledet_feature_extractor.py (deflated 82%)\n",
            "  adding: content/models/research/object_detection/models/ssd_pnasnet_feature_extractor.py (deflated 67%)\n",
            "  adding: content/models/research/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_tf2_test.py (deflated 78%)\n",
            "  adding: content/models/research/object_detection/models/ssd_mobilenet_v2_keras_feature_extractor.py (deflated 68%)\n",
            "  adding: content/models/research/object_detection/models/feature_map_generators.py (deflated 79%)\n",
            "  adding: content/models/research/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_testbase.py (deflated 74%)\n",
            "  adding: content/models/research/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_tf2_test.py (deflated 81%)\n",
            "  adding: content/models/research/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor.py (deflated 67%)\n",
            "  adding: content/models/research/object_detection/models/ssd_pnasnet_feature_extractor_tf1_test.py (deflated 69%)\n",
            "  adding: content/models/research/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor_tf1_test.py (deflated 80%)\n",
            "  adding: content/models/research/object_detection/models/faster_rcnn_pnas_feature_extractor.py (deflated 68%)\n",
            "  adding: content/models/research/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor_tf1_test.py (deflated 74%)\n",
            "  adding: content/models/research/object_detection/models/ssd_mobilenet_v3_feature_extractor_tf1_test.py (deflated 73%)\n",
            "  adding: content/models/research/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_tf2_test.py (deflated 77%)\n",
            "  adding: content/models/research/object_detection/models/center_net_resnet_v1_fpn_feature_extractor_tf2_test.py (deflated 53%)\n",
            "  adding: content/models/research/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor.py (deflated 61%)\n",
            "  adding: content/models/research/object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py (deflated 70%)\n",
            "  adding: content/models/research/object_detection/models/ssd_inception_v2_feature_extractor.py (deflated 67%)\n",
            "  adding: content/models/research/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor.py (deflated 72%)\n",
            "  adding: content/models/research/object_detection/models/ssd_resnet_v1_ppn_feature_extractor.py (deflated 79%)\n",
            "  adding: content/models/research/object_detection/models/faster_rcnn_nas_feature_extractor_tf1_test.py (deflated 75%)\n",
            "  adding: content/models/research/object_detection/models/center_net_resnet_feature_extractor.py (deflated 67%)\n",
            "  adding: content/models/research/object_detection/models/faster_rcnn_pnas_feature_extractor_tf1_test.py (deflated 74%)\n",
            "  adding: content/models/research/object_detection/models/ssd_inception_v3_feature_extractor.py (deflated 67%)\n",
            "  adding: content/models/research/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_tf1_test.py (deflated 74%)\n",
            "  adding: content/models/research/object_detection/models/bidirectional_feature_pyramid_generators_tf2_test.py (deflated 78%)\n",
            "  adding: content/models/research/object_detection/models/center_net_mobilenet_v2_feature_extractor.py (deflated 63%)\n",
            "  adding: content/models/research/object_detection/models/ssd_spaghettinet_feature_extractor_tf1_test.py (deflated 71%)\n",
            "  adding: content/models/research/object_detection/models/ssd_mobilenet_v1_fpn_keras_feature_extractor.py (deflated 71%)\n",
            "  adding: content/models/research/object_detection/models/ssd_spaghettinet_feature_extractor.py (deflated 83%)\n",
            "  adding: content/models/research/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor_tf1_test.py (deflated 75%)\n",
            "  adding: content/models/research/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor.py (deflated 70%)\n",
            "  adding: content/models/research/object_detection/models/ssd_mobilenet_v2_feature_extractor.py (deflated 67%)\n",
            "  adding: content/models/research/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_tf1_test.py (deflated 75%)\n",
            "  adding: content/models/research/object_detection/models/ssd_mobilenet_v2_mnasfpn_feature_extractor.py (deflated 72%)\n",
            "  adding: content/models/research/object_detection/models/ssd_inception_v2_feature_extractor_tf1_test.py (deflated 77%)\n",
            "  adding: content/models/research/object_detection/models/faster_rcnn_resnet_keras_feature_extractor.py (deflated 76%)\n",
            "  adding: content/models/research/object_detection/models/ssd_mobilenet_v2_feature_extractor_tf1_test.py (deflated 79%)\n",
            "  adding: content/models/research/object_detection/models/ssd_mobilenet_v2_mnasfpn_feature_extractor_tf1_test.py (deflated 69%)\n",
            "  adding: content/models/research/object_detection/models/faster_rcnn_inception_v2_feature_extractor_tf1_test.py (deflated 76%)\n",
            "  adding: content/models/research/object_detection/models/center_net_resnet_v1_fpn_feature_extractor.py (deflated 70%)\n",
            "  adding: content/models/research/object_detection/models/ssd_mobilenet_v3_feature_extractor.py (deflated 74%)\n",
            "  adding: content/models/research/object_detection/models/faster_rcnn_resnet_v1_feature_extractor.py (deflated 75%)\n",
            "  adding: content/models/research/object_detection/models/feature_map_generators_test.py (deflated 88%)\n",
            "  adding: content/models/research/object_detection/models/ssd_mobilenet_v2_feature_extractor_tf2_test.py (deflated 79%)\n",
            "  adding: content/models/research/object_detection/models/ssd_resnet_v1_fpn_feature_extractor.py (deflated 81%)\n",
            "  adding: content/models/research/object_detection/models/ssd_mobilenet_v1_feature_extractor_tf1_test.py (deflated 80%)\n",
            "  adding: content/models/research/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor_tf1_test.py (deflated 76%)\n",
            "  adding: content/models/research/object_detection/core/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/core/preprocessor_cache.py (deflated 62%)\n",
            "  adding: content/models/research/object_detection/core/data_parser.py (deflated 52%)\n",
            "  adding: content/models/research/object_detection/core/region_similarity_calculator.py (deflated 71%)\n",
            "  adding: content/models/research/object_detection/core/__pycache__/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/core/__pycache__/region_similarity_calculator.cpython-37.pyc (deflated 63%)\n",
            "  adding: content/models/research/object_detection/core/__pycache__/box_predictor.cpython-37.pyc (deflated 73%)\n",
            "  adding: content/models/research/object_detection/core/__pycache__/minibatch_sampler.cpython-37.pyc (deflated 51%)\n",
            "  adding: content/models/research/object_detection/core/__pycache__/box_list_ops.cpython-37.pyc (deflated 65%)\n",
            "  adding: content/models/research/object_detection/core/__pycache__/anchor_generator.cpython-37.pyc (deflated 57%)\n",
            "  adding: content/models/research/object_detection/core/__pycache__/freezable_batch_norm.cpython-37.pyc (deflated 48%)\n",
            "  adding: content/models/research/object_detection/core/__pycache__/standard_fields.cpython-37.pyc (deflated 71%)\n",
            "  adding: content/models/research/object_detection/core/__pycache__/data_decoder.cpython-37.pyc (deflated 42%)\n",
            "  adding: content/models/research/object_detection/core/__pycache__/__init__.cpython-37.pyc (deflated 22%)\n",
            "  adding: content/models/research/object_detection/core/__pycache__/preprocessor.cpython-37.pyc (deflated 76%)\n",
            "  adding: content/models/research/object_detection/core/__pycache__/losses.cpython-37.pyc (deflated 70%)\n",
            "  adding: content/models/research/object_detection/core/__pycache__/keypoint_ops.cpython-37.pyc (deflated 68%)\n",
            "  adding: content/models/research/object_detection/core/__pycache__/box_list.cpython-37.pyc (deflated 58%)\n",
            "  adding: content/models/research/object_detection/core/__pycache__/densepose_ops.cpython-37.pyc (deflated 63%)\n",
            "  adding: content/models/research/object_detection/core/__pycache__/model.cpython-37.pyc (deflated 69%)\n",
            "  adding: content/models/research/object_detection/core/__pycache__/post_processing.cpython-37.pyc (deflated 68%)\n",
            "  adding: content/models/research/object_detection/core/__pycache__/balanced_positive_negative_sampler.cpython-37.pyc (deflated 59%)\n",
            "  adding: content/models/research/object_detection/core/__pycache__/target_assigner.cpython-37.pyc (deflated 71%)\n",
            "  adding: content/models/research/object_detection/core/__pycache__/matcher.cpython-37.pyc (deflated 65%)\n",
            "  adding: content/models/research/object_detection/core/__pycache__/preprocessor_cache.cpython-37.pyc (deflated 51%)\n",
            "  adding: content/models/research/object_detection/core/__pycache__/box_coder.cpython-37.pyc (deflated 57%)\n",
            "  adding: content/models/research/object_detection/core/region_similarity_calculator_test.py (deflated 76%)\n",
            "  adding: content/models/research/object_detection/core/losses_test.py (deflated 92%)\n",
            "  adding: content/models/research/object_detection/core/preprocessor.py (deflated 85%)\n",
            "  adding: content/models/research/object_detection/core/batcher.py (deflated 63%)\n",
            "  adding: content/models/research/object_detection/core/prefetcher_tf1_test.py (deflated 73%)\n",
            "  adding: content/models/research/object_detection/core/box_list_ops.py (deflated 78%)\n",
            "  adding: content/models/research/object_detection/core/minibatch_sampler_test.py (deflated 69%)\n",
            "  adding: content/models/research/object_detection/core/densepose_ops.py (deflated 74%)\n",
            "  adding: content/models/research/object_detection/core/data_decoder.py (deflated 50%)\n",
            "  adding: content/models/research/object_detection/core/freezable_batch_norm.py (deflated 54%)\n",
            "  adding: content/models/research/object_detection/core/keypoint_ops.py (deflated 77%)\n",
            "  adding: content/models/research/object_detection/core/anchor_generator.py (deflated 63%)\n",
            "  adding: content/models/research/object_detection/core/__init__.py (stored 0%)\n",
            "  adding: content/models/research/object_detection/core/multiclass_nms_test.py (deflated 89%)\n",
            "  adding: content/models/research/object_detection/core/minibatch_sampler.py (deflated 59%)\n",
            "  adding: content/models/research/object_detection/core/target_assigner.py (deflated 82%)\n",
            "  adding: content/models/research/object_detection/core/batcher_tf1_test.py (deflated 79%)\n",
            "  adding: content/models/research/object_detection/core/matcher.py (deflated 72%)\n",
            "  adding: content/models/research/object_detection/core/standard_fields.py (deflated 76%)\n",
            "  adding: content/models/research/object_detection/core/densepose_ops_test.py (deflated 78%)\n",
            "  adding: content/models/research/object_detection/core/losses.py (deflated 79%)\n",
            "  adding: content/models/research/object_detection/core/box_list.py (deflated 66%)\n",
            "  adding: content/models/research/object_detection/core/class_agnostic_nms_test.py (deflated 76%)\n",
            "  adding: content/models/research/object_detection/core/matcher_test.py (deflated 82%)\n",
            "  adding: content/models/research/object_detection/core/model_test.py (deflated 60%)\n",
            "  adding: content/models/research/object_detection/core/box_list_test.py (deflated 72%)\n",
            "  adding: content/models/research/object_detection/core/prefetcher.py (deflated 58%)\n",
            "  adding: content/models/research/object_detection/core/keypoint_ops_test.py (deflated 85%)\n",
            "  adding: content/models/research/object_detection/core/batch_multiclass_nms_test.py (deflated 91%)\n",
            "  adding: content/models/research/object_detection/core/post_processing.py (deflated 81%)\n",
            "  adding: content/models/research/object_detection/core/model.py (deflated 75%)\n",
            "  adding: content/models/research/object_detection/core/box_list_ops_test.py (deflated 87%)\n",
            "  adding: content/models/research/object_detection/core/preprocessor_test.py (deflated 91%)\n",
            "  adding: content/models/research/object_detection/core/balanced_positive_negative_sampler_test.py (deflated 84%)\n",
            "  adding: content/models/research/object_detection/core/balanced_positive_negative_sampler.py (deflated 73%)\n",
            "  adding: content/models/research/object_detection/core/target_assigner_test.py (deflated 90%)\n",
            "  adding: content/models/research/object_detection/core/box_coder.py (deflated 65%)\n",
            "  adding: content/models/research/object_detection/core/box_predictor.py (deflated 77%)\n",
            "  adding: content/models/research/object_detection/core/freezable_batch_norm_tf2_test.py (deflated 79%)\n",
            "  adding: content/models/research/object_detection/core/freezable_sync_batch_norm.py (deflated 54%)\n",
            "  adding: content/models/research/object_detection/core/box_coder_test.py (deflated 56%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/ssd_meta_arch_test_lib.py (deflated 70%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/ssd_meta_arch.py (deflated 79%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/__pycache__/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/__pycache__/rfcn_meta_arch.cpython-37.pyc (deflated 65%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/__pycache__/context_rcnn_meta_arch.cpython-37.pyc (deflated 70%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/__pycache__/faster_rcnn_meta_arch.cpython-37.pyc (deflated 72%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/__pycache__/__init__.cpython-37.pyc (deflated 23%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/__pycache__/context_rcnn_lib_tf2.cpython-37.pyc (deflated 57%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/__pycache__/deepmac_meta_arch.cpython-37.pyc (deflated 63%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/__pycache__/context_rcnn_lib.cpython-37.pyc (deflated 60%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/__pycache__/ssd_meta_arch.cpython-37.pyc (deflated 67%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/__pycache__/center_net_meta_arch.cpython-37.pyc (deflated 70%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch_test_lib.py (deflated 87%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/ssd_meta_arch_test.py (deflated 86%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/__init__.py (stored 0%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/context_rcnn_meta_arch.py (deflated 78%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/center_net_meta_arch_tf2_test.py (deflated 86%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/context_rcnn_meta_arch_test.py (deflated 78%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/context_rcnn_lib_tf2_test.py (deflated 70%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/center_net_meta_arch.py (deflated 81%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/context_rcnn_lib.py (deflated 74%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/deepmac_meta_arch.py (deflated 78%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py (deflated 81%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/context_rcnn_lib_tf1_test.py (deflated 78%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/rfcn_meta_arch_test.py (deflated 61%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch_test.py (deflated 86%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/rfcn_meta_arch.py (deflated 72%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/context_rcnn_lib_tf2.py (deflated 72%)\n",
            "  adding: content/models/research/object_detection/meta_architectures/deepmac_meta_arch_test.py (deflated 82%)\n",
            "  adding: content/models/research/object_detection/model_lib_v2.py (deflated 77%)\n",
            "  adding: content/models/research/object_detection/packages/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/packages/tf2/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/packages/tf2/setup.py (deflated 55%)\n",
            "  adding: content/models/research/object_detection/packages/tf1/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/packages/tf1/setup.py (deflated 56%)\n",
            "  adding: content/models/research/object_detection/data/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/data/mscoco_label_map.pbtxt (deflated 78%)\n",
            "  adding: content/models/research/object_detection/data/ava_label_map_v2.1.pbtxt (deflated 74%)\n",
            "  adding: content/models/research/object_detection/data/snapshot_serengeti_label_map.pbtxt (deflated 74%)\n",
            "  adding: content/models/research/object_detection/data/kitti_label_map.pbtxt (deflated 29%)\n",
            "  adding: content/models/research/object_detection/data/pascal_label_map.pbtxt (deflated 73%)\n",
            "  adding: content/models/research/object_detection/data/fgvc_2854_classes_label_map.pbtxt (deflated 77%)\n",
            "  adding: content/models/research/object_detection/data/mscoco_minival_ids.txt (deflated 52%)\n",
            "  adding: content/models/research/object_detection/data/face_label_map.pbtxt (deflated 21%)\n",
            "  adding: content/models/research/object_detection/data/mscoco_complete_label_map.pbtxt (deflated 79%)\n",
            "  adding: content/models/research/object_detection/data/face_person_with_keypoints_label_map.pbtxt (deflated 77%)\n",
            "  adding: content/models/research/object_detection/data/oid_object_detection_challenge_500_label_map.pbtxt (deflated 79%)\n",
            "  adding: content/models/research/object_detection/data/oid_v4_label_map.pbtxt (deflated 79%)\n",
            "  adding: content/models/research/object_detection/data/oid_bbox_trainable_label_map.pbtxt (deflated 79%)\n",
            "  adding: content/models/research/object_detection/data/pet_label_map.pbtxt (deflated 71%)\n",
            "  adding: content/models/research/object_detection/model_lib.py (deflated 78%)\n",
            "  adding: content/models/research/object_detection/model_main.py (deflated 65%)\n",
            "  adding: content/models/research/object_detection/legacy/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/legacy/trainer.py (deflated 72%)\n",
            "  adding: content/models/research/object_detection/legacy/train.py (deflated 66%)\n",
            "  adding: content/models/research/object_detection/legacy/__init__.py (stored 0%)\n",
            "  adding: content/models/research/object_detection/legacy/eval.py (deflated 66%)\n",
            "  adding: content/models/research/object_detection/legacy/evaluator.py (deflated 73%)\n",
            "  adding: content/models/research/object_detection/legacy/trainer_tf1_test.py (deflated 71%)\n",
            "  adding: content/models/research/object_detection/metrics/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/metrics/coco_evaluation.py (deflated 85%)\n",
            "  adding: content/models/research/object_detection/metrics/tf_example_parser.py (deflated 76%)\n",
            "  adding: content/models/research/object_detection/metrics/lvis_tools.py (deflated 70%)\n",
            "  adding: content/models/research/object_detection/metrics/lvis_evaluation.py (deflated 77%)\n",
            "  adding: content/models/research/object_detection/metrics/__pycache__/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/metrics/__pycache__/coco_tools.cpython-37.pyc (deflated 69%)\n",
            "  adding: content/models/research/object_detection/metrics/__pycache__/lvis_evaluation.cpython-37.pyc (deflated 59%)\n",
            "  adding: content/models/research/object_detection/metrics/__pycache__/lvis_tools.cpython-37.pyc (deflated 59%)\n",
            "  adding: content/models/research/object_detection/metrics/__pycache__/coco_evaluation.cpython-37.pyc (deflated 75%)\n",
            "  adding: content/models/research/object_detection/metrics/__pycache__/__init__.cpython-37.pyc (deflated 22%)\n",
            "  adding: content/models/research/object_detection/metrics/coco_tools.py (deflated 80%)\n",
            "  adding: content/models/research/object_detection/metrics/oid_challenge_evaluation.py (deflated 65%)\n",
            "  adding: content/models/research/object_detection/metrics/calibration_metrics_tf1_test.py (deflated 71%)\n",
            "  adding: content/models/research/object_detection/metrics/__init__.py (stored 0%)\n",
            "  adding: content/models/research/object_detection/metrics/oid_challenge_evaluation_utils_test.py (deflated 82%)\n",
            "  adding: content/models/research/object_detection/metrics/oid_challenge_evaluation_utils.py (deflated 70%)\n",
            "  adding: content/models/research/object_detection/metrics/calibration_metrics.py (deflated 61%)\n",
            "  adding: content/models/research/object_detection/metrics/calibration_evaluation.py (deflated 70%)\n",
            "  adding: content/models/research/object_detection/metrics/offline_eval_map_corloc_test.py (deflated 66%)\n",
            "  adding: content/models/research/object_detection/metrics/oid_vrd_challenge_evaluation.py (deflated 69%)\n",
            "  adding: content/models/research/object_detection/metrics/tf_example_parser_test.py (deflated 79%)\n",
            "  adding: content/models/research/object_detection/metrics/lvis_evaluation_test.py (deflated 78%)\n",
            "  adding: content/models/research/object_detection/metrics/coco_evaluation_test.py (deflated 93%)\n",
            "  adding: content/models/research/object_detection/metrics/coco_tools_test.py (deflated 84%)\n",
            "  adding: content/models/research/object_detection/metrics/offline_eval_map_corloc.py (deflated 64%)\n",
            "  adding: content/models/research/object_detection/metrics/io_utils.py (deflated 47%)\n",
            "  adding: content/models/research/object_detection/metrics/oid_vrd_challenge_evaluation_utils.py (deflated 75%)\n",
            "  adding: content/models/research/object_detection/metrics/lvis_tools_test.py (deflated 72%)\n",
            "  adding: content/models/research/object_detection/metrics/oid_vrd_challenge_evaluation_utils_test.py (deflated 78%)\n",
            "  adding: content/models/research/object_detection/metrics/calibration_evaluation_tf1_test.py (deflated 79%)\n",
            "  adding: content/models/research/object_detection/inputs.py (deflated 81%)\n",
            "  adding: content/models/research/object_detection/export_tflite_graph_lib_tf2.py (deflated 74%)\n",
            "  adding: content/models/research/object_detection/export_tflite_ssd_graph_lib_tf1_test.py (deflated 84%)\n",
            "  adding: content/models/research/object_detection/configs/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/faster_rcnn_resnet101_v1_800x1333_coco17_gpu-8.config (deflated 66%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/centernet_hourglass104_512x512_coco17_tpu-8.config (deflated 62%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/ssd_resnet101_v1_fpn_1024x1024_coco17_tpu-8.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/centernet_hourglass104_1024x1024_kpts_coco17_tpu-32.config (deflated 78%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/centernet_hourglass104_1024x1024_coco17_tpu-32.config (deflated 61%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/ssd_efficientdet_d4_1024x1024_coco17_tpu-32.config (deflated 66%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/ssd_resnet50_v1_fpn_1024x1024_coco17_tpu-8.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/faster_rcnn_resnet152_v1_640x640_coco17_tpu-8.config (deflated 64%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/ssd_efficientdet_d2_768x768_coco17_tpu-8.config (deflated 66%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/center_net_deepmac_1024x1024_non_voc_only_tpu-128.config (deflated 68%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/centernet_resnet50_v2_512x512_kpts_coco17_tpu-8.config (deflated 78%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/center_net_deepmac_1024x1024_voc_only_tpu-128.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/ssd_mobilenet_v2_320x320_coco17_tpu-8.config (deflated 67%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.config (deflated 64%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.config (deflated 64%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/center_net_deepmac_512x512_voc_only_tpu-32.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/centernet_resnet50_v1_fpn_512x512_kpts_coco17_tpu-8.config (deflated 78%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8.config (deflated 67%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/faster_rcnn_resnet50_v1_800x1333_coco17_gpu-8.config (deflated 66%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/centernet_resnet101_v1_fpn_512x512_coco17_tpu-8.config (deflated 63%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/faster_rcnn_resnet50_v1_1024x1024_coco17_tpu-8.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/ssd_efficientdet_d0_512x512_coco17_tpu-8.config (deflated 66%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/centernet_hourglass104_512x512_kpts_coco17_tpu-32.config (deflated 78%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/center_net_deepmac_1024x1024_coco_tpu-128.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/ssd_efficientdet_d7_1536x1536_coco17_tpu-32.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/ssd_efficientdet_d1_640x640_coco17_tpu-8.config (deflated 66%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/ssd_efficientdet_d5_1280x1280_coco17_tpu-32.config (deflated 66%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/ssd_resnet152_v1_fpn_640x640_coco17_tpu-8.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/faster_rcnn_resnet152_v1_800x1333_coco17_gpu-8.config (deflated 66%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/ssd_efficientdet_d6_1408x1408_coco17_tpu-32.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/ssd_resnet152_v1_fpn_1024x1024_coco17_tpu-8.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/faster_rcnn_resnet50_v1_fpn_640x640_coco17_tpu-8.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/ssd_efficientdet_d3_896x896_coco17_tpu-32.config (deflated 66%)\n",
            "  adding: content/models/research/object_detection/configs/tf2/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/configs/tf1/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/configs/tf1/ssd_spaghettinet_edgetpu_320x320_coco17_sync_4x4.config (deflated 65%)\n",
            "  adding: content/models/research/object_detection/data_decoders/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/data_decoders/__pycache__/ (stored 0%)\n",
            "  adding: content/models/research/object_detection/data_decoders/__pycache__/tf_example_decoder.cpython-37.pyc (deflated 65%)\n",
            "  adding: content/models/research/object_detection/data_decoders/__pycache__/__init__.cpython-37.pyc (deflated 22%)\n",
            "  adding: content/models/research/object_detection/data_decoders/__pycache__/tf_sequence_example_decoder.cpython-37.pyc (deflated 58%)\n",
            "  adding: content/models/research/object_detection/data_decoders/tf_example_decoder.py (deflated 80%)\n",
            "  adding: content/models/research/object_detection/data_decoders/tf_sequence_example_decoder_test.py (deflated 84%)\n",
            "  adding: content/models/research/object_detection/data_decoders/__init__.py (stored 0%)\n",
            "  adding: content/models/research/object_detection/data_decoders/tf_example_decoder_test.py (deflated 93%)\n",
            "  adding: content/models/research/object_detection/data_decoders/tf_sequence_example_decoder.py (deflated 73%)\n",
            "  adding: content/models/research/deep_speech/ (stored 0%)\n",
            "  adding: content/models/research/deep_speech/README.md (deflated 57%)\n",
            "  adding: content/models/research/deep_speech/decoder.py (deflated 58%)\n",
            "  adding: content/models/research/deep_speech/__init__.py (stored 0%)\n",
            "  adding: content/models/research/deep_speech/deep_speech.py (deflated 67%)\n",
            "  adding: content/models/research/deep_speech/deep_speech_model.py (deflated 65%)\n",
            "  adding: content/models/research/deep_speech/run_deep_speech.sh (deflated 63%)\n",
            "  adding: content/models/research/deep_speech/requirements.txt (deflated 13%)\n",
            "  adding: content/models/research/deep_speech/data/ (stored 0%)\n",
            "  adding: content/models/research/deep_speech/data/featurizer.py (deflated 58%)\n",
            "  adding: content/models/research/deep_speech/data/dataset.py (deflated 67%)\n",
            "  adding: content/models/research/deep_speech/data/__init__.py (stored 0%)\n",
            "  adding: content/models/research/deep_speech/data/download.py (deflated 66%)\n",
            "  adding: content/models/research/deep_speech/data/vocabulary.txt (deflated 27%)\n",
            "  adding: content/models/research/cvt_text/ (stored 0%)\n",
            "  adding: content/models/research/cvt_text/README.md (deflated 50%)\n",
            "  adding: content/models/research/cvt_text/__init__.py (stored 0%)\n",
            "  adding: content/models/research/cvt_text/corpus_processing/ (stored 0%)\n",
            "  adding: content/models/research/cvt_text/corpus_processing/example.py (deflated 56%)\n",
            "  adding: content/models/research/cvt_text/corpus_processing/scorer.py (deflated 54%)\n",
            "  adding: content/models/research/cvt_text/corpus_processing/__init__.py (stored 0%)\n",
            "  adding: content/models/research/cvt_text/corpus_processing/unlabeled_data.py (deflated 59%)\n",
            "  adding: content/models/research/cvt_text/corpus_processing/minibatching.py (deflated 63%)\n",
            "  adding: content/models/research/cvt_text/training/ (stored 0%)\n",
            "  adding: content/models/research/cvt_text/training/trainer.py (deflated 66%)\n",
            "  adding: content/models/research/cvt_text/training/__init__.py (stored 0%)\n",
            "  adding: content/models/research/cvt_text/training/training_progress.py (deflated 61%)\n",
            "  adding: content/models/research/cvt_text/base/ (stored 0%)\n",
            "  adding: content/models/research/cvt_text/base/__init__.py (stored 0%)\n",
            "  adding: content/models/research/cvt_text/base/configure.py (deflated 63%)\n",
            "  adding: content/models/research/cvt_text/base/embeddings.py (deflated 60%)\n",
            "  adding: content/models/research/cvt_text/base/utils.py (deflated 52%)\n",
            "  adding: content/models/research/cvt_text/fetch_data.sh (deflated 55%)\n",
            "  adding: content/models/research/cvt_text/preprocessing.py (deflated 60%)\n",
            "  adding: content/models/research/cvt_text/cvt.py (deflated 57%)\n",
            "  adding: content/models/research/cvt_text/task_specific/ (stored 0%)\n",
            "  adding: content/models/research/cvt_text/task_specific/word_level/ (stored 0%)\n",
            "  adding: content/models/research/cvt_text/task_specific/word_level/__init__.py (stored 0%)\n",
            "  adding: content/models/research/cvt_text/task_specific/word_level/depparse_scorer.py (deflated 55%)\n",
            "  adding: content/models/research/cvt_text/task_specific/word_level/word_level_scorer.py (deflated 55%)\n",
            "  adding: content/models/research/cvt_text/task_specific/word_level/depparse_module.py (deflated 67%)\n",
            "  adding: content/models/research/cvt_text/task_specific/word_level/word_level_data.py (deflated 66%)\n",
            "  adding: content/models/research/cvt_text/task_specific/word_level/tagging_utils.py (deflated 56%)\n",
            "  adding: content/models/research/cvt_text/task_specific/word_level/tagging_module.py (deflated 61%)\n",
            "  adding: content/models/research/cvt_text/task_specific/word_level/tagging_scorers.py (deflated 64%)\n",
            "  adding: content/models/research/cvt_text/task_specific/__init__.py (stored 0%)\n",
            "  adding: content/models/research/cvt_text/task_specific/task_definitions.py (deflated 64%)\n",
            "  adding: content/models/research/cvt_text/model/ (stored 0%)\n",
            "  adding: content/models/research/cvt_text/model/multitask_model.py (deflated 68%)\n",
            "  adding: content/models/research/cvt_text/model/model_helpers.py (deflated 56%)\n",
            "  adding: content/models/research/cvt_text/model/__init__.py (stored 0%)\n",
            "  adding: content/models/research/cvt_text/model/task_module.py (deflated 53%)\n",
            "  adding: content/models/research/cvt_text/model/shared_inputs.py (deflated 59%)\n",
            "  adding: content/models/research/cvt_text/model/encoder.py (deflated 72%)\n",
            "  adding: content/models/research/cognitive_planning/ (stored 0%)\n",
            "  adding: content/models/research/cognitive_planning/train_supervised_active_vision.py (deflated 69%)\n",
            "  adding: content/models/research/cognitive_planning/README.md (deflated 63%)\n",
            "  adding: content/models/research/cognitive_planning/string_int_label_map_pb2.py (deflated 73%)\n",
            "  adding: content/models/research/cognitive_planning/__init__.py (stored 0%)\n",
            "  adding: content/models/research/cognitive_planning/standard_fields.py (deflated 74%)\n",
            "  adding: content/models/research/cognitive_planning/visualization_utils.py (deflated 76%)\n",
            "  adding: content/models/research/cognitive_planning/viz_active_vision_dataset_main.py (deflated 69%)\n",
            "  adding: content/models/research/cognitive_planning/policies.py (deflated 72%)\n",
            "  adding: content/models/research/cognitive_planning/train_supervised_active_vision.sh (deflated 48%)\n",
            "  adding: content/models/research/cognitive_planning/label_map.txt (deflated 78%)\n",
            "  adding: content/models/research/cognitive_planning/label_map_util.py (deflated 66%)\n",
            "  adding: content/models/research/cognitive_planning/envs/ (stored 0%)\n",
            "  adding: content/models/research/cognitive_planning/envs/util.py (deflated 53%)\n",
            "  adding: content/models/research/cognitive_planning/envs/__init__.py (stored 0%)\n",
            "  adding: content/models/research/cognitive_planning/envs/task_env.py (deflated 66%)\n",
            "  adding: content/models/research/cognitive_planning/envs/configs/ (stored 0%)\n",
            "  adding: content/models/research/cognitive_planning/envs/configs/active_vision_config.gin (deflated 64%)\n",
            "  adding: content/models/research/cognitive_planning/envs/active_vision_dataset_env.py (deflated 74%)\n",
            "  adding: content/models/research/cognitive_planning/embedders.py (deflated 74%)\n",
            "  adding: content/models/research/cognitive_planning/tasks.py (deflated 77%)\n",
            "  adding: content/models/research/cognitive_planning/preprocessing/ (stored 0%)\n",
            "  adding: content/models/research/cognitive_planning/preprocessing/vgg_preprocessing.py (deflated 73%)\n",
            "  adding: content/models/research/cognitive_planning/preprocessing/__init__.py (stored 0%)\n",
            "  adding: content/models/research/cognitive_planning/preprocessing/cifarnet_preprocessing.py (deflated 71%)\n",
            "  adding: content/models/research/cognitive_planning/preprocessing/inception_preprocessing.py (deflated 73%)\n",
            "  adding: content/models/research/cognitive_planning/preprocessing/preprocessing_factory.py (deflated 67%)\n",
            "  adding: content/models/research/cognitive_planning/preprocessing/lenet_preprocessing.py (deflated 52%)\n",
            "  adding: content/models/research/cognitive_planning/command (deflated 46%)\n",
            "  adding: content/models/research/cognitive_planning/BUILD (deflated 40%)\n",
            "  adding: content/models/research/efficient-hrl/ (stored 0%)\n",
            "  adding: content/models/research/efficient-hrl/utils/ (stored 0%)\n",
            "  adding: content/models/research/efficient-hrl/utils/__init__.py (stored 0%)\n",
            "  adding: content/models/research/efficient-hrl/utils/eval_utils.py (deflated 68%)\n",
            "  adding: content/models/research/efficient-hrl/utils/utils.py (deflated 66%)\n",
            "  adding: content/models/research/efficient-hrl/README.md (deflated 54%)\n",
            "  adding: content/models/research/efficient-hrl/train.py (deflated 77%)\n",
            "  adding: content/models/research/efficient-hrl/run_train.py (deflated 49%)\n",
            "  adding: content/models/research/efficient-hrl/agent.py (deflated 78%)\n",
            "  adding: content/models/research/efficient-hrl/cond_fn.py (deflated 79%)\n",
            "  adding: content/models/research/efficient-hrl/scripts/ (stored 0%)\n",
            "  adding: content/models/research/efficient-hrl/scripts/local_eval.py (deflated 59%)\n",
            "  adding: content/models/research/efficient-hrl/scripts/local_train.py (deflated 58%)\n",
            "  adding: content/models/research/efficient-hrl/run_env.py (deflated 62%)\n",
            "  adding: content/models/research/efficient-hrl/context/ (stored 0%)\n",
            "  adding: content/models/research/efficient-hrl/context/gin_imports.py (deflated 50%)\n",
            "  adding: content/models/research/efficient-hrl/context/__init__.py (stored 0%)\n",
            "  adding: content/models/research/efficient-hrl/context/gin_utils.py (deflated 50%)\n",
            "  adding: content/models/research/efficient-hrl/context/context.py (deflated 73%)\n",
            "  adding: content/models/research/efficient-hrl/context/context_transition_functions.py (deflated 66%)\n",
            "  adding: content/models/research/efficient-hrl/context/rewards_functions.py (deflated 86%)\n",
            "  adding: content/models/research/efficient-hrl/context/samplers.py (deflated 78%)\n",
            "  adding: content/models/research/efficient-hrl/context/configs/ (stored 0%)\n",
            "  adding: content/models/research/efficient-hrl/context/configs/ant_maze.gin (deflated 69%)\n",
            "  adding: content/models/research/efficient-hrl/context/configs/default.gin (deflated 29%)\n",
            "  adding: content/models/research/efficient-hrl/context/configs/ant_fall_multi.gin (deflated 68%)\n",
            "  adding: content/models/research/efficient-hrl/context/configs/ant_fall_single.gin (deflated 68%)\n",
            "  adding: content/models/research/efficient-hrl/context/configs/ant_block.gin (deflated 69%)\n",
            "  adding: content/models/research/efficient-hrl/context/configs/ant_push_multi_img.gin (deflated 70%)\n",
            "  adding: content/models/research/efficient-hrl/context/configs/ant_push_single.gin (deflated 68%)\n",
            "  adding: content/models/research/efficient-hrl/context/configs/hiro_orig.gin (deflated 46%)\n",
            "  adding: content/models/research/efficient-hrl/context/configs/hiro_repr.gin (deflated 43%)\n",
            "  adding: content/models/research/efficient-hrl/context/configs/ant_fall_multi_img.gin (deflated 70%)\n",
            "  adding: content/models/research/efficient-hrl/context/configs/hiro_xy.gin (deflated 32%)\n",
            "  adding: content/models/research/efficient-hrl/context/configs/ant_push_multi.gin (deflated 68%)\n",
            "  adding: content/models/research/efficient-hrl/context/configs/ant_maze_img.gin (deflated 71%)\n",
            "  adding: content/models/research/efficient-hrl/context/configs/point_maze.gin (deflated 69%)\n",
            "  adding: content/models/research/efficient-hrl/context/configs/ant_block_maze.gin (deflated 69%)\n",
            "  adding: content/models/research/efficient-hrl/eval.py (deflated 72%)\n",
            "  adding: content/models/research/efficient-hrl/environments/ (stored 0%)\n",
            "  adding: content/models/research/efficient-hrl/environments/ant_maze_env.py (deflated 44%)\n",
            "  adding: content/models/research/efficient-hrl/environments/__init__.py (stored 0%)\n",
            "  adding: content/models/research/efficient-hrl/environments/maze_env.py (deflated 76%)\n",
            "  adding: content/models/research/efficient-hrl/environments/ant.py (deflated 62%)\n",
            "  adding: content/models/research/efficient-hrl/environments/point.py (deflated 57%)\n",
            "  adding: content/models/research/efficient-hrl/environments/maze_env_utils.py (deflated 62%)\n",
            "  adding: content/models/research/efficient-hrl/environments/assets/ (stored 0%)\n",
            "  adding: content/models/research/efficient-hrl/environments/assets/ant.xml (deflated 78%)\n",
            "  adding: content/models/research/efficient-hrl/environments/create_maze_env.py (deflated 61%)\n",
            "  adding: content/models/research/efficient-hrl/environments/point_maze_env.py (deflated 44%)\n",
            "  adding: content/models/research/efficient-hrl/agents/ (stored 0%)\n",
            "  adding: content/models/research/efficient-hrl/agents/__init__.py (stored 0%)\n",
            "  adding: content/models/research/efficient-hrl/agents/ddpg_networks.py (deflated 71%)\n",
            "  adding: content/models/research/efficient-hrl/agents/ddpg_agent.py (deflated 83%)\n",
            "  adding: content/models/research/efficient-hrl/agents/circular_buffer.py (deflated 72%)\n",
            "  adding: content/models/research/efficient-hrl/train_utils.py (deflated 68%)\n",
            "  adding: content/models/research/efficient-hrl/run_eval.py (deflated 51%)\n",
            "  adding: content/models/research/efficient-hrl/configs/ (stored 0%)\n",
            "  adding: content/models/research/efficient-hrl/configs/base_uvf.gin (deflated 71%)\n",
            "  adding: content/models/research/efficient-hrl/configs/eval_uvf.gin (deflated 48%)\n",
            "  adding: content/models/research/efficient-hrl/configs/train_uvf.gin (deflated 70%)\n",
            "  adding: content/models/research/slim/ (stored 0%)\n",
            "  adding: content/models/research/slim/README.md (deflated 70%)\n",
            "  adding: content/models/research/slim/export_inference_graph_test.py (deflated 49%)\n",
            "  adding: content/models/research/slim/__init__.py (stored 0%)\n",
            "  adding: content/models/research/slim/scripts/ (stored 0%)\n",
            "  adding: content/models/research/slim/scripts/finetune_inception_resnet_v2_on_flowers.sh (deflated 68%)\n",
            "  adding: content/models/research/slim/scripts/finetune_inception_v1_on_flowers.sh (deflated 67%)\n",
            "  adding: content/models/research/slim/scripts/finetune_inception_v3_on_flowers.sh (deflated 67%)\n",
            "  adding: content/models/research/slim/scripts/train_lenet_on_mnist.sh (deflated 54%)\n",
            "  adding: content/models/research/slim/scripts/export_mobilenet.sh (deflated 63%)\n",
            "  adding: content/models/research/slim/scripts/train_cifarnet_on_cifar10.sh (deflated 55%)\n",
            "  adding: content/models/research/slim/scripts/finetune_resnet_v1_50_on_flowers.sh (deflated 67%)\n",
            "  adding: content/models/research/slim/setup.py (deflated 47%)\n",
            "  adding: content/models/research/slim/eval_image_classifier.py (deflated 66%)\n",
            "  adding: content/models/research/slim/download_and_convert_data.py (deflated 64%)\n",
            "  adding: content/models/research/slim/datasets/ (stored 0%)\n",
            "  adding: content/models/research/slim/datasets/download_imagenet.sh (deflated 59%)\n",
            "  adding: content/models/research/slim/datasets/build_imagenet_data.py (deflated 73%)\n",
            "  adding: content/models/research/slim/datasets/download_and_convert_mnist.py (deflated 67%)\n",
            "  adding: content/models/research/slim/datasets/cifar10.py (deflated 56%)\n",
            "  adding: content/models/research/slim/datasets/dataset_utils.py (deflated 68%)\n",
            "  adding: content/models/research/slim/datasets/mnist.py (deflated 56%)\n",
            "  adding: content/models/research/slim/datasets/flowers.py (deflated 56%)\n",
            "  adding: content/models/research/slim/datasets/__init__.py (stored 0%)\n",
            "  adding: content/models/research/slim/datasets/download_and_convert_visualwakewords_lib.py (deflated 72%)\n",
            "  adding: content/models/research/slim/datasets/download_and_convert_flowers.py (deflated 64%)\n",
            "  adding: content/models/research/slim/datasets/visualwakewords.py (deflated 60%)\n",
            "  adding: content/models/research/slim/datasets/process_bounding_boxes.py (deflated 63%)\n",
            "  adding: content/models/research/slim/datasets/download_and_convert_cifar10.py (deflated 63%)\n",
            "  adding: content/models/research/slim/datasets/dataset_factory.py (deflated 54%)\n",
            "  adding: content/models/research/slim/datasets/preprocess_imagenet_validation_data.py (deflated 56%)\n",
            "  adding: content/models/research/slim/datasets/download_and_convert_visualwakewords.py (deflated 67%)\n",
            "  adding: content/models/research/slim/datasets/imagenet_2012_validation_synset_labels.txt (deflated 76%)\n",
            "  adding: content/models/research/slim/datasets/imagenet_metadata.txt (deflated 60%)\n",
            "  adding: content/models/research/slim/datasets/imagenet_lsvrc_2015_synsets.txt (deflated 62%)\n",
            "  adding: content/models/research/slim/datasets/imagenet.py (deflated 61%)\n",
            "  adding: content/models/research/slim/datasets/download_and_convert_imagenet.sh (deflated 60%)\n",
            "  adding: content/models/research/slim/export_inference_graph.py (deflated 63%)\n",
            "  adding: content/models/research/slim/train_image_classifier.py (deflated 73%)\n",
            "  adding: content/models/research/slim/preprocessing/ (stored 0%)\n",
            "  adding: content/models/research/slim/preprocessing/vgg_preprocessing.py (deflated 73%)\n",
            "  adding: content/models/research/slim/preprocessing/__init__.py (stored 0%)\n",
            "  adding: content/models/research/slim/preprocessing/cifarnet_preprocessing.py (deflated 73%)\n",
            "  adding: content/models/research/slim/preprocessing/inception_preprocessing.py (deflated 74%)\n",
            "  adding: content/models/research/slim/preprocessing/preprocessing_factory.py (deflated 70%)\n",
            "  adding: content/models/research/slim/preprocessing/lenet_preprocessing.py (deflated 55%)\n",
            "  adding: content/models/research/slim/nets/ (stored 0%)\n",
            "  adding: content/models/research/slim/nets/resnet_v1_test.py (deflated 83%)\n",
            "  adding: content/models/research/slim/nets/mobilenet_v1.png (deflated 2%)\n",
            "  adding: content/models/research/slim/nets/mobilenet_v1.md (deflated 74%)\n",
            "  adding: content/models/research/slim/nets/inception_v4_test.py (deflated 82%)\n",
            "  adding: content/models/research/slim/nets/i3d_utils.py (deflated 72%)\n",
            "  adding: content/models/research/slim/nets/__pycache__/ (stored 0%)\n",
            "  adding: content/models/research/slim/nets/__pycache__/inception_resnet_v2.cpython-37.pyc (deflated 56%)\n",
            "  adding: content/models/research/slim/nets/__pycache__/mobilenet_v1.cpython-37.pyc (deflated 64%)\n",
            "  adding: content/models/research/slim/nets/__pycache__/inception_v2.cpython-37.pyc (deflated 66%)\n",
            "  adding: content/models/research/slim/nets/__pycache__/inception_v3.cpython-37.pyc (deflated 67%)\n",
            "  adding: content/models/research/slim/nets/__pycache__/resnet_v1.cpython-37.pyc (deflated 60%)\n",
            "  adding: content/models/research/slim/nets/__pycache__/__init__.cpython-37.pyc (deflated 23%)\n",
            "  adding: content/models/research/slim/nets/__pycache__/resnet_utils.cpython-37.pyc (deflated 55%)\n",
            "  adding: content/models/research/slim/nets/__pycache__/inception_utils.cpython-37.pyc (deflated 45%)\n",
            "  adding: content/models/research/slim/nets/post_training_quantization.py (deflated 63%)\n",
            "  adding: content/models/research/slim/nets/mobilenet/ (stored 0%)\n",
            "  adding: content/models/research/slim/nets/mobilenet/mobilenet.py (deflated 66%)\n",
            "  adding: content/models/research/slim/nets/mobilenet/__pycache__/ (stored 0%)\n",
            "  adding: content/models/research/slim/nets/mobilenet/__pycache__/mobilenet_v3.cpython-37.pyc (deflated 87%)\n",
            "  adding: content/models/research/slim/nets/mobilenet/__pycache__/mobilenet_v2.cpython-37.pyc (deflated 49%)\n",
            "  adding: content/models/research/slim/nets/mobilenet/__pycache__/conv_blocks.cpython-37.pyc (deflated 55%)\n",
            "  adding: content/models/research/slim/nets/mobilenet/__pycache__/__init__.cpython-37.pyc (deflated 23%)\n",
            "  adding: content/models/research/slim/nets/mobilenet/__pycache__/mobilenet.cpython-37.pyc (deflated 53%)\n",
            "  adding: content/models/research/slim/nets/mobilenet/README.md (deflated 76%)\n",
            "  adding: content/models/research/slim/nets/mobilenet/mobilenet_example.ipynb (deflated 28%)\n",
            "  adding: content/models/research/slim/nets/mobilenet/__init__.py (stored 0%)\n",
            "  adding: content/models/research/slim/nets/mobilenet/mobilenet_v2.py (deflated 68%)\n",
            "  adding: content/models/research/slim/nets/mobilenet/conv_blocks.py (deflated 71%)\n",
            "  adding: content/models/research/slim/nets/mobilenet/mobilenet_v3_test.py (deflated 76%)\n",
            "  adding: content/models/research/slim/nets/mobilenet/mobilenet_v2_test.py (deflated 72%)\n",
            "  adding: content/models/research/slim/nets/mobilenet/g3doc/ (stored 0%)\n",
            "  adding: content/models/research/slim/nets/mobilenet/g3doc/madds_top1_accuracy.png (deflated 2%)\n",
            "  adding: content/models/research/slim/nets/mobilenet/g3doc/latency_pixel1.png (deflated 1%)\n",
            "  adding: content/models/research/slim/nets/mobilenet/g3doc/edgetpu_latency.png (deflated 8%)\n",
            "  adding: content/models/research/slim/nets/mobilenet/mobilenet_v3.py (deflated 88%)\n",
            "  adding: content/models/research/slim/nets/mobilenet/mnet_v1_vs_v2_pixel1_latency.png (deflated 10%)\n",
            "  adding: content/models/research/slim/nets/resnet_utils.py (deflated 65%)\n",
            "  adding: content/models/research/slim/nets/resnet_v2.py (deflated 73%)\n",
            "  adding: content/models/research/slim/nets/alexnet_test.py (deflated 80%)\n",
            "  adding: content/models/research/slim/nets/cyclegan_test.py (deflated 71%)\n",
            "  adding: content/models/research/slim/nets/inception_v3.py (deflated 84%)\n",
            "  adding: content/models/research/slim/nets/inception_v2_test.py (deflated 82%)\n",
            "  adding: content/models/research/slim/nets/inception_resnet_v2_test.py (deflated 84%)\n",
            "  adding: content/models/research/slim/nets/inception_v3_test.py (deflated 82%)\n",
            "  adding: content/models/research/slim/nets/inception_v2.py (deflated 83%)\n",
            "  adding: content/models/research/slim/nets/inception.py (deflated 65%)\n",
            "  adding: content/models/research/slim/nets/__init__.py (stored 0%)\n",
            "  adding: content/models/research/slim/nets/s3dg.py (deflated 80%)\n",
            "  adding: content/models/research/slim/nets/inception_v1.py (deflated 83%)\n",
            "  adding: content/models/research/slim/nets/inception_utils.py (deflated 59%)\n",
            "  adding: content/models/research/slim/nets/nasnet/ (stored 0%)\n",
            "  adding: content/models/research/slim/nets/nasnet/__pycache__/ (stored 0%)\n",
            "  adding: content/models/research/slim/nets/nasnet/__pycache__/nasnet_utils.cpython-37.pyc (deflated 53%)\n",
            "  adding: content/models/research/slim/nets/nasnet/__pycache__/__init__.cpython-37.pyc (deflated 22%)\n",
            "  adding: content/models/research/slim/nets/nasnet/__pycache__/nasnet.cpython-37.pyc (deflated 59%)\n",
            "  adding: content/models/research/slim/nets/nasnet/__pycache__/pnasnet.cpython-37.pyc (deflated 50%)\n",
            "  adding: content/models/research/slim/nets/nasnet/README.md (deflated 61%)\n",
            "  adding: content/models/research/slim/nets/nasnet/__init__.py (stored 0%)\n",
            "  adding: content/models/research/slim/nets/nasnet/pnasnet_test.py (deflated 83%)\n",
            "  adding: content/models/research/slim/nets/nasnet/nasnet_utils.py (deflated 74%)\n",
            "  adding: content/models/research/slim/nets/nasnet/nasnet_utils_test.py (deflated 61%)\n",
            "  adding: content/models/research/slim/nets/nasnet/nasnet.py (deflated 81%)\n",
            "  adding: content/models/research/slim/nets/nasnet/pnasnet.py (deflated 75%)\n",
            "  adding: content/models/research/slim/nets/nasnet/nasnet_test.py (deflated 87%)\n",
            "  adding: content/models/research/slim/nets/overfeat.py (deflated 65%)\n",
            "  adding: content/models/research/slim/nets/pix2pix_test.py (deflated 76%)\n",
            "  adding: content/models/research/slim/nets/vgg_test.py (deflated 91%)\n",
            "  adding: content/models/research/slim/nets/dcgan.py (deflated 70%)\n",
            "  adding: content/models/research/slim/nets/alexnet.py (deflated 63%)\n",
            "  adding: content/models/research/slim/nets/nets_factory_test.py (deflated 72%)\n",
            "  adding: content/models/research/slim/nets/nets_factory.py (deflated 72%)\n",
            "  adding: content/models/research/slim/nets/cyclegan.py (deflated 68%)\n",
            "  adding: content/models/research/slim/nets/mobilenet_v1.py (deflated 74%)\n",
            "  adding: content/models/research/slim/nets/cifarnet.py (deflated 61%)\n",
            "  adding: content/models/research/slim/nets/mobilenet_v1_train.py (deflated 65%)\n",
            "  adding: content/models/research/slim/nets/inception_v1_test.py (deflated 80%)\n",
            "  adding: content/models/research/slim/nets/inception_resnet_v2.py (deflated 77%)\n",
            "  adding: content/models/research/slim/nets/lenet.py (deflated 58%)\n",
            "  adding: content/models/research/slim/nets/dcgan_test.py (deflated 67%)\n",
            "  adding: content/models/research/slim/nets/pix2pix.py (deflated 66%)\n",
            "  adding: content/models/research/slim/nets/mobilenet_v1_eval.py (deflated 62%)\n",
            "  adding: content/models/research/slim/nets/s3dg_test.py (deflated 74%)\n",
            "  adding: content/models/research/slim/nets/inception_v4.py (deflated 81%)\n",
            "  adding: content/models/research/slim/nets/vgg.py (deflated 82%)\n",
            "  adding: content/models/research/slim/nets/i3d.py (deflated 62%)\n",
            "  adding: content/models/research/slim/nets/overfeat_test.py (deflated 80%)\n",
            "  adding: content/models/research/slim/nets/mobilenet_v1_test.py (deflated 88%)\n",
            "  adding: content/models/research/slim/nets/resnet_v1.py (deflated 74%)\n",
            "  adding: content/models/research/slim/nets/resnet_v2_test.py (deflated 81%)\n",
            "  adding: content/models/research/slim/nets/i3d_test.py (deflated 74%)\n",
            "  adding: content/models/research/slim/WORKSPACE (stored 0%)\n",
            "  adding: content/models/research/slim/deployment/ (stored 0%)\n",
            "  adding: content/models/research/slim/deployment/model_deploy_test.py (deflated 88%)\n",
            "  adding: content/models/research/slim/deployment/__init__.py (stored 0%)\n",
            "  adding: content/models/research/slim/deployment/model_deploy.py (deflated 74%)\n",
            "  adding: content/models/research/slim/slim_walkthrough.ipynb (deflated 78%)\n",
            "  adding: content/models/research/slim/BUILD (deflated 91%)\n",
            "  adding: content/models/research/pcl_rl/ (stored 0%)\n",
            "  adding: content/models/research/pcl_rl/trainer.py (deflated 73%)\n",
            "  adding: content/models/research/pcl_rl/README.md (deflated 64%)\n",
            "  adding: content/models/research/pcl_rl/trust_region.py (deflated 65%)\n",
            "  adding: content/models/research/pcl_rl/env_spec.py (deflated 71%)\n",
            "  adding: content/models/research/pcl_rl/baseline.py (deflated 73%)\n",
            "  adding: content/models/research/pcl_rl/replay_buffer.py (deflated 70%)\n",
            "  adding: content/models/research/pcl_rl/full_episode_objective.py (deflated 61%)\n",
            "  adding: content/models/research/pcl_rl/policy.py (deflated 78%)\n",
            "  adding: content/models/research/pcl_rl/controller.py (deflated 74%)\n",
            "  adding: content/models/research/pcl_rl/expert_paths.py (deflated 71%)\n",
            "  adding: content/models/research/pcl_rl/model.py (deflated 78%)\n",
            "  adding: content/models/research/pcl_rl/optimizers.py (deflated 72%)\n",
            "  adding: content/models/research/pcl_rl/gym_wrapper.py (deflated 62%)\n",
            "  adding: content/models/research/pcl_rl/objective.py (deflated 81%)\n",
            "  adding: content/models/research/delf/ (stored 0%)\n",
            "  adding: content/models/research/delf/README.md (deflated 67%)\n",
            "  adding: content/models/research/delf/EXTRACTION_MATCHING.md (deflated 58%)\n",
            "  adding: content/models/research/delf/setup.py (deflated 47%)\n",
            "  adding: content/models/research/delf/.gitignore (deflated 20%)\n",
            "  adding: content/models/research/delf/DETECTION.md (deflated 53%)\n",
            "  adding: content/models/research/delf/INSTALL_INSTRUCTIONS.md (deflated 64%)\n",
            "  adding: content/models/research/delf/delf/ (stored 0%)\n",
            "  adding: content/models/research/delf/delf/__init__.py (deflated 62%)\n",
            "  adding: content/models/research/delf/delf/protos/ (stored 0%)\n",
            "  adding: content/models/research/delf/delf/protos/aggregation_config.proto (deflated 59%)\n",
            "  adding: content/models/research/delf/delf/protos/__init__.py (stored 0%)\n",
            "  adding: content/models/research/delf/delf/protos/box.proto (deflated 44%)\n",
            "  adding: content/models/research/delf/delf/protos/feature.proto (deflated 48%)\n",
            "  adding: content/models/research/delf/delf/protos/datum.proto (deflated 59%)\n",
            "  adding: content/models/research/delf/delf/protos/delf_config.proto (deflated 67%)\n",
            "  adding: content/models/research/delf/delf/python/ (stored 0%)\n",
            "  adding: content/models/research/delf/delf/python/pooling_layers/ (stored 0%)\n",
            "  adding: content/models/research/delf/delf/python/pooling_layers/pooling_test.py (deflated 66%)\n",
            "  adding: content/models/research/delf/delf/python/pooling_layers/__init__.py (deflated 44%)\n",
            "  adding: content/models/research/delf/delf/python/pooling_layers/pooling.py (deflated 69%)\n",
            "  adding: content/models/research/delf/delf/python/detect_to_retrieve/ (stored 0%)\n",
            "  adding: content/models/research/delf/delf/python/detect_to_retrieve/perform_retrieval.py (deflated 72%)\n",
            "  adding: content/models/research/delf/delf/python/detect_to_retrieve/extract_index_boxes_and_features.py (deflated 64%)\n",
            "  adding: content/models/research/delf/delf/python/detect_to_retrieve/cluster_delf_features.py (deflated 63%)\n",
            "  adding: content/models/research/delf/delf/python/detect_to_retrieve/__init__.py (deflated 49%)\n",
            "  adding: content/models/research/delf/delf/python/detect_to_retrieve/delf_gld_config.pbtxt (deflated 53%)\n",
            "  adding: content/models/research/delf/delf/python/detect_to_retrieve/extract_aggregation.py (deflated 61%)\n",
            "  adding: content/models/research/delf/delf/python/detect_to_retrieve/aggregation_extraction.py (deflated 68%)\n",
            "  adding: content/models/research/delf/delf/python/detect_to_retrieve/boxes_and_features_extraction.py (deflated 67%)\n",
            "  adding: content/models/research/delf/delf/python/detect_to_retrieve/image_reranking.py (deflated 71%)\n",
            "  adding: content/models/research/delf/delf/python/detect_to_retrieve/query_aggregation_config.pbtxt (deflated 32%)\n",
            "  adding: content/models/research/delf/delf/python/detect_to_retrieve/extract_query_features.py (deflated 61%)\n",
            "  adding: content/models/research/delf/delf/python/detect_to_retrieve/DETECT_TO_RETRIEVE_INSTRUCTIONS.md (deflated 73%)\n",
            "  adding: content/models/research/delf/delf/python/detect_to_retrieve/index_aggregation_config.pbtxt (deflated 34%)\n",
            "  adding: content/models/research/delf/delf/python/feature_io.py (deflated 77%)\n",
            "  adding: content/models/research/delf/delf/python/examples/ (stored 0%)\n",
            "  adding: content/models/research/delf/delf/python/examples/delf_config_example.pbtxt (deflated 53%)\n",
            "  adding: content/models/research/delf/delf/python/examples/matched_images_example.jpg (deflated 0%)\n",
            "  adding: content/models/research/delf/delf/python/examples/detector.py (deflated 52%)\n",
            "  adding: content/models/research/delf/delf/python/examples/match_images.py (deflated 62%)\n",
            "  adding: content/models/research/delf/delf/python/examples/__init__.py (stored 0%)\n",
            "  adding: content/models/research/delf/delf/python/examples/detection_example_1.jpg (deflated 3%)\n",
            "  adding: content/models/research/delf/delf/python/examples/extractor.py (deflated 75%)\n",
            "  adding: content/models/research/delf/delf/python/examples/detection_example_2.jpg (deflated 2%)\n",
            "  adding: content/models/research/delf/delf/python/examples/extract_boxes.py (deflated 64%)\n",
            "  adding: content/models/research/delf/delf/python/examples/extract_features.py (deflated 60%)\n",
            "  adding: content/models/research/delf/delf/python/feature_aggregation_extractor_test.py (deflated 89%)\n",
            "  adding: content/models/research/delf/delf/python/__init__.py (stored 0%)\n",
            "  adding: content/models/research/delf/delf/python/box_io_test.py (deflated 62%)\n",
            "  adding: content/models/research/delf/delf/python/training/ (stored 0%)\n",
            "  adding: content/models/research/delf/delf/python/training/README.md (deflated 67%)\n",
            "  adding: content/models/research/delf/delf/python/training/download_dataset.sh (deflated 67%)\n",
            "  adding: content/models/research/delf/delf/python/training/train.py (deflated 73%)\n",
            "  adding: content/models/research/delf/delf/python/training/matched_images_demo.png (deflated 1%)\n",
            "  adding: content/models/research/delf/delf/python/training/__init__.py (deflated 47%)\n",
            "  adding: content/models/research/delf/delf/python/training/losses/ (stored 0%)\n",
            "  adding: content/models/research/delf/delf/python/training/losses/__init__.py (deflated 44%)\n",
            "  adding: content/models/research/delf/delf/python/training/losses/ranking_losses_test.py (deflated 67%)\n",
            "  adding: content/models/research/delf/delf/python/training/losses/ranking_losses.py (deflated 72%)\n",
            "  adding: content/models/research/delf/delf/python/training/tensorboard_utils.py (deflated 47%)\n",
            "  adding: content/models/research/delf/delf/python/training/build_image_dataset.py (deflated 72%)\n",
            "  adding: content/models/research/delf/delf/python/training/install_delf.sh (deflated 67%)\n",
            "  adding: content/models/research/delf/delf/python/training/global_features_utils.py (deflated 67%)\n",
            "  adding: content/models/research/delf/delf/python/training/global_features/ (stored 0%)\n",
            "  adding: content/models/research/delf/delf/python/training/global_features/README.md (deflated 56%)\n",
            "  adding: content/models/research/delf/delf/python/training/global_features/train.py (deflated 69%)\n",
            "  adding: content/models/research/delf/delf/python/training/global_features/__init__.py (deflated 45%)\n",
            "  adding: content/models/research/delf/delf/python/training/global_features/train_utils.py (deflated 71%)\n",
            "  adding: content/models/research/delf/delf/python/training/model/ (stored 0%)\n",
            "  adding: content/models/research/delf/delf/python/training/model/delf_model.py (deflated 69%)\n",
            "  adding: content/models/research/delf/delf/python/training/model/delg_model.py (deflated 69%)\n",
            "  adding: content/models/research/delf/delf/python/training/model/export_model_utils.py (deflated 77%)\n",
            "  adding: content/models/research/delf/delf/python/training/model/delf_model_test.py (deflated 64%)\n",
            "  adding: content/models/research/delf/delf/python/training/model/__init__.py (deflated 53%)\n",
            "  adding: content/models/research/delf/delf/python/training/model/global_model.py (deflated 66%)\n",
            "  adding: content/models/research/delf/delf/python/training/model/export_global_model.py (deflated 69%)\n",
            "  adding: content/models/research/delf/delf/python/training/model/export_local_and_global_model.py (deflated 67%)\n",
            "  adding: content/models/research/delf/delf/python/training/model/delg_model_test.py (deflated 70%)\n",
            "  adding: content/models/research/delf/delf/python/training/model/export_CNN_global.py (deflated 67%)\n",
            "  adding: content/models/research/delf/delf/python/training/model/export_local_model.py (deflated 62%)\n",
            "  adding: content/models/research/delf/delf/python/training/model/global_model_test.py (deflated 61%)\n",
            "  adding: content/models/research/delf/delf/python/training/model/resnet50.py (deflated 76%)\n",
            "  adding: content/models/research/delf/delf/python/feature_aggregation_extractor.py (deflated 77%)\n",
            "  adding: content/models/research/delf/delf/python/delg/ (stored 0%)\n",
            "  adding: content/models/research/delf/delf/python/delg/perform_retrieval.py (deflated 70%)\n",
            "  adding: content/models/research/delf/delf/python/delg/r50delg_gld_config.pbtxt (deflated 55%)\n",
            "  adding: content/models/research/delf/delf/python/delg/measure_latency.py (deflated 58%)\n",
            "  adding: content/models/research/delf/delf/python/delg/r101delg_gldv2clean_config.pbtxt (deflated 54%)\n",
            "  adding: content/models/research/delf/delf/python/delg/r101delg_gld_config.pbtxt (deflated 54%)\n",
            "  adding: content/models/research/delf/delf/python/delg/r50delg_gldv2clean_config.pbtxt (deflated 54%)\n",
            "  adding: content/models/research/delf/delf/python/delg/DELG_INSTRUCTIONS.md (deflated 68%)\n",
            "  adding: content/models/research/delf/delf/python/delg/extract_features.py (deflated 64%)\n",
            "  adding: content/models/research/delf/delf/python/normalization_layers/ (stored 0%)\n",
            "  adding: content/models/research/delf/delf/python/normalization_layers/normalization.py (deflated 49%)\n",
            "  adding: content/models/research/delf/delf/python/normalization_layers/__init__.py (deflated 44%)\n",
            "  adding: content/models/research/delf/delf/python/normalization_layers/normalization_test.py (deflated 46%)\n",
            "  adding: content/models/research/delf/delf/python/feature_extractor_test.py (deflated 59%)\n",
            "  adding: content/models/research/delf/delf/python/datum_io_test.py (deflated 68%)\n",
            "  adding: content/models/research/delf/delf/python/utils_test.py (deflated 75%)\n",
            "  adding: content/models/research/delf/delf/python/datasets/ (stored 0%)\n",
            "  adding: content/models/research/delf/delf/python/datasets/generic_dataset_test.py (deflated 52%)\n",
            "  adding: content/models/research/delf/delf/python/datasets/generic_dataset.py (deflated 56%)\n",
            "  adding: content/models/research/delf/delf/python/datasets/tuples_dataset_test.py (deflated 54%)\n",
            "  adding: content/models/research/delf/delf/python/datasets/utils_test.py (deflated 59%)\n",
            "  adding: content/models/research/delf/delf/python/datasets/utils.py (deflated 59%)\n",
            "  adding: content/models/research/delf/delf/python/datasets/revisited_op/ (stored 0%)\n",
            "  adding: content/models/research/delf/delf/python/datasets/revisited_op/dataset.py (deflated 73%)\n",
            "  adding: content/models/research/delf/delf/python/datasets/revisited_op/__init__.py (deflated 47%)\n",
            "  adding: content/models/research/delf/delf/python/datasets/revisited_op/dataset_test.py (deflated 78%)\n",
            "  adding: content/models/research/delf/delf/python/datasets/google_landmarks_dataset/ (stored 0%)\n",
            "  adding: content/models/research/delf/delf/python/datasets/google_landmarks_dataset/googlelandmarks.py (deflated 65%)\n",
            "  adding: content/models/research/delf/delf/python/datasets/google_landmarks_dataset/dataset_file_io.py (deflated 69%)\n",
            "  adding: content/models/research/delf/delf/python/datasets/google_landmarks_dataset/README.md (deflated 64%)\n",
            "  adding: content/models/research/delf/delf/python/datasets/google_landmarks_dataset/rn101_af_gldv2clean_config.pbtxt (deflated 35%)\n",
            "  adding: content/models/research/delf/delf/python/datasets/google_landmarks_dataset/compute_recognition_metrics.py (deflated 66%)\n",
            "  adding: content/models/research/delf/delf/python/datasets/google_landmarks_dataset/__init__.py (deflated 48%)\n",
            "  adding: content/models/research/delf/delf/python/datasets/google_landmarks_dataset/metrics.py (deflated 75%)\n",
            "  adding: content/models/research/delf/delf/python/datasets/google_landmarks_dataset/compute_retrieval_metrics.py (deflated 68%)\n",
            "  adding: content/models/research/delf/delf/python/datasets/google_landmarks_dataset/dataset_file_io_test.py (deflated 77%)\n",
            "  adding: content/models/research/delf/delf/python/datasets/google_landmarks_dataset/metrics_test.py (deflated 79%)\n",
            "  adding: content/models/research/delf/delf/python/datasets/tuples_dataset.py (deflated 68%)\n",
            "  adding: content/models/research/delf/delf/python/datasets/sfm120k/ (stored 0%)\n",
            "  adding: content/models/research/delf/delf/python/datasets/sfm120k/__init__.py (deflated 47%)\n",
            "  adding: content/models/research/delf/delf/python/datasets/sfm120k/sfm120k_test.py (deflated 48%)\n",
            "  adding: content/models/research/delf/delf/python/datasets/sfm120k/sfm120k.py (deflated 64%)\n",
            "  adding: content/models/research/delf/delf/python/datasets/sfm120k/dataset_download.py (deflated 70%)\n",
            "  adding: content/models/research/delf/delf/python/feature_extractor.py (deflated 68%)\n",
            "  adding: content/models/research/delf/delf/python/whiten_test.py (deflated 63%)\n",
            "  adding: content/models/research/delf/delf/python/whiten.py (deflated 62%)\n",
            "  adding: content/models/research/delf/delf/python/utils.py (deflated 60%)\n",
            "  adding: content/models/research/delf/delf/python/feature_aggregation_similarity.py (deflated 74%)\n",
            "  adding: content/models/research/delf/delf/python/feature_io_test.py (deflated 71%)\n",
            "  adding: content/models/research/delf/delf/python/feature_aggregation_similarity_test.py (deflated 77%)\n",
            "  adding: content/models/research/delf/delf/python/box_io.py (deflated 72%)\n",
            "  adding: content/models/research/delf/delf/python/datum_io.py (deflated 73%)\n",
            "  adding: content/models/research/adversarial_text/ (stored 0%)\n",
            "  adding: content/models/research/adversarial_text/README.md (deflated 66%)\n",
            "  adding: content/models/research/adversarial_text/pretrain.py (deflated 46%)\n",
            "  adding: content/models/research/adversarial_text/layers.py (deflated 69%)\n",
            "  adding: content/models/research/adversarial_text/__init__.py (stored 0%)\n",
            "  adding: content/models/research/adversarial_text/graphs_test.py (deflated 67%)\n",
            "  adding: content/models/research/adversarial_text/gen_vocab.py (deflated 58%)\n",
            "  adding: content/models/research/adversarial_text/train_utils.py (deflated 63%)\n",
            "  adding: content/models/research/adversarial_text/train_classifier.py (deflated 53%)\n",
            "  adding: content/models/research/adversarial_text/graphs.py (deflated 78%)\n",
            "  adding: content/models/research/adversarial_text/evaluate.py (deflated 61%)\n",
            "  adding: content/models/research/adversarial_text/adversarial_losses.py (deflated 69%)\n",
            "  adding: content/models/research/adversarial_text/data/ (stored 0%)\n",
            "  adding: content/models/research/adversarial_text/data/data_utils_test.py (deflated 75%)\n",
            "  adding: content/models/research/adversarial_text/data/__init__.py (stored 0%)\n",
            "  adding: content/models/research/adversarial_text/data/data_utils.py (deflated 70%)\n",
            "  adding: content/models/research/adversarial_text/data/document_generators.py (deflated 74%)\n",
            "  adding: content/models/research/adversarial_text/gen_data.py (deflated 71%)\n",
            "  adding: content/models/research/adversarial_text/inputs.py (deflated 72%)\n",
            "  adding: content/models/research/attention_ocr/ (stored 0%)\n",
            "  adding: content/models/research/attention_ocr/README.md (deflated 63%)\n",
            "  adding: content/models/research/attention_ocr/python/ (stored 0%)\n",
            "  adding: content/models/research/attention_ocr/python/model_export.py (deflated 63%)\n",
            "  adding: content/models/research/attention_ocr/python/train.py (deflated 66%)\n",
            "  adding: content/models/research/attention_ocr/python/model_export_lib.py (deflated 61%)\n",
            "  adding: content/models/research/attention_ocr/python/common_flags.py (deflated 64%)\n",
            "  adding: content/models/research/attention_ocr/python/all_jobs.screenrc (deflated 55%)\n",
            "  adding: content/models/research/attention_ocr/python/eval.py (deflated 56%)\n",
            "  adding: content/models/research/attention_ocr/python/model_test.py (deflated 75%)\n",
            "  adding: content/models/research/attention_ocr/python/data_provider_test.py (deflated 60%)\n",
            "  adding: content/models/research/attention_ocr/python/inception_preprocessing.py (deflated 72%)\n",
            "  adding: content/models/research/attention_ocr/python/model_export_test.py (deflated 64%)\n",
            "  adding: content/models/research/attention_ocr/python/demo_inference_test.py (deflated 74%)\n",
            "  adding: content/models/research/attention_ocr/python/datasets/ (stored 0%)\n",
            "  adding: content/models/research/attention_ocr/python/datasets/unittest_utils_test.py (deflated 55%)\n",
            "  adding: content/models/research/attention_ocr/python/datasets/fsns_test.py (deflated 59%)\n",
            "  adding: content/models/research/attention_ocr/python/datasets/__init__.py (deflated 44%)\n",
            "  adding: content/models/research/attention_ocr/python/datasets/unittest_utils.py (deflated 52%)\n",
            "  adding: content/models/research/attention_ocr/python/datasets/testdata/ (stored 0%)\n",
            "  adding: content/models/research/attention_ocr/python/datasets/testdata/fsns/ (stored 0%)\n",
            "  adding: content/models/research/attention_ocr/python/datasets/testdata/fsns/fsns-00000-of-00001 (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/datasets/testdata/fsns/links.txt (deflated 15%)\n",
            "  adding: content/models/research/attention_ocr/python/datasets/testdata/fsns/charset_size=134.txt (deflated 33%)\n",
            "  adding: content/models/research/attention_ocr/python/datasets/testdata/fsns/download_data.py (deflated 46%)\n",
            "  adding: content/models/research/attention_ocr/python/datasets/fsns.py (deflated 63%)\n",
            "  adding: content/models/research/attention_ocr/python/metrics.py (deflated 69%)\n",
            "  adding: content/models/research/attention_ocr/python/utils.py (deflated 56%)\n",
            "  adding: content/models/research/attention_ocr/python/data_provider.py (deflated 65%)\n",
            "  adding: content/models/research/attention_ocr/python/demo_inference.py (deflated 60%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/ (stored 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_02.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_18.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_20.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_00.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_22.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_13.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_21.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_17.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_30.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_24.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_15.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_07.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_03.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_06.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_10.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_11.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_31.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_26.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_16.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_01.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_28.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_09.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_12.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_05.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_25.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_14.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_04.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_23.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_29.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_08.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_19.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/testdata/fsns_train_27.png (deflated 0%)\n",
            "  adding: content/models/research/attention_ocr/python/sequence_layers_test.py (deflated 71%)\n",
            "  adding: content/models/research/attention_ocr/python/model.py (deflated 71%)\n",
            "  adding: content/models/research/attention_ocr/python/metrics_test.py (deflated 66%)\n",
            "  adding: content/models/research/attention_ocr/python/sequence_layers.py (deflated 72%)\n",
            "  adding: content/models/LICENSE (deflated 65%)\n",
            "  adding: content/models/tensorflow_models/ (stored 0%)\n",
            "  adding: content/models/tensorflow_models/__init__.py (deflated 45%)\n",
            "  adding: content/models/tensorflow_models/LICENSE (deflated 65%)\n",
            "  adding: content/models/tensorflow_models/nlp/ (stored 0%)\n",
            "  adding: content/models/tensorflow_models/nlp/__init__.py (deflated 39%)\n",
            "  adding: content/models/tensorflow_models/vision/ (stored 0%)\n",
            "  adding: content/models/tensorflow_models/vision/__init__.py (deflated 40%)\n",
            "  adding: content/models/tensorflow_models/tensorflow_models_test.py (deflated 46%)\n",
            "  adding: content/models/.gitignore (deflated 44%)\n",
            "  adding: content/models/orbit/ (stored 0%)\n",
            "  adding: content/models/orbit/controller_test.py (deflated 86%)\n",
            "  adding: content/models/orbit/utils/ (stored 0%)\n",
            "  adding: content/models/orbit/utils/epoch_helper.py (deflated 59%)\n",
            "  adding: content/models/orbit/utils/__init__.py (deflated 51%)\n",
            "  adding: content/models/orbit/utils/loop_fns.py (deflated 70%)\n",
            "  adding: content/models/orbit/utils/common_test.py (deflated 44%)\n",
            "  adding: content/models/orbit/utils/tpu_summaries.py (deflated 63%)\n",
            "  adding: content/models/orbit/utils/common.py (deflated 58%)\n",
            "  adding: content/models/orbit/utils/tpu_summaries_test.py (deflated 70%)\n",
            "  adding: content/models/orbit/utils/summary_manager.py (deflated 63%)\n",
            "  adding: content/models/orbit/README.md (deflated 40%)\n",
            "  adding: content/models/orbit/examples/ (stored 0%)\n",
            "  adding: content/models/orbit/examples/single_task/ (stored 0%)\n",
            "  adding: content/models/orbit/examples/single_task/single_task_trainer.py (deflated 61%)\n",
            "  adding: content/models/orbit/examples/single_task/single_task_evaluator.py (deflated 57%)\n",
            "  adding: content/models/orbit/examples/single_task/__init__.py (deflated 37%)\n",
            "  adding: content/models/orbit/examples/single_task/single_task_trainer_test.py (deflated 52%)\n",
            "  adding: content/models/orbit/examples/single_task/single_task_evaluator_test.py (deflated 55%)\n",
            "  adding: content/models/orbit/examples/__init__.py (deflated 37%)\n",
            "  adding: content/models/orbit/__init__.py (deflated 53%)\n",
            "  adding: content/models/orbit/LICENSE (deflated 65%)\n",
            "  adding: content/models/orbit/standard_runner.py (deflated 74%)\n",
            "  adding: content/models/orbit/controller.py (deflated 71%)\n",
            "  adding: content/models/orbit/standard_runner_test.py (deflated 72%)\n",
            "  adding: content/models/orbit/runner.py (deflated 60%)\n",
            "  adding: content/models/orbit/actions/ (stored 0%)\n",
            "  adding: content/models/orbit/actions/new_best_metric_test.py (deflated 72%)\n",
            "  adding: content/models/orbit/actions/conditional_action.py (deflated 52%)\n",
            "  adding: content/models/orbit/actions/export_saved_model.py (deflated 61%)\n",
            "  adding: content/models/orbit/actions/__init__.py (deflated 55%)\n",
            "  adding: content/models/orbit/actions/conditional_action_test.py (deflated 48%)\n",
            "  adding: content/models/orbit/actions/export_saved_model_test.py (deflated 77%)\n",
            "  adding: content/models/orbit/actions/new_best_metric.py (deflated 66%)\n",
            "  adding: content/models/ISSUES.md (deflated 49%)\n",
            "  adding: content/models/CODEOWNERS (deflated 56%)\n",
            "  adding: content/models/official/ (stored 0%)\n",
            "  adding: content/models/official/projects/ (stored 0%)\n",
            "  adding: content/models/official/projects/mobilebert/ (stored 0%)\n",
            "  adding: content/models/official/projects/mobilebert/tf2_model_checkpoint_converter.py (deflated 70%)\n",
            "  adding: content/models/official/projects/mobilebert/README.md (deflated 65%)\n",
            "  adding: content/models/official/projects/mobilebert/experiments/ (stored 0%)\n",
            "  adding: content/models/official/projects/mobilebert/experiments/mobilebert_distillation_en_uncased.yaml (deflated 71%)\n",
            "  adding: content/models/official/projects/mobilebert/experiments/en_uncased_teacher.yaml (deflated 55%)\n",
            "  adding: content/models/official/projects/mobilebert/experiments/en_uncased_student.yaml (deflated 56%)\n",
            "  adding: content/models/official/projects/mobilebert/model_utils.py (deflated 68%)\n",
            "  adding: content/models/official/projects/mobilebert/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/projects/mobilebert/run_distillation.py (deflated 63%)\n",
            "  adding: content/models/official/projects/mobilebert/utils.py (deflated 43%)\n",
            "  adding: content/models/official/projects/mobilebert/distillation_test.py (deflated 70%)\n",
            "  adding: content/models/official/projects/mobilebert/export_tfhub.py (deflated 58%)\n",
            "  adding: content/models/official/projects/mobilebert/distillation.py (deflated 75%)\n",
            "  adding: content/models/official/projects/edgetpu/ (stored 0%)\n",
            "  adding: content/models/official/projects/edgetpu/README.md (deflated 53%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/ (stored 0%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/utils/ (stored 0%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/utils/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/utils/utils_test.py (deflated 57%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/utils/utils.py (deflated 58%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/README.md (deflated 58%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/mobilebert_edgetpu_trainer_test.py (deflated 61%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/experiments/ (stored 0%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/experiments/mobilebert_edgetpu_xs.yaml (deflated 71%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/experiments/mobilebert_edgetpu_m.yaml (deflated 71%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/experiments/downstream_tasks/ (stored 0%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/experiments/downstream_tasks/mobilebert_edgetpu_xs.yaml (deflated 52%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/experiments/downstream_tasks/mobilebert_edgetpu_m.yaml (deflated 52%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/experiments/downstream_tasks/mobilebert_edgetpu_s.yaml (deflated 52%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/experiments/downstream_tasks/mobilebert_baseline.yaml (deflated 53%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/experiments/downstream_tasks/squad_v1.yaml (deflated 56%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/experiments/downstream_tasks/glue_mnli.yaml (deflated 59%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/experiments/mobilebert_edgetpu_s.yaml (deflated 71%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/experiments/mobilebert_baseline.yaml (deflated 71%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/mobilebert_edgetpu_trainer.py (deflated 76%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/modeling/ (stored 0%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/modeling/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/modeling/model_builder_test.py (deflated 63%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/modeling/pretrainer_test.py (deflated 71%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/modeling/edgetpu_layers_test.py (deflated 79%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/modeling/edgetpu_layers.py (deflated 64%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/modeling/encoder.py (deflated 68%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/modeling/model_builder.py (deflated 65%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/modeling/pretrainer.py (deflated 64%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/run_mobilebert_edgetpu_train.py (deflated 64%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/serving/ (stored 0%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/serving/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/serving/export_tflite_squad_test.py (deflated 59%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/serving/export_tflite_squad.py (deflated 62%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/configs/ (stored 0%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/configs/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/projects/edgetpu/nlp/configs/params.py (deflated 67%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/ (stored 0%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/README.md (deflated 75%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/tasks/ (stored 0%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/tasks/semantic_segmentation_test.py (deflated 71%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/tasks/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/tasks/image_classification_test.py (deflated 62%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/tasks/image_classification.py (deflated 71%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/tasks/semantic_segmentation.py (deflated 74%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/train.py (deflated 60%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/dataloaders/ (stored 0%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/dataloaders/classification_input.py (deflated 73%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/dataloaders/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/dataloaders/classification_input_test.py (deflated 69%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/modeling/ (stored 0%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/modeling/common_modules.py (deflated 64%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/modeling/heads/ (stored 0%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/modeling/heads/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/modeling/heads/bifpn_head.py (deflated 76%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/modeling/mobilenet_edgetpu_v1_model_blocks.py (deflated 71%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/modeling/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/modeling/custom_layers_test.py (deflated 73%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/modeling/mobilenet_edgetpu_v2_model.py (deflated 68%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/modeling/mobilenet_edgetpu_v2_model_test.py (deflated 58%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/modeling/mobilenet_edgetpu_v1_model.py (deflated 63%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/modeling/mobilenet_edgetpu_v1_model_test.py (deflated 76%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/modeling/custom_layers.py (deflated 74%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/modeling/backbones/ (stored 0%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/modeling/backbones/mobilenet_edgetpu.py (deflated 66%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/modeling/backbones/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/modeling/backbones/mobilenet_edgetpu_test.py (deflated 52%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/modeling/mobilenet_edgetpu_v2_model_blocks.py (deflated 81%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/serving/ (stored 0%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/serving/export_tflite_test.py (deflated 65%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/serving/inference_visualization_tool.ipynb (deflated 74%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/serving/tflite_imagenet_evaluator_test.py (deflated 54%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/serving/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/serving/tflite_imagenet_evaluator.py (deflated 60%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/serving/export_util.py (deflated 67%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/serving/tflite_imagenet_evaluator_run.py (deflated 53%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/serving/testdata/ (stored 0%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/serving/testdata/ADE_val_00000557.jpg (deflated 1%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/serving/testdata/ADE_val_00001626.jpg (deflated 1%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/serving/testdata/ADE_val_00001471.jpg (deflated 1%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/serving/export_tflite.py (deflated 65%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/configs/ (stored 0%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/configs/semantic_segmentation_searched_config.py (deflated 69%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/configs/mobilenet_edgetpu_config.py (deflated 74%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/configs/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/projects/edgetpu/vision/configs/semantic_segmentation_config.py (deflated 74%)\n",
            "  adding: content/models/official/projects/README.md (deflated 30%)\n",
            "  adding: content/models/official/projects/yt8m/ (stored 0%)\n",
            "  adding: content/models/official/projects/yt8m/eval_utils/ (stored 0%)\n",
            "  adding: content/models/official/projects/yt8m/eval_utils/eval_util.py (deflated 72%)\n",
            "  adding: content/models/official/projects/yt8m/eval_utils/mean_average_precision_calculator.py (deflated 63%)\n",
            "  adding: content/models/official/projects/yt8m/eval_utils/average_precision_calculator.py (deflated 70%)\n",
            "  adding: content/models/official/projects/yt8m/README.md (deflated 56%)\n",
            "  adding: content/models/official/projects/yt8m/tasks/ (stored 0%)\n",
            "  adding: content/models/official/projects/yt8m/tasks/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/projects/yt8m/tasks/yt8m_task.py (deflated 69%)\n",
            "  adding: content/models/official/projects/yt8m/train.py (deflated 44%)\n",
            "  adding: content/models/official/projects/yt8m/experiments/ (stored 0%)\n",
            "  adding: content/models/official/projects/yt8m/experiments/yt8m_test.yaml (deflated 52%)\n",
            "  adding: content/models/official/projects/yt8m/experiments/yt8m.yaml (deflated 65%)\n",
            "  adding: content/models/official/projects/yt8m/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/projects/yt8m/train_test.py (deflated 60%)\n",
            "  adding: content/models/official/projects/yt8m/dataloaders/ (stored 0%)\n",
            "  adding: content/models/official/projects/yt8m/dataloaders/utils.py (deflated 69%)\n",
            "  adding: content/models/official/projects/yt8m/dataloaders/yt8m_input.py (deflated 73%)\n",
            "  adding: content/models/official/projects/yt8m/modeling/ (stored 0%)\n",
            "  adding: content/models/official/projects/yt8m/modeling/yt8m_agg_models.py (deflated 67%)\n",
            "  adding: content/models/official/projects/yt8m/modeling/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/projects/yt8m/modeling/yt8m_model_utils.py (deflated 69%)\n",
            "  adding: content/models/official/projects/yt8m/modeling/yt8m_model.py (deflated 68%)\n",
            "  adding: content/models/official/projects/yt8m/modeling/yt8m_model_test.py (deflated 53%)\n",
            "  adding: content/models/official/projects/yt8m/configs/ (stored 0%)\n",
            "  adding: content/models/official/projects/yt8m/configs/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/projects/yt8m/configs/yt8m.py (deflated 64%)\n",
            "  adding: content/models/official/projects/volumetric_models/ (stored 0%)\n",
            "  adding: content/models/official/projects/volumetric_models/README.md (deflated 53%)\n",
            "  adding: content/models/official/projects/volumetric_models/tasks/ (stored 0%)\n",
            "  adding: content/models/official/projects/volumetric_models/tasks/semantic_segmentation_3d_test.py (deflated 61%)\n",
            "  adding: content/models/official/projects/volumetric_models/tasks/semantic_segmentation_3d.py (deflated 70%)\n",
            "  adding: content/models/official/projects/volumetric_models/train.py (deflated 43%)\n",
            "  adding: content/models/official/projects/volumetric_models/losses/ (stored 0%)\n",
            "  adding: content/models/official/projects/volumetric_models/losses/segmentation_losses_test.py (deflated 61%)\n",
            "  adding: content/models/official/projects/volumetric_models/losses/segmentation_losses.py (deflated 62%)\n",
            "  adding: content/models/official/projects/volumetric_models/train_test.py (deflated 61%)\n",
            "  adding: content/models/official/projects/volumetric_models/evaluation/ (stored 0%)\n",
            "  adding: content/models/official/projects/volumetric_models/evaluation/segmentation_metrics_test.py (deflated 58%)\n",
            "  adding: content/models/official/projects/volumetric_models/evaluation/segmentation_metrics.py (deflated 66%)\n",
            "  adding: content/models/official/projects/volumetric_models/dataloaders/ (stored 0%)\n",
            "  adding: content/models/official/projects/volumetric_models/dataloaders/segmentation_input_3d.py (deflated 67%)\n",
            "  adding: content/models/official/projects/volumetric_models/dataloaders/segmentation_input_3d_test.py (deflated 55%)\n",
            "  adding: content/models/official/projects/volumetric_models/registry_imports.py (deflated 49%)\n",
            "  adding: content/models/official/projects/volumetric_models/modeling/ (stored 0%)\n",
            "  adding: content/models/official/projects/volumetric_models/modeling/factory_test.py (deflated 52%)\n",
            "  adding: content/models/official/projects/volumetric_models/modeling/nn_blocks_3d_test.py (deflated 68%)\n",
            "  adding: content/models/official/projects/volumetric_models/modeling/heads/ (stored 0%)\n",
            "  adding: content/models/official/projects/volumetric_models/modeling/heads/segmentation_heads_3d_test.py (deflated 56%)\n",
            "  adding: content/models/official/projects/volumetric_models/modeling/heads/segmentation_heads_3d.py (deflated 66%)\n",
            "  adding: content/models/official/projects/volumetric_models/modeling/factory.py (deflated 62%)\n",
            "  adding: content/models/official/projects/volumetric_models/modeling/segmentation_model_test.py (deflated 61%)\n",
            "  adding: content/models/official/projects/volumetric_models/modeling/decoders/ (stored 0%)\n",
            "  adding: content/models/official/projects/volumetric_models/modeling/decoders/factory_test.py (deflated 64%)\n",
            "  adding: content/models/official/projects/volumetric_models/modeling/decoders/unet_3d_decoder.py (deflated 65%)\n",
            "  adding: content/models/official/projects/volumetric_models/modeling/decoders/unet_3d_decoder_test.py (deflated 55%)\n",
            "  adding: content/models/official/projects/volumetric_models/modeling/decoders/__init__.py (deflated 38%)\n",
            "  adding: content/models/official/projects/volumetric_models/modeling/decoders/factory.py (deflated 59%)\n",
            "  adding: content/models/official/projects/volumetric_models/modeling/backbones/ (stored 0%)\n",
            "  adding: content/models/official/projects/volumetric_models/modeling/backbones/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/projects/volumetric_models/modeling/backbones/unet_3d_test.py (deflated 52%)\n",
            "  adding: content/models/official/projects/volumetric_models/modeling/backbones/unet_3d.py (deflated 64%)\n",
            "  adding: content/models/official/projects/volumetric_models/modeling/nn_blocks_3d.py (deflated 84%)\n",
            "  adding: content/models/official/projects/volumetric_models/serving/ (stored 0%)\n",
            "  adding: content/models/official/projects/volumetric_models/serving/export_saved_model.py (deflated 62%)\n",
            "  adding: content/models/official/projects/volumetric_models/serving/semantic_segmentation_3d_test.py (deflated 62%)\n",
            "  adding: content/models/official/projects/volumetric_models/serving/semantic_segmentation_3d.py (deflated 52%)\n",
            "  adding: content/models/official/projects/volumetric_models/configs/ (stored 0%)\n",
            "  adding: content/models/official/projects/volumetric_models/configs/semantic_segmentation_3d_test.py (deflated 52%)\n",
            "  adding: content/models/official/projects/volumetric_models/configs/backbones.py (deflated 46%)\n",
            "  adding: content/models/official/projects/volumetric_models/configs/semantic_segmentation_3d.py (deflated 68%)\n",
            "  adding: content/models/official/projects/volumetric_models/configs/decoders.py (deflated 51%)\n",
            "  adding: content/models/official/projects/basnet/ (stored 0%)\n",
            "  adding: content/models/official/projects/basnet/README.md (deflated 52%)\n",
            "  adding: content/models/official/projects/basnet/tasks/ (stored 0%)\n",
            "  adding: content/models/official/projects/basnet/tasks/basnet.py (deflated 70%)\n",
            "  adding: content/models/official/projects/basnet/train.py (deflated 47%)\n",
            "  adding: content/models/official/projects/basnet/losses/ (stored 0%)\n",
            "  adding: content/models/official/projects/basnet/losses/basnet_losses.py (deflated 57%)\n",
            "  adding: content/models/official/projects/basnet/evaluation/ (stored 0%)\n",
            "  adding: content/models/official/projects/basnet/evaluation/metrics.py (deflated 77%)\n",
            "  adding: content/models/official/projects/basnet/evaluation/metrics_test.py (deflated 59%)\n",
            "  adding: content/models/official/projects/basnet/modeling/ (stored 0%)\n",
            "  adding: content/models/official/projects/basnet/modeling/nn_blocks.py (deflated 77%)\n",
            "  adding: content/models/official/projects/basnet/modeling/basnet_model.py (deflated 74%)\n",
            "  adding: content/models/official/projects/basnet/modeling/basnet_model_test.py (deflated 57%)\n",
            "  adding: content/models/official/projects/basnet/modeling/refunet.py (deflated 67%)\n",
            "  adding: content/models/official/projects/basnet/serving/ (stored 0%)\n",
            "  adding: content/models/official/projects/basnet/serving/export_saved_model.py (deflated 60%)\n",
            "  adding: content/models/official/projects/basnet/serving/basnet.py (deflated 50%)\n",
            "  adding: content/models/official/projects/basnet/configs/ (stored 0%)\n",
            "  adding: content/models/official/projects/basnet/configs/experiments/ (stored 0%)\n",
            "  adding: content/models/official/projects/basnet/configs/experiments/basnet_dut_gpu.yaml (deflated 39%)\n",
            "  adding: content/models/official/projects/basnet/configs/basnet_test.py (deflated 51%)\n",
            "  adding: content/models/official/projects/basnet/configs/basnet.py (deflated 66%)\n",
            "  adding: content/models/official/projects/nhnet/ (stored 0%)\n",
            "  adding: content/models/official/projects/nhnet/configs_test.py (deflated 66%)\n",
            "  adding: content/models/official/projects/nhnet/trainer.py (deflated 65%)\n",
            "  adding: content/models/official/projects/nhnet/README.md (deflated 56%)\n",
            "  adding: content/models/official/projects/nhnet/trainer_test.py (deflated 58%)\n",
            "  adding: content/models/official/projects/nhnet/decoder.py (deflated 76%)\n",
            "  adding: content/models/official/projects/nhnet/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/projects/nhnet/models_test.py (deflated 78%)\n",
            "  adding: content/models/official/projects/nhnet/evaluation.py (deflated 66%)\n",
            "  adding: content/models/official/projects/nhnet/configs.py (deflated 59%)\n",
            "  adding: content/models/official/projects/nhnet/decoder_test.py (deflated 76%)\n",
            "  adding: content/models/official/projects/nhnet/utils.py (deflated 59%)\n",
            "  adding: content/models/official/projects/nhnet/optimizer.py (deflated 62%)\n",
            "  adding: content/models/official/projects/nhnet/raw_data_processor.py (deflated 70%)\n",
            "  adding: content/models/official/projects/nhnet/testdata/ (stored 0%)\n",
            "  adding: content/models/official/projects/nhnet/testdata/vocab.txt (deflated 10%)\n",
            "  adding: content/models/official/projects/nhnet/testdata/crawled_articles/ (stored 0%)\n",
            "  adding: content/models/official/projects/nhnet/testdata/crawled_articles/domain_1.com/ (stored 0%)\n",
            "  adding: content/models/official/projects/nhnet/testdata/crawled_articles/domain_1.com/url_001.html (deflated 9%)\n",
            "  adding: content/models/official/projects/nhnet/testdata/crawled_articles/domain_1.com/url_001.json (deflated 27%)\n",
            "  adding: content/models/official/projects/nhnet/testdata/crawled_articles/domain_0.com/ (stored 0%)\n",
            "  adding: content/models/official/projects/nhnet/testdata/crawled_articles/domain_0.com/url_000.json (deflated 24%)\n",
            "  adding: content/models/official/projects/nhnet/testdata/crawled_articles/domain_0.com/url_000.html (deflated 9%)\n",
            "  adding: content/models/official/projects/nhnet/testdata/stories.json (deflated 81%)\n",
            "  adding: content/models/official/projects/nhnet/models.py (deflated 79%)\n",
            "  adding: content/models/official/projects/nhnet/raw_data_process.py (deflated 62%)\n",
            "  adding: content/models/official/projects/nhnet/input_pipeline.py (deflated 73%)\n",
            "  adding: content/models/official/projects/text_classification_example/ (stored 0%)\n",
            "  adding: content/models/official/projects/text_classification_example/README.md (deflated 57%)\n",
            "  adding: content/models/official/projects/text_classification_example/train.py (deflated 56%)\n",
            "  adding: content/models/official/projects/text_classification_example/experiments/ (stored 0%)\n",
            "  adding: content/models/official/projects/text_classification_example/experiments/classification_ft_cola.yaml (deflated 59%)\n",
            "  adding: content/models/official/projects/text_classification_example/experiments/local_example.yaml (deflated 57%)\n",
            "  adding: content/models/official/projects/text_classification_example/classification_example_test.py (deflated 58%)\n",
            "  adding: content/models/official/projects/text_classification_example/classification_example.py (deflated 66%)\n",
            "  adding: content/models/official/projects/text_classification_example/classification_data_loader.py (deflated 58%)\n",
            "  adding: content/models/official/pip_package/ (stored 0%)\n",
            "  adding: content/models/official/pip_package/setup.py (deflated 57%)\n",
            "  adding: content/models/official/utils/ (stored 0%)\n",
            "  adding: content/models/official/utils/misc/ (stored 0%)\n",
            "  adding: content/models/official/utils/misc/model_helpers.py (deflated 60%)\n",
            "  adding: content/models/official/utils/misc/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/utils/misc/keras_utils.py (deflated 68%)\n",
            "  adding: content/models/official/utils/misc/model_helpers_test.py (deflated 71%)\n",
            "  adding: content/models/official/utils/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/utils/flags/ (stored 0%)\n",
            "  adding: content/models/official/utils/flags/flags_test.py (deflated 71%)\n",
            "  adding: content/models/official/utils/flags/README.md (deflated 56%)\n",
            "  adding: content/models/official/utils/flags/_benchmark.py (deflated 67%)\n",
            "  adding: content/models/official/utils/flags/_performance.py (deflated 70%)\n",
            "  adding: content/models/official/utils/flags/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/utils/flags/core.py (deflated 61%)\n",
            "  adding: content/models/official/utils/flags/_distribution.py (deflated 52%)\n",
            "  adding: content/models/official/utils/flags/_misc.py (deflated 47%)\n",
            "  adding: content/models/official/utils/flags/_device.py (deflated 56%)\n",
            "  adding: content/models/official/utils/flags/_base.py (deflated 68%)\n",
            "  adding: content/models/official/utils/flags/_conventions.py (deflated 44%)\n",
            "  adding: content/models/official/utils/flags/guidelines.md (deflated 55%)\n",
            "  adding: content/models/official/utils/testing/ (stored 0%)\n",
            "  adding: content/models/official/utils/testing/mock_task.py (deflated 57%)\n",
            "  adding: content/models/official/utils/testing/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/utils/testing/pylint.rcfile (deflated 60%)\n",
            "  adding: content/models/official/utils/testing/integration.py (deflated 54%)\n",
            "  adding: content/models/official/utils/testing/scripts/ (stored 0%)\n",
            "  adding: content/models/official/utils/testing/scripts/builds_common.sh (deflated 49%)\n",
            "  adding: content/models/official/utils/testing/scripts/ci_sanity.sh (deflated 57%)\n",
            "  adding: content/models/official/utils/testing/scripts/presubmit.sh (deflated 48%)\n",
            "  adding: content/models/official/utils/docs/ (stored 0%)\n",
            "  adding: content/models/official/utils/docs/build_vision_api_docs.py (deflated 55%)\n",
            "  adding: content/models/official/utils/docs/build_api_docs_lib.py (deflated 52%)\n",
            "  adding: content/models/official/utils/docs/build_nlp_api_docs.py (deflated 55%)\n",
            "  adding: content/models/official/utils/hyperparams_flags.py (deflated 64%)\n",
            "  adding: content/models/official/README.md (deflated 62%)\n",
            "  adding: content/models/official/colab/ (stored 0%)\n",
            "  adding: content/models/official/colab/decoding_api_in_tf_nlp.ipynb (deflated 77%)\n",
            "  adding: content/models/official/colab/nlp/ (stored 0%)\n",
            "  adding: content/models/official/colab/nlp/customize_encoder.ipynb (deflated 79%)\n",
            "  adding: content/models/official/colab/nlp/nlp_modeling_library_intro.ipynb (deflated 79%)\n",
            "  adding: content/models/official/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/LICENSE (deflated 65%)\n",
            "  adding: content/models/official/nlp/ (stored 0%)\n",
            "  adding: content/models/official/nlp/bert/ (stored 0%)\n",
            "  adding: content/models/official/nlp/bert/run_pretraining.py (deflated 70%)\n",
            "  adding: content/models/official/nlp/bert/export_tfhub_test.py (deflated 63%)\n",
            "  adding: content/models/official/nlp/bert/run_classifier.py (deflated 72%)\n",
            "  adding: content/models/official/nlp/bert/tf1_checkpoint_converter_lib.py (deflated 69%)\n",
            "  adding: content/models/official/nlp/bert/README.md (deflated 73%)\n",
            "  adding: content/models/official/nlp/bert/tokenization_test.py (deflated 73%)\n",
            "  adding: content/models/official/nlp/bert/run_squad_helper.py (deflated 72%)\n",
            "  adding: content/models/official/nlp/bert/common_flags.py (deflated 61%)\n",
            "  adding: content/models/official/nlp/bert/model_training_utils_test.py (deflated 73%)\n",
            "  adding: content/models/official/nlp/bert/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/nlp/bert/bert_models_test.py (deflated 70%)\n",
            "  adding: content/models/official/nlp/bert/model_saving_utils.py (deflated 59%)\n",
            "  adding: content/models/official/nlp/bert/squad_evaluate_v2_0.py (deflated 68%)\n",
            "  adding: content/models/official/nlp/bert/tokenization.py (deflated 70%)\n",
            "  adding: content/models/official/nlp/bert/configs.py (deflated 61%)\n",
            "  adding: content/models/official/nlp/bert/tf2_encoder_checkpoint_converter.py (deflated 66%)\n",
            "  adding: content/models/official/nlp/bert/model_training_utils.py (deflated 71%)\n",
            "  adding: content/models/official/nlp/bert/bert_cloud_tpu.md (deflated 54%)\n",
            "  adding: content/models/official/nlp/bert/bert_models.py (deflated 77%)\n",
            "  adding: content/models/official/nlp/bert/squad_evaluate_v1_1.py (deflated 59%)\n",
            "  adding: content/models/official/nlp/bert/input_pipeline.py (deflated 78%)\n",
            "  adding: content/models/official/nlp/bert/serving.py (deflated 64%)\n",
            "  adding: content/models/official/nlp/bert/export_tfhub.py (deflated 68%)\n",
            "  adding: content/models/official/nlp/bert/run_squad.py (deflated 65%)\n",
            "  adding: content/models/official/nlp/projects/ (stored 0%)\n",
            "  adding: content/models/official/nlp/projects/teams/ (stored 0%)\n",
            "  adding: content/models/official/nlp/projects/teams/teams.py (deflated 63%)\n",
            "  adding: content/models/official/nlp/projects/teams/README.md (deflated 41%)\n",
            "  adding: content/models/official/nlp/projects/teams/teams_task_test.py (deflated 57%)\n",
            "  adding: content/models/official/nlp/projects/teams/teams_experiments_test.py (deflated 48%)\n",
            "  adding: content/models/official/nlp/projects/teams/experiments/ (stored 0%)\n",
            "  adding: content/models/official/nlp/projects/teams/experiments/teams_en_uncased_small.yaml (deflated 53%)\n",
            "  adding: content/models/official/nlp/projects/teams/experiments/base/ (stored 0%)\n",
            "  adding: content/models/official/nlp/projects/teams/experiments/base/wiki_books_pretrain.yaml (deflated 71%)\n",
            "  adding: content/models/official/nlp/projects/teams/experiments/base/squad_v2.yaml (deflated 58%)\n",
            "  adding: content/models/official/nlp/projects/teams/experiments/base/squad_v1.yaml (deflated 57%)\n",
            "  adding: content/models/official/nlp/projects/teams/experiments/base/glue_mnli.yaml (deflated 58%)\n",
            "  adding: content/models/official/nlp/projects/teams/experiments/teams_en_uncased_base.yaml (deflated 54%)\n",
            "  adding: content/models/official/nlp/projects/teams/experiments/small/ (stored 0%)\n",
            "  adding: content/models/official/nlp/projects/teams/experiments/small/wiki_books_pretrain.yaml (deflated 70%)\n",
            "  adding: content/models/official/nlp/projects/teams/experiments/small/squad_v2.yaml (deflated 58%)\n",
            "  adding: content/models/official/nlp/projects/teams/experiments/small/squad_v1.yaml (deflated 58%)\n",
            "  adding: content/models/official/nlp/projects/teams/experiments/small/glue_mnli.yaml (deflated 58%)\n",
            "  adding: content/models/official/nlp/projects/teams/teams_experiments.py (deflated 59%)\n",
            "  adding: content/models/official/nlp/projects/teams/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/nlp/projects/teams/teams_pretrainer.py (deflated 74%)\n",
            "  adding: content/models/official/nlp/projects/teams/teams_task.py (deflated 72%)\n",
            "  adding: content/models/official/nlp/projects/teams/teams_pretrainer_test.py (deflated 72%)\n",
            "  adding: content/models/official/nlp/projects/bigbird/ (stored 0%)\n",
            "  adding: content/models/official/nlp/projects/bigbird/stateless_dropout.py (deflated 57%)\n",
            "  adding: content/models/official/nlp/projects/bigbird/experiment_configs.py (deflated 73%)\n",
            "  adding: content/models/official/nlp/projects/bigbird/README.md (deflated 62%)\n",
            "  adding: content/models/official/nlp/projects/bigbird/experiments/ (stored 0%)\n",
            "  adding: content/models/official/nlp/projects/bigbird/experiments/glue_mnli_matched.yaml (deflated 60%)\n",
            "  adding: content/models/official/nlp/projects/bigbird/experiments/squad_v1.yaml (deflated 59%)\n",
            "  adding: content/models/official/nlp/projects/bigbird/encoder_test.py (deflated 62%)\n",
            "  adding: content/models/official/nlp/projects/bigbird/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/nlp/projects/bigbird/recomputing_dropout.py (deflated 62%)\n",
            "  adding: content/models/official/nlp/projects/bigbird/recompute_grad.py (deflated 62%)\n",
            "  adding: content/models/official/nlp/projects/bigbird/encoder.py (deflated 69%)\n",
            "  adding: content/models/official/nlp/projects/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/nlp/projects/triviaqa/ (stored 0%)\n",
            "  adding: content/models/official/nlp/projects/triviaqa/predict.py (deflated 65%)\n",
            "  adding: content/models/official/nlp/projects/triviaqa/prediction.py (deflated 56%)\n",
            "  adding: content/models/official/nlp/projects/triviaqa/train.py (deflated 69%)\n",
            "  adding: content/models/official/nlp/projects/triviaqa/preprocess.py (deflated 73%)\n",
            "  adding: content/models/official/nlp/projects/triviaqa/modeling.py (deflated 66%)\n",
            "  adding: content/models/official/nlp/projects/triviaqa/dataset.py (deflated 74%)\n",
            "  adding: content/models/official/nlp/projects/triviaqa/sentencepiece_pb2.py (deflated 83%)\n",
            "  adding: content/models/official/nlp/projects/triviaqa/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/nlp/projects/triviaqa/evaluation.py (deflated 69%)\n",
            "  adding: content/models/official/nlp/projects/triviaqa/download_and_prepare.py (deflated 53%)\n",
            "  adding: content/models/official/nlp/projects/triviaqa/evaluate.py (deflated 47%)\n",
            "  adding: content/models/official/nlp/projects/triviaqa/inputs.py (deflated 75%)\n",
            "  adding: content/models/official/nlp/projects/tn_bert/ (stored 0%)\n",
            "  adding: content/models/official/nlp/projects/tn_bert/README.md (deflated 52%)\n",
            "  adding: content/models/official/nlp/README.md (deflated 53%)\n",
            "  adding: content/models/official/nlp/tasks/ (stored 0%)\n",
            "  adding: content/models/official/nlp/tasks/translation.py (deflated 67%)\n",
            "  adding: content/models/official/nlp/tasks/tagging_test.py (deflated 69%)\n",
            "  adding: content/models/official/nlp/tasks/electra_task.py (deflated 71%)\n",
            "  adding: content/models/official/nlp/tasks/__init__.py (deflated 52%)\n",
            "  adding: content/models/official/nlp/tasks/sentence_prediction.py (deflated 70%)\n",
            "  adding: content/models/official/nlp/tasks/dual_encoder.py (deflated 66%)\n",
            "  adding: content/models/official/nlp/tasks/masked_lm_test.py (deflated 54%)\n",
            "  adding: content/models/official/nlp/tasks/translation_test.py (deflated 72%)\n",
            "  adding: content/models/official/nlp/tasks/question_answering_test.py (deflated 78%)\n",
            "  adding: content/models/official/nlp/tasks/question_answering.py (deflated 76%)\n",
            "  adding: content/models/official/nlp/tasks/sentence_prediction_test.py (deflated 74%)\n",
            "  adding: content/models/official/nlp/tasks/utils.py (deflated 56%)\n",
            "  adding: content/models/official/nlp/tasks/electra_task_test.py (deflated 59%)\n",
            "  adding: content/models/official/nlp/tasks/dual_encoder_test.py (deflated 66%)\n",
            "  adding: content/models/official/nlp/tasks/tagging.py (deflated 67%)\n",
            "  adding: content/models/official/nlp/tasks/masked_lm.py (deflated 68%)\n",
            "  adding: content/models/official/nlp/train.py (deflated 57%)\n",
            "  adding: content/models/official/nlp/continuous_finetune_lib.py (deflated 63%)\n",
            "  adding: content/models/official/nlp/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/nlp/xlnet/ (stored 0%)\n",
            "  adding: content/models/official/nlp/xlnet/xlnet_config.py (deflated 64%)\n",
            "  adding: content/models/official/nlp/xlnet/run_classifier.py (deflated 66%)\n",
            "  adding: content/models/official/nlp/xlnet/run_pretrain.py (deflated 67%)\n",
            "  adding: content/models/official/nlp/xlnet/README.md (deflated 60%)\n",
            "  adding: content/models/official/nlp/xlnet/common_flags.py (deflated 66%)\n",
            "  adding: content/models/official/nlp/xlnet/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/nlp/xlnet/preprocess_utils.py (deflated 61%)\n",
            "  adding: content/models/official/nlp/xlnet/xlnet_modeling.py (deflated 80%)\n",
            "  adding: content/models/official/nlp/xlnet/optimization.py (deflated 65%)\n",
            "  adding: content/models/official/nlp/xlnet/training_utils.py (deflated 68%)\n",
            "  adding: content/models/official/nlp/xlnet/data_utils.py (deflated 76%)\n",
            "  adding: content/models/official/nlp/xlnet/classifier_utils.py (deflated 64%)\n",
            "  adding: content/models/official/nlp/xlnet/preprocess_squad_data.py (deflated 64%)\n",
            "  adding: content/models/official/nlp/xlnet/squad_utils.py (deflated 73%)\n",
            "  adding: content/models/official/nlp/xlnet/preprocess_pretrain_data.py (deflated 72%)\n",
            "  adding: content/models/official/nlp/xlnet/preprocess_classification_data.py (deflated 74%)\n",
            "  adding: content/models/official/nlp/xlnet/run_squad.py (deflated 71%)\n",
            "  adding: content/models/official/nlp/albert/ (stored 0%)\n",
            "  adding: content/models/official/nlp/albert/run_classifier.py (deflated 64%)\n",
            "  adding: content/models/official/nlp/albert/README.md (deflated 71%)\n",
            "  adding: content/models/official/nlp/albert/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/nlp/albert/configs.py (deflated 50%)\n",
            "  adding: content/models/official/nlp/albert/run_squad.py (deflated 64%)\n",
            "  adding: content/models/official/nlp/docs/ (stored 0%)\n",
            "  adding: content/models/official/nlp/docs/tfhub.md (deflated 66%)\n",
            "  adding: content/models/official/nlp/docs/pretrained_models.md (deflated 74%)\n",
            "  adding: content/models/official/nlp/docs/train.md (deflated 68%)\n",
            "  adding: content/models/official/nlp/tools/ (stored 0%)\n",
            "  adding: content/models/official/nlp/tools/export_tfhub_lib.py (deflated 69%)\n",
            "  adding: content/models/official/nlp/tools/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/nlp/tools/tf2_albert_encoder_checkpoint_converter.py (deflated 67%)\n",
            "  adding: content/models/official/nlp/tools/export_tfhub_lib_test.py (deflated 79%)\n",
            "  adding: content/models/official/nlp/tools/export_tfhub.py (deflated 67%)\n",
            "  adding: content/models/official/nlp/finetuning/ (stored 0%)\n",
            "  adding: content/models/official/nlp/finetuning/superglue/ (stored 0%)\n",
            "  adding: content/models/official/nlp/finetuning/superglue/flags.py (deflated 69%)\n",
            "  adding: content/models/official/nlp/finetuning/superglue/run_superglue.py (deflated 67%)\n",
            "  adding: content/models/official/nlp/finetuning/binary_helper.py (deflated 79%)\n",
            "  adding: content/models/official/nlp/finetuning/glue/ (stored 0%)\n",
            "  adding: content/models/official/nlp/finetuning/glue/flags.py (deflated 68%)\n",
            "  adding: content/models/official/nlp/finetuning/glue/run_glue.py (deflated 69%)\n",
            "  adding: content/models/official/nlp/transformer/ (stored 0%)\n",
            "  adding: content/models/official/nlp/transformer/utils/ (stored 0%)\n",
            "  adding: content/models/official/nlp/transformer/utils/tokenizer.py (deflated 71%)\n",
            "  adding: content/models/official/nlp/transformer/utils/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/nlp/transformer/utils/metrics.py (deflated 71%)\n",
            "  adding: content/models/official/nlp/transformer/utils/tokenizer_test.py (deflated 72%)\n",
            "  adding: content/models/official/nlp/transformer/transformer_main.py (deflated 72%)\n",
            "  adding: content/models/official/nlp/transformer/README.md (deflated 63%)\n",
            "  adding: content/models/official/nlp/transformer/transformer.py (deflated 76%)\n",
            "  adding: content/models/official/nlp/transformer/data_download.py (deflated 68%)\n",
            "  adding: content/models/official/nlp/transformer/compute_bleu.py (deflated 59%)\n",
            "  adding: content/models/official/nlp/transformer/model_utils.py (deflated 60%)\n",
            "  adding: content/models/official/nlp/transformer/model_params.py (deflated 57%)\n",
            "  adding: content/models/official/nlp/transformer/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/nlp/transformer/model_utils_test.py (deflated 58%)\n",
            "  adding: content/models/official/nlp/transformer/transformer_layers_test.py (deflated 67%)\n",
            "  adding: content/models/official/nlp/transformer/ffn_layer.py (deflated 59%)\n",
            "  adding: content/models/official/nlp/transformer/embedding_layer.py (deflated 61%)\n",
            "  adding: content/models/official/nlp/transformer/misc.py (deflated 68%)\n",
            "  adding: content/models/official/nlp/transformer/transformer_test.py (deflated 65%)\n",
            "  adding: content/models/official/nlp/transformer/compute_bleu_test.py (deflated 66%)\n",
            "  adding: content/models/official/nlp/transformer/data_pipeline.py (deflated 67%)\n",
            "  adding: content/models/official/nlp/transformer/metrics.py (deflated 70%)\n",
            "  adding: content/models/official/nlp/transformer/optimizer.py (deflated 61%)\n",
            "  adding: content/models/official/nlp/transformer/translate.py (deflated 63%)\n",
            "  adding: content/models/official/nlp/transformer/transformer_main_test.py (deflated 71%)\n",
            "  adding: content/models/official/nlp/transformer/transformer_forward_test.py (deflated 69%)\n",
            "  adding: content/models/official/nlp/transformer/beam_search_v1.py (deflated 61%)\n",
            "  adding: content/models/official/nlp/transformer/attention_layer.py (deflated 67%)\n",
            "  adding: content/models/official/nlp/optimization.py (deflated 70%)\n",
            "  adding: content/models/official/nlp/modeling/ (stored 0%)\n",
            "  adding: content/models/official/nlp/modeling/README.md (deflated 56%)\n",
            "  adding: content/models/official/nlp/modeling/__init__.py (deflated 46%)\n",
            "  adding: content/models/official/nlp/modeling/losses/ (stored 0%)\n",
            "  adding: content/models/official/nlp/modeling/losses/README.md (deflated 31%)\n",
            "  adding: content/models/official/nlp/modeling/losses/weighted_sparse_categorical_crossentropy.py (deflated 57%)\n",
            "  adding: content/models/official/nlp/modeling/losses/__init__.py (deflated 40%)\n",
            "  adding: content/models/official/nlp/modeling/losses/weighted_sparse_categorical_crossentropy_test.py (deflated 72%)\n",
            "  adding: content/models/official/nlp/modeling/layers/ (stored 0%)\n",
            "  adding: content/models/official/nlp/modeling/layers/reuse_transformer.py (deflated 76%)\n",
            "  adding: content/models/official/nlp/modeling/layers/text_layers_test.py (deflated 82%)\n",
            "  adding: content/models/official/nlp/modeling/layers/gated_feedforward.py (deflated 72%)\n",
            "  adding: content/models/official/nlp/modeling/layers/rezero_transformer_test.py (deflated 69%)\n",
            "  adding: content/models/official/nlp/modeling/layers/cls_head_test.py (deflated 79%)\n",
            "  adding: content/models/official/nlp/modeling/layers/talking_heads_attention_test.py (deflated 73%)\n",
            "  adding: content/models/official/nlp/modeling/layers/spectral_normalization_test.py (deflated 55%)\n",
            "  adding: content/models/official/nlp/modeling/layers/reuse_transformer_test.py (deflated 86%)\n",
            "  adding: content/models/official/nlp/modeling/layers/util.py (deflated 50%)\n",
            "  adding: content/models/official/nlp/modeling/layers/README.md (deflated 65%)\n",
            "  adding: content/models/official/nlp/modeling/layers/attention.py (deflated 60%)\n",
            "  adding: content/models/official/nlp/modeling/layers/transformer.py (deflated 82%)\n",
            "  adding: content/models/official/nlp/modeling/layers/relative_attention_test.py (deflated 74%)\n",
            "  adding: content/models/official/nlp/modeling/layers/mobile_bert_layers.py (deflated 77%)\n",
            "  adding: content/models/official/nlp/modeling/layers/attention_test.py (deflated 66%)\n",
            "  adding: content/models/official/nlp/modeling/layers/transformer_scaffold_test.py (deflated 87%)\n",
            "  adding: content/models/official/nlp/modeling/layers/rezero_transformer.py (deflated 73%)\n",
            "  adding: content/models/official/nlp/modeling/layers/tn_expand_condense_test.py (deflated 70%)\n",
            "  adding: content/models/official/nlp/modeling/layers/multi_channel_attention.py (deflated 67%)\n",
            "  adding: content/models/official/nlp/modeling/layers/__init__.py (deflated 72%)\n",
            "  adding: content/models/official/nlp/modeling/layers/text_layers.py (deflated 73%)\n",
            "  adding: content/models/official/nlp/modeling/layers/tn_expand_condense.py (deflated 65%)\n",
            "  adding: content/models/official/nlp/modeling/layers/transformer_xl.py (deflated 79%)\n",
            "  adding: content/models/official/nlp/modeling/layers/kernel_attention.py (deflated 69%)\n",
            "  adding: content/models/official/nlp/modeling/layers/tn_transformer_expand_condense.py (deflated 75%)\n",
            "  adding: content/models/official/nlp/modeling/layers/bigbird_attention_test.py (deflated 58%)\n",
            "  adding: content/models/official/nlp/modeling/layers/position_embedding.py (deflated 69%)\n",
            "  adding: content/models/official/nlp/modeling/layers/relative_attention.py (deflated 80%)\n",
            "  adding: content/models/official/nlp/modeling/layers/gated_feedforward_test.py (deflated 70%)\n",
            "  adding: content/models/official/nlp/modeling/layers/transformer_encoder_block_test.py (deflated 84%)\n",
            "  adding: content/models/official/nlp/modeling/layers/kernel_attention_test.py (deflated 69%)\n",
            "  adding: content/models/official/nlp/modeling/layers/tn_transformer_test.py (deflated 81%)\n",
            "  adding: content/models/official/nlp/modeling/layers/on_device_embedding_test.py (deflated 85%)\n",
            "  adding: content/models/official/nlp/modeling/layers/masked_lm_test.py (deflated 72%)\n",
            "  adding: content/models/official/nlp/modeling/layers/gaussian_process_test.py (deflated 70%)\n",
            "  adding: content/models/official/nlp/modeling/layers/transformer_test.py (deflated 70%)\n",
            "  adding: content/models/official/nlp/modeling/layers/transformer_encoder_block.py (deflated 75%)\n",
            "  adding: content/models/official/nlp/modeling/layers/on_device_embedding.py (deflated 61%)\n",
            "  adding: content/models/official/nlp/modeling/layers/position_embedding_test.py (deflated 77%)\n",
            "  adding: content/models/official/nlp/modeling/layers/spectral_normalization.py (deflated 74%)\n",
            "  adding: content/models/official/nlp/modeling/layers/mat_mul_with_margin_test.py (deflated 54%)\n",
            "  adding: content/models/official/nlp/modeling/layers/transformer_xl_test.py (deflated 76%)\n",
            "  adding: content/models/official/nlp/modeling/layers/transformer_scaffold.py (deflated 75%)\n",
            "  adding: content/models/official/nlp/modeling/layers/bigbird_attention.py (deflated 79%)\n",
            "  adding: content/models/official/nlp/modeling/layers/self_attention_mask.py (deflated 53%)\n",
            "  adding: content/models/official/nlp/modeling/layers/talking_heads_attention.py (deflated 67%)\n",
            "  adding: content/models/official/nlp/modeling/layers/cls_head.py (deflated 75%)\n",
            "  adding: content/models/official/nlp/modeling/layers/masked_softmax_test.py (deflated 74%)\n",
            "  adding: content/models/official/nlp/modeling/layers/mobile_bert_layers_test.py (deflated 77%)\n",
            "  adding: content/models/official/nlp/modeling/layers/reuse_attention_test.py (deflated 82%)\n",
            "  adding: content/models/official/nlp/modeling/layers/multi_channel_attention_test.py (deflated 55%)\n",
            "  adding: content/models/official/nlp/modeling/layers/reuse_attention.py (deflated 74%)\n",
            "  adding: content/models/official/nlp/modeling/layers/gaussian_process.py (deflated 72%)\n",
            "  adding: content/models/official/nlp/modeling/layers/mat_mul_with_margin.py (deflated 54%)\n",
            "  adding: content/models/official/nlp/modeling/layers/masked_lm.py (deflated 61%)\n",
            "  adding: content/models/official/nlp/modeling/layers/masked_softmax.py (deflated 57%)\n",
            "  adding: content/models/official/nlp/modeling/models/ (stored 0%)\n",
            "  adding: content/models/official/nlp/modeling/models/bert_span_labeler_test.py (deflated 66%)\n",
            "  adding: content/models/official/nlp/modeling/models/README.md (deflated 56%)\n",
            "  adding: content/models/official/nlp/modeling/models/electra_pretrainer_test.py (deflated 72%)\n",
            "  adding: content/models/official/nlp/modeling/models/t5.py (deflated 81%)\n",
            "  adding: content/models/official/nlp/modeling/models/xlnet_test.py (deflated 83%)\n",
            "  adding: content/models/official/nlp/modeling/models/bert_pretrainer_test.py (deflated 77%)\n",
            "  adding: content/models/official/nlp/modeling/models/__init__.py (deflated 59%)\n",
            "  adding: content/models/official/nlp/modeling/models/electra_pretrainer.py (deflated 70%)\n",
            "  adding: content/models/official/nlp/modeling/models/bert_classifier_test.py (deflated 66%)\n",
            "  adding: content/models/official/nlp/modeling/models/bert_span_labeler.py (deflated 57%)\n",
            "  adding: content/models/official/nlp/modeling/models/dual_encoder.py (deflated 66%)\n",
            "  adding: content/models/official/nlp/modeling/models/seq2seq_transformer_test.py (deflated 68%)\n",
            "  adding: content/models/official/nlp/modeling/models/bert_pretrainer.py (deflated 69%)\n",
            "  adding: content/models/official/nlp/modeling/models/bert_classifier.py (deflated 60%)\n",
            "  adding: content/models/official/nlp/modeling/models/t5_test.py (deflated 82%)\n",
            "  adding: content/models/official/nlp/modeling/models/seq2seq_transformer.py (deflated 77%)\n",
            "  adding: content/models/official/nlp/modeling/models/bert_token_classifier_test.py (deflated 66%)\n",
            "  adding: content/models/official/nlp/modeling/models/bert_token_classifier.py (deflated 59%)\n",
            "  adding: content/models/official/nlp/modeling/models/xlnet.py (deflated 74%)\n",
            "  adding: content/models/official/nlp/modeling/models/dual_encoder_test.py (deflated 68%)\n",
            "  adding: content/models/official/nlp/modeling/ops/ (stored 0%)\n",
            "  adding: content/models/official/nlp/modeling/ops/beam_search.py (deflated 74%)\n",
            "  adding: content/models/official/nlp/modeling/ops/segment_extractor.py (deflated 71%)\n",
            "  adding: content/models/official/nlp/modeling/ops/beam_search_test.py (deflated 60%)\n",
            "  adding: content/models/official/nlp/modeling/ops/__init__.py (deflated 44%)\n",
            "  adding: content/models/official/nlp/modeling/ops/decoding_module.py (deflated 69%)\n",
            "  adding: content/models/official/nlp/modeling/ops/sampling_module.py (deflated 76%)\n",
            "  adding: content/models/official/nlp/modeling/ops/decoding_module_test.py (deflated 60%)\n",
            "  adding: content/models/official/nlp/modeling/ops/segment_extractor_test.py (deflated 78%)\n",
            "  adding: content/models/official/nlp/modeling/networks/ (stored 0%)\n",
            "  adding: content/models/official/nlp/modeling/networks/xlnet_base_test.py (deflated 80%)\n",
            "  adding: content/models/official/nlp/modeling/networks/classification.py (deflated 57%)\n",
            "  adding: content/models/official/nlp/modeling/networks/README.md (deflated 53%)\n",
            "  adding: content/models/official/nlp/modeling/networks/encoder_scaffold.py (deflated 71%)\n",
            "  adding: content/models/official/nlp/modeling/networks/albert_encoder_test.py (deflated 71%)\n",
            "  adding: content/models/official/nlp/modeling/networks/packed_sequence_embedding_test.py (deflated 67%)\n",
            "  adding: content/models/official/nlp/modeling/networks/__init__.py (deflated 58%)\n",
            "  adding: content/models/official/nlp/modeling/networks/bert_dense_encoder_test.py (deflated 85%)\n",
            "  adding: content/models/official/nlp/modeling/networks/xlnet_base.py (deflated 75%)\n",
            "  adding: content/models/official/nlp/modeling/networks/span_labeling.py (deflated 72%)\n",
            "  adding: content/models/official/nlp/modeling/networks/funnel_transformer_test.py (deflated 77%)\n",
            "  adding: content/models/official/nlp/modeling/networks/span_labeling_test.py (deflated 80%)\n",
            "  adding: content/models/official/nlp/modeling/networks/bert_dense_encoder.py (deflated 70%)\n",
            "  adding: content/models/official/nlp/modeling/networks/bert_encoder_test.py (deflated 87%)\n",
            "  adding: content/models/official/nlp/modeling/networks/albert_encoder.py (deflated 66%)\n",
            "  adding: content/models/official/nlp/modeling/networks/classification_test.py (deflated 77%)\n",
            "  adding: content/models/official/nlp/modeling/networks/packed_sequence_embedding.py (deflated 71%)\n",
            "  adding: content/models/official/nlp/modeling/networks/encoder_scaffold_test.py (deflated 86%)\n",
            "  adding: content/models/official/nlp/modeling/networks/mobile_bert_encoder.py (deflated 68%)\n",
            "  adding: content/models/official/nlp/modeling/networks/mobile_bert_encoder_test.py (deflated 77%)\n",
            "  adding: content/models/official/nlp/modeling/networks/funnel_transformer.py (deflated 71%)\n",
            "  adding: content/models/official/nlp/modeling/networks/bert_encoder.py (deflated 79%)\n",
            "  adding: content/models/official/nlp/data/ (stored 0%)\n",
            "  adding: content/models/official/nlp/data/question_answering_dataloader_test.py (deflated 60%)\n",
            "  adding: content/models/official/nlp/data/pretrain_dynamic_dataloader_test.py (deflated 75%)\n",
            "  adding: content/models/official/nlp/data/create_finetuning_data.py (deflated 78%)\n",
            "  adding: content/models/official/nlp/data/sentence_prediction_dataloader.py (deflated 72%)\n",
            "  adding: content/models/official/nlp/data/tagging_dataloader.py (deflated 62%)\n",
            "  adding: content/models/official/nlp/data/create_pretraining_data_test.py (deflated 70%)\n",
            "  adding: content/models/official/nlp/data/tagging_dataloader_test.py (deflated 62%)\n",
            "  adding: content/models/official/nlp/data/question_answering_dataloader.py (deflated 62%)\n",
            "  adding: content/models/official/nlp/data/create_xlnet_pretraining_data.py (deflated 71%)\n",
            "  adding: content/models/official/nlp/data/create_xlnet_pretraining_data_test.py (deflated 73%)\n",
            "  adding: content/models/official/nlp/data/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/nlp/data/tagging_data_lib_test.py (deflated 63%)\n",
            "  adding: content/models/official/nlp/data/squad_lib_sp.py (deflated 75%)\n",
            "  adding: content/models/official/nlp/data/pretrain_dataloader_test.py (deflated 79%)\n",
            "  adding: content/models/official/nlp/data/train_sentencepiece.py (deflated 59%)\n",
            "  adding: content/models/official/nlp/data/tagging_data_lib.py (deflated 72%)\n",
            "  adding: content/models/official/nlp/data/classifier_data_lib_test.py (deflated 59%)\n",
            "  adding: content/models/official/nlp/data/dual_encoder_dataloader.py (deflated 63%)\n",
            "  adding: content/models/official/nlp/data/squad_lib.py (deflated 75%)\n",
            "  adding: content/models/official/nlp/data/data_loader_factory_test.py (deflated 49%)\n",
            "  adding: content/models/official/nlp/data/dual_encoder_dataloader_test.py (deflated 70%)\n",
            "  adding: content/models/official/nlp/data/pretrain_dataloader.py (deflated 77%)\n",
            "  adding: content/models/official/nlp/data/data_loader_factory.py (deflated 53%)\n",
            "  adding: content/models/official/nlp/data/wmt_dataloader_test.py (deflated 65%)\n",
            "  adding: content/models/official/nlp/data/create_pretraining_data.py (deflated 69%)\n",
            "  adding: content/models/official/nlp/data/wmt_dataloader.py (deflated 67%)\n",
            "  adding: content/models/official/nlp/data/data_loader.py (deflated 50%)\n",
            "  adding: content/models/official/nlp/data/pretrain_dynamic_dataloader.py (deflated 66%)\n",
            "  adding: content/models/official/nlp/data/classifier_data_lib.py (deflated 84%)\n",
            "  adding: content/models/official/nlp/data/sentence_prediction_dataloader_test.py (deflated 80%)\n",
            "  adding: content/models/official/nlp/data/sentence_retrieval_lib.py (deflated 70%)\n",
            "  adding: content/models/official/nlp/serving/ (stored 0%)\n",
            "  adding: content/models/official/nlp/serving/export_savedmodel_util.py (deflated 56%)\n",
            "  adding: content/models/official/nlp/serving/serving_modules_test.py (deflated 82%)\n",
            "  adding: content/models/official/nlp/serving/serving_modules.py (deflated 84%)\n",
            "  adding: content/models/official/nlp/serving/export_savedmodel.py (deflated 63%)\n",
            "  adding: content/models/official/nlp/serving/export_savedmodel_test.py (deflated 75%)\n",
            "  adding: content/models/official/nlp/metrics/ (stored 0%)\n",
            "  adding: content/models/official/nlp/metrics/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/nlp/metrics/bleu_test.py (deflated 65%)\n",
            "  adding: content/models/official/nlp/metrics/bleu.py (deflated 62%)\n",
            "  adding: content/models/official/nlp/continuous_finetune_lib_test.py (deflated 62%)\n",
            "  adding: content/models/official/nlp/configs/ (stored 0%)\n",
            "  adding: content/models/official/nlp/configs/bert.py (deflated 48%)\n",
            "  adding: content/models/official/nlp/configs/encoders.py (deflated 84%)\n",
            "  adding: content/models/official/nlp/configs/experiment_configs.py (deflated 45%)\n",
            "  adding: content/models/official/nlp/configs/finetuning_experiments.py (deflated 79%)\n",
            "  adding: content/models/official/nlp/configs/experiments/ (stored 0%)\n",
            "  adding: content/models/official/nlp/configs/experiments/glue_mnli_matched.yaml (deflated 59%)\n",
            "  adding: content/models/official/nlp/configs/experiments/squad_v1.yaml (deflated 58%)\n",
            "  adding: content/models/official/nlp/configs/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/nlp/configs/pretraining_experiments.py (deflated 64%)\n",
            "  adding: content/models/official/nlp/configs/electra.py (deflated 48%)\n",
            "  adding: content/models/official/nlp/configs/wmt_transformer_experiments.py (deflated 64%)\n",
            "  adding: content/models/official/nlp/configs/models/ (stored 0%)\n",
            "  adding: content/models/official/nlp/configs/models/bert_en_uncased_base.yaml (deflated 52%)\n",
            "  adding: content/models/official/nlp/configs/models/albert_base.yaml (deflated 53%)\n",
            "  adding: content/models/official/nlp/configs/encoders_test.py (deflated 51%)\n",
            "  adding: content/models/official/README-TPU.md (deflated 62%)\n",
            "  adding: content/models/official/common/ (stored 0%)\n",
            "  adding: content/models/official/common/dataset_fn.py (deflated 63%)\n",
            "  adding: content/models/official/common/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/common/flags.py (deflated 60%)\n",
            "  adding: content/models/official/common/registry_imports.py (deflated 42%)\n",
            "  adding: content/models/official/common/distribute_utils_test.py (deflated 73%)\n",
            "  adding: content/models/official/common/distribute_utils.py (deflated 68%)\n",
            "  adding: content/models/official/common/streamz_counters.py (deflated 47%)\n",
            "  adding: content/models/official/modeling/ (stored 0%)\n",
            "  adding: content/models/official/modeling/multitask/ (stored 0%)\n",
            "  adding: content/models/official/modeling/multitask/interleaving_trainer.py (deflated 61%)\n",
            "  adding: content/models/official/modeling/multitask/train_lib_test.py (deflated 72%)\n",
            "  adding: content/models/official/modeling/multitask/train_lib.py (deflated 76%)\n",
            "  adding: content/models/official/modeling/multitask/base_model.py (deflated 49%)\n",
            "  adding: content/models/official/modeling/multitask/multitask.py (deflated 65%)\n",
            "  adding: content/models/official/modeling/multitask/evaluator_test.py (deflated 64%)\n",
            "  adding: content/models/official/modeling/multitask/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/modeling/multitask/task_sampler_test.py (deflated 64%)\n",
            "  adding: content/models/official/modeling/multitask/configs.py (deflated 62%)\n",
            "  adding: content/models/official/modeling/multitask/base_trainer_test.py (deflated 67%)\n",
            "  adding: content/models/official/modeling/multitask/base_trainer.py (deflated 68%)\n",
            "  adding: content/models/official/modeling/multitask/task_sampler.py (deflated 68%)\n",
            "  adding: content/models/official/modeling/multitask/test_utils.py (deflated 66%)\n",
            "  adding: content/models/official/modeling/multitask/evaluator.py (deflated 67%)\n",
            "  adding: content/models/official/modeling/multitask/interleaving_trainer_test.py (deflated 70%)\n",
            "  adding: content/models/official/modeling/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/modeling/grad_utils.py (deflated 70%)\n",
            "  adding: content/models/official/modeling/grad_utils_test.py (deflated 65%)\n",
            "  adding: content/models/official/modeling/optimization/ (stored 0%)\n",
            "  adding: content/models/official/modeling/optimization/ema_optimizer.py (deflated 68%)\n",
            "  adding: content/models/official/modeling/optimization/lr_schedule.py (deflated 79%)\n",
            "  adding: content/models/official/modeling/optimization/__init__.py (deflated 54%)\n",
            "  adding: content/models/official/modeling/optimization/lr_schedule_test.py (deflated 69%)\n",
            "  adding: content/models/official/modeling/optimization/adafactor_optimizer.py (deflated 39%)\n",
            "  adding: content/models/official/modeling/optimization/lars_optimizer.py (deflated 67%)\n",
            "  adding: content/models/official/modeling/optimization/slide_optimizer.py (deflated 38%)\n",
            "  adding: content/models/official/modeling/optimization/optimizer_factory_test.py (deflated 85%)\n",
            "  adding: content/models/official/modeling/optimization/optimizer_factory.py (deflated 68%)\n",
            "  adding: content/models/official/modeling/optimization/configs/ (stored 0%)\n",
            "  adding: content/models/official/modeling/optimization/configs/learning_rate_config.py (deflated 79%)\n",
            "  adding: content/models/official/modeling/optimization/configs/optimizer_config.py (deflated 73%)\n",
            "  adding: content/models/official/modeling/optimization/configs/optimization_config_test.py (deflated 61%)\n",
            "  adding: content/models/official/modeling/optimization/configs/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/modeling/optimization/configs/optimization_config.py (deflated 70%)\n",
            "  adding: content/models/official/modeling/tf_utils.py (deflated 65%)\n",
            "  adding: content/models/official/modeling/activations/ (stored 0%)\n",
            "  adding: content/models/official/modeling/activations/swish_test.py (deflated 52%)\n",
            "  adding: content/models/official/modeling/activations/sigmoid_test.py (deflated 46%)\n",
            "  adding: content/models/official/modeling/activations/__init__.py (deflated 52%)\n",
            "  adding: content/models/official/modeling/activations/gelu_test.py (deflated 41%)\n",
            "  adding: content/models/official/modeling/activations/sigmoid.py (deflated 41%)\n",
            "  adding: content/models/official/modeling/activations/gelu.py (deflated 40%)\n",
            "  adding: content/models/official/modeling/activations/swish.py (deflated 59%)\n",
            "  adding: content/models/official/modeling/activations/relu_test.py (deflated 44%)\n",
            "  adding: content/models/official/modeling/activations/relu.py (deflated 41%)\n",
            "  adding: content/models/official/modeling/fast_training/ (stored 0%)\n",
            "  adding: content/models/official/modeling/fast_training/progressive/ (stored 0%)\n",
            "  adding: content/models/official/modeling/fast_training/progressive/train_lib_test.py (deflated 68%)\n",
            "  adding: content/models/official/modeling/fast_training/progressive/train_lib.py (deflated 64%)\n",
            "  adding: content/models/official/modeling/fast_training/progressive/trainer.py (deflated 71%)\n",
            "  adding: content/models/official/modeling/fast_training/progressive/train.py (deflated 56%)\n",
            "  adding: content/models/official/modeling/fast_training/progressive/trainer_test.py (deflated 74%)\n",
            "  adding: content/models/official/modeling/fast_training/progressive/policies.py (deflated 68%)\n",
            "  adding: content/models/official/modeling/fast_training/progressive/utils.py (deflated 54%)\n",
            "  adding: content/models/official/modeling/fast_training/experimental/ (stored 0%)\n",
            "  adding: content/models/official/modeling/fast_training/experimental/tf2_utils_2x_wide.py (deflated 68%)\n",
            "  adding: content/models/official/modeling/fast_training/experimental/tf2_utils_2x_wide_test.py (deflated 69%)\n",
            "  adding: content/models/official/modeling/hyperparams/ (stored 0%)\n",
            "  adding: content/models/official/modeling/hyperparams/oneof_test.py (deflated 56%)\n",
            "  adding: content/models/official/modeling/hyperparams/base_config.py (deflated 68%)\n",
            "  adding: content/models/official/modeling/hyperparams/__init__.py (deflated 43%)\n",
            "  adding: content/models/official/modeling/hyperparams/oneof.py (deflated 55%)\n",
            "  adding: content/models/official/modeling/hyperparams/params_dict_test.py (deflated 82%)\n",
            "  adding: content/models/official/modeling/hyperparams/base_config_test.py (deflated 76%)\n",
            "  adding: content/models/official/modeling/hyperparams/params_dict.py (deflated 70%)\n",
            "  adding: content/models/official/modeling/performance.py (deflated 56%)\n",
            "  adding: content/models/official/recommendation/ (stored 0%)\n",
            "  adding: content/models/official/recommendation/README.md (deflated 58%)\n",
            "  adding: content/models/official/recommendation/popen_helper.py (deflated 58%)\n",
            "  adding: content/models/official/recommendation/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/recommendation/ncf_keras_main.py (deflated 70%)\n",
            "  adding: content/models/official/recommendation/ncf_input_pipeline.py (deflated 68%)\n",
            "  adding: content/models/official/recommendation/constants.py (deflated 53%)\n",
            "  adding: content/models/official/recommendation/data_preprocessing.py (deflated 67%)\n",
            "  adding: content/models/official/recommendation/create_ncf_data.py (deflated 62%)\n",
            "  adding: content/models/official/recommendation/run.sh (deflated 53%)\n",
            "  adding: content/models/official/recommendation/data_pipeline.py (deflated 74%)\n",
            "  adding: content/models/official/recommendation/ncf_common.py (deflated 68%)\n",
            "  adding: content/models/official/recommendation/neumf_model.py (deflated 67%)\n",
            "  adding: content/models/official/recommendation/stat_utils.py (deflated 53%)\n",
            "  adding: content/models/official/recommendation/ncf_test.py (deflated 71%)\n",
            "  adding: content/models/official/recommendation/data_test.py (deflated 67%)\n",
            "  adding: content/models/official/recommendation/movielens.py (deflated 63%)\n",
            "  adding: content/models/official/recommendation/ranking/ (stored 0%)\n",
            "  adding: content/models/official/recommendation/ranking/README.md (deflated 57%)\n",
            "  adding: content/models/official/recommendation/ranking/task_test.py (deflated 57%)\n",
            "  adding: content/models/official/recommendation/ranking/train.py (deflated 66%)\n",
            "  adding: content/models/official/recommendation/ranking/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/recommendation/ranking/train_test.py (deflated 70%)\n",
            "  adding: content/models/official/recommendation/ranking/common.py (deflated 61%)\n",
            "  adding: content/models/official/recommendation/ranking/preprocessing/ (stored 0%)\n",
            "  adding: content/models/official/recommendation/ranking/preprocessing/README.md (deflated 72%)\n",
            "  adding: content/models/official/recommendation/ranking/preprocessing/shard_rebalancer.py (deflated 62%)\n",
            "  adding: content/models/official/recommendation/ranking/preprocessing/criteo_preprocess.py (deflated 66%)\n",
            "  adding: content/models/official/recommendation/ranking/preprocessing/setup.py (deflated 42%)\n",
            "  adding: content/models/official/recommendation/ranking/task.py (deflated 67%)\n",
            "  adding: content/models/official/recommendation/ranking/data/ (stored 0%)\n",
            "  adding: content/models/official/recommendation/ranking/data/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/recommendation/ranking/data/data_pipeline_test.py (deflated 56%)\n",
            "  adding: content/models/official/recommendation/ranking/data/data_pipeline.py (deflated 68%)\n",
            "  adding: content/models/official/recommendation/ranking/configs/ (stored 0%)\n",
            "  adding: content/models/official/recommendation/ranking/configs/yaml/ (stored 0%)\n",
            "  adding: content/models/official/recommendation/ranking/configs/yaml/dlrm_criteo_tpu.yaml (deflated 54%)\n",
            "  adding: content/models/official/recommendation/ranking/configs/yaml/dcn_v2_criteo_tpu.yaml (deflated 54%)\n",
            "  adding: content/models/official/recommendation/ranking/configs/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/recommendation/ranking/configs/config_test.py (deflated 54%)\n",
            "  adding: content/models/official/recommendation/ranking/configs/config.py (deflated 74%)\n",
            "  adding: content/models/official/core/ (stored 0%)\n",
            "  adding: content/models/official/core/actions.py (deflated 70%)\n",
            "  adding: content/models/official/core/registry.py (deflated 68%)\n",
            "  adding: content/models/official/core/train_lib_test.py (deflated 75%)\n",
            "  adding: content/models/official/core/train_lib.py (deflated 66%)\n",
            "  adding: content/models/official/core/task_factory.py (deflated 55%)\n",
            "  adding: content/models/official/core/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/core/base_task.py (deflated 70%)\n",
            "  adding: content/models/official/core/actions_test.py (deflated 68%)\n",
            "  adding: content/models/official/core/export_base.py (deflated 61%)\n",
            "  adding: content/models/official/core/input_reader.py (deflated 75%)\n",
            "  adding: content/models/official/core/train_utils.py (deflated 69%)\n",
            "  adding: content/models/official/core/exp_factory.py (deflated 46%)\n",
            "  adding: content/models/official/core/export_base_test.py (deflated 68%)\n",
            "  adding: content/models/official/core/config_definitions.py (deflated 64%)\n",
            "  adding: content/models/official/core/base_trainer_test.py (deflated 75%)\n",
            "  adding: content/models/official/core/base_trainer.py (deflated 72%)\n",
            "  adding: content/models/official/core/registry_test.py (deflated 66%)\n",
            "  adding: content/models/official/core/test_utils.py (deflated 57%)\n",
            "  adding: content/models/official/core/train_utils_test.py (deflated 68%)\n",
            "  adding: content/models/official/requirements.txt (deflated 36%)\n",
            "  adding: content/models/official/legacy/ (stored 0%)\n",
            "  adding: content/models/official/legacy/image_classification/ (stored 0%)\n",
            "  adding: content/models/official/legacy/image_classification/mnist_main.py (deflated 62%)\n",
            "  adding: content/models/official/legacy/image_classification/callbacks.py (deflated 69%)\n",
            "  adding: content/models/official/legacy/image_classification/efficientnet/ (stored 0%)\n",
            "  adding: content/models/official/legacy/image_classification/efficientnet/common_modules.py (deflated 62%)\n",
            "  adding: content/models/official/legacy/image_classification/efficientnet/efficientnet_model.py (deflated 70%)\n",
            "  adding: content/models/official/legacy/image_classification/efficientnet/efficientnet_config.py (deflated 57%)\n",
            "  adding: content/models/official/legacy/image_classification/efficientnet/tfhub_export.py (deflated 54%)\n",
            "  adding: content/models/official/legacy/image_classification/efficientnet/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/legacy/image_classification/README.md (deflated 64%)\n",
            "  adding: content/models/official/legacy/image_classification/classifier_trainer_util_test.py (deflated 66%)\n",
            "  adding: content/models/official/legacy/image_classification/augment_test.py (deflated 66%)\n",
            "  adding: content/models/official/legacy/image_classification/learning_rate.py (deflated 67%)\n",
            "  adding: content/models/official/legacy/image_classification/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/legacy/image_classification/mnist_test.py (deflated 55%)\n",
            "  adding: content/models/official/legacy/image_classification/augment.py (deflated 73%)\n",
            "  adding: content/models/official/legacy/image_classification/classifier_trainer_test.py (deflated 74%)\n",
            "  adding: content/models/official/legacy/image_classification/learning_rate_test.py (deflated 53%)\n",
            "  adding: content/models/official/legacy/image_classification/classifier_trainer.py (deflated 71%)\n",
            "  adding: content/models/official/legacy/image_classification/preprocessing.py (deflated 75%)\n",
            "  adding: content/models/official/legacy/image_classification/dataset_factory.py (deflated 72%)\n",
            "  adding: content/models/official/legacy/image_classification/test_utils.py (deflated 47%)\n",
            "  adding: content/models/official/legacy/image_classification/optimizer_factory_test.py (deflated 65%)\n",
            "  adding: content/models/official/legacy/image_classification/optimizer_factory.py (deflated 69%)\n",
            "  adding: content/models/official/legacy/image_classification/configs/ (stored 0%)\n",
            "  adding: content/models/official/legacy/image_classification/configs/examples/ (stored 0%)\n",
            "  adding: content/models/official/legacy/image_classification/configs/examples/efficientnet/ (stored 0%)\n",
            "  adding: content/models/official/legacy/image_classification/configs/examples/efficientnet/imagenet/ (stored 0%)\n",
            "  adding: content/models/official/legacy/image_classification/configs/examples/efficientnet/imagenet/efficientnet-b1-gpu.yaml (deflated 55%)\n",
            "  adding: content/models/official/legacy/image_classification/configs/examples/efficientnet/imagenet/efficientnet-b1-tpu.yaml (deflated 55%)\n",
            "  adding: content/models/official/legacy/image_classification/configs/examples/efficientnet/imagenet/efficientnet-b0-gpu.yaml (deflated 54%)\n",
            "  adding: content/models/official/legacy/image_classification/configs/examples/efficientnet/imagenet/efficientnet-b0-tpu.yaml (deflated 54%)\n",
            "  adding: content/models/official/legacy/image_classification/configs/examples/resnet/ (stored 0%)\n",
            "  adding: content/models/official/legacy/image_classification/configs/examples/resnet/imagenet/ (stored 0%)\n",
            "  adding: content/models/official/legacy/image_classification/configs/examples/resnet/imagenet/gpu.yaml (deflated 55%)\n",
            "  adding: content/models/official/legacy/image_classification/configs/examples/resnet/imagenet/tpu.yaml (deflated 56%)\n",
            "  adding: content/models/official/legacy/image_classification/configs/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/legacy/image_classification/configs/configs.py (deflated 72%)\n",
            "  adding: content/models/official/legacy/image_classification/configs/base_configs.py (deflated 72%)\n",
            "  adding: content/models/official/legacy/image_classification/resnet/ (stored 0%)\n",
            "  adding: content/models/official/legacy/image_classification/resnet/resnet_config.py (deflated 53%)\n",
            "  adding: content/models/official/legacy/image_classification/resnet/resnet_model.py (deflated 78%)\n",
            "  adding: content/models/official/legacy/image_classification/resnet/resnet_ctl_imagenet_main.py (deflated 66%)\n",
            "  adding: content/models/official/legacy/image_classification/resnet/README.md (deflated 57%)\n",
            "  adding: content/models/official/legacy/image_classification/resnet/tfhub_export.py (deflated 53%)\n",
            "  adding: content/models/official/legacy/image_classification/resnet/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/legacy/image_classification/resnet/imagenet_preprocessing.py (deflated 69%)\n",
            "  adding: content/models/official/legacy/image_classification/resnet/common.py (deflated 68%)\n",
            "  adding: content/models/official/legacy/image_classification/resnet/resnet_runnable.py (deflated 69%)\n",
            "  adding: content/models/official/vision/ (stored 0%)\n",
            "  adding: content/models/official/vision/utils/ (stored 0%)\n",
            "  adding: content/models/official/vision/utils/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/utils/object_detection/ (stored 0%)\n",
            "  adding: content/models/official/vision/utils/object_detection/region_similarity_calculator.py (deflated 67%)\n",
            "  adding: content/models/official/vision/utils/object_detection/preprocessor.py (deflated 75%)\n",
            "  adding: content/models/official/vision/utils/object_detection/argmax_matcher.py (deflated 71%)\n",
            "  adding: content/models/official/vision/utils/object_detection/box_list_ops.py (deflated 77%)\n",
            "  adding: content/models/official/vision/utils/object_detection/faster_rcnn_box_coder.py (deflated 61%)\n",
            "  adding: content/models/official/vision/utils/object_detection/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/utils/object_detection/minibatch_sampler.py (deflated 57%)\n",
            "  adding: content/models/official/vision/utils/object_detection/target_assigner.py (deflated 83%)\n",
            "  adding: content/models/official/vision/utils/object_detection/matcher.py (deflated 71%)\n",
            "  adding: content/models/official/vision/utils/object_detection/visualization_utils.py (deflated 75%)\n",
            "  adding: content/models/official/vision/utils/object_detection/box_list.py (deflated 66%)\n",
            "  adding: content/models/official/vision/utils/object_detection/shape_utils.py (deflated 62%)\n",
            "  adding: content/models/official/vision/utils/object_detection/balanced_positive_negative_sampler.py (deflated 73%)\n",
            "  adding: content/models/official/vision/utils/object_detection/box_coder.py (deflated 64%)\n",
            "  adding: content/models/official/vision/utils/object_detection/ops.py (deflated 57%)\n",
            "  adding: content/models/official/vision/beta/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/example/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/example/README.md (deflated 63%)\n",
            "  adding: content/models/official/vision/beta/projects/example/train.py (deflated 44%)\n",
            "  adding: content/models/official/vision/beta/projects/example/example_config.py (deflated 65%)\n",
            "  adding: content/models/official/vision/beta/projects/example/example_task.py (deflated 66%)\n",
            "  adding: content/models/official/vision/beta/projects/example/example_model.py (deflated 59%)\n",
            "  adding: content/models/official/vision/beta/projects/example/registry_imports.py (deflated 50%)\n",
            "  adding: content/models/official/vision/beta/projects/example/example_config_local.yaml (deflated 55%)\n",
            "  adding: content/models/official/vision/beta/projects/example/example_input.py (deflated 63%)\n",
            "  adding: content/models/official/vision/beta/projects/example/example_config_tpu.yaml (deflated 55%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/README.md (deflated 56%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/tasks/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/tasks/deep_mask_head_rcnn.py (deflated 75%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/tasks/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/train.py (deflated 56%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/common/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/common/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/common/registry_imports.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/modeling/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/modeling/heads/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/modeling/heads/hourglass_network.py (deflated 79%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/modeling/heads/instance_heads.py (deflated 75%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/modeling/heads/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/modeling/heads/instance_heads_test.py (deflated 67%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/modeling/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/modeling/maskrcnn_model.py (deflated 71%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/modeling/maskrcnn_model_test.py (deflated 69%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/serving/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/serving/export_saved_model.py (deflated 61%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/serving/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/serving/detection_test.py (deflated 70%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/serving/detection.py (deflated 64%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/configs/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/configs/experiments/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/configs/experiments/deep_mask_head_rcnn_voc_spinenet143_hg52.yaml (deflated 49%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/configs/experiments/deep_mask_head_rcnn_nonvoc_spinenet143_hg52.yaml (deflated 49%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/configs/experiments/deep_mask_head_rcnn_voc_r101_hg52.yaml (deflated 46%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/configs/experiments/deep_mask_head_rcnn_voc_r50_hg52.yaml (deflated 46%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/configs/experiments/deep_mask_head_rcnn_voc_r50.yaml (deflated 45%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/configs/deep_mask_head_rcnn.py (deflated 76%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/configs/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/projects/deepmac_maskrcnn/configs/deep_mask_head_rcnn_config_test.py (deflated 50%)\n",
            "  adding: content/models/official/vision/beta/projects/README.md (deflated 34%)\n",
            "  adding: content/models/official/vision/beta/projects/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/README.md (deflated 58%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/tasks/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/tasks/task_utils.py (deflated 54%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/tasks/image_classification.py (deflated 65%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/tasks/yolo.py (deflated 70%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/train.py (deflated 43%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/losses/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/losses/yolo_loss.py (deflated 76%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/losses/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/losses/yolo_loss_test.py (deflated 58%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/dataloaders/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/dataloaders/classification_input.py (deflated 69%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/dataloaders/tf_example_decoder.py (deflated 62%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/dataloaders/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/dataloaders/yolo_input.py (deflated 71%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/optimization/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/optimization/__init__.py (deflated 51%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/optimization/sgd_torch.py (deflated 70%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/optimization/optimizer_factory.py (deflated 60%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/optimization/configs/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/optimization/configs/optimizer_config.py (deflated 58%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/optimization/configs/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/optimization/configs/optimization_config.py (deflated 57%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/common/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/common/registry_imports.py (deflated 60%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/modeling/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/modeling/heads/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/modeling/heads/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/modeling/heads/yolo_head_test.py (deflated 57%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/modeling/heads/yolo_head.py (deflated 65%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/modeling/factory.py (deflated 70%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/modeling/yolo_model.py (deflated 59%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/modeling/decoders/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/modeling/decoders/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/modeling/decoders/yolo_decoder.py (deflated 80%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/modeling/decoders/yolo_decoder_test.py (deflated 70%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/modeling/backbones/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/modeling/backbones/darknet_test.py (deflated 66%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/modeling/backbones/darknet.py (deflated 78%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/modeling/layers/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/modeling/layers/nn_blocks_test.py (deflated 83%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/modeling/layers/nn_blocks.py (deflated 84%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/modeling/layers/detection_generator_test.py (deflated 48%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/modeling/layers/detection_generator.py (deflated 68%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/ops/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/ops/math_ops.py (deflated 55%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/ops/mosaic.py (deflated 75%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/ops/box_ops_test.py (deflated 60%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/ops/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/ops/anchor.py (deflated 72%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/ops/loss_utils.py (deflated 74%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/ops/preprocessing_ops_test.py (deflated 72%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/ops/preprocessing_ops.py (deflated 74%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/ops/box_ops.py (deflated 78%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/configs/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/configs/experiments/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/configs/experiments/yolov4/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/configs/experiments/yolov4/imagenet_pretraining/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/configs/experiments/yolov4/imagenet_pretraining/cspdarknet53_256_tpu.yaml (deflated 58%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/configs/experiments/yolov4/detection/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/configs/experiments/yolov4/detection/yolov4_512_tpu.yaml (deflated 63%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/configs/experiments/scaled-yolo/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/configs/experiments/scaled-yolo/detection/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/configs/experiments/scaled-yolo/detection/yolo_csp_640_tpu.yaml (deflated 59%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/configs/experiments/scaled-yolo/detection/yolo_l_p5_896_tpu.yaml (deflated 59%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/configs/experiments/scaled-yolo/detection/yolo_l_p6_1280_tpu.yaml (deflated 60%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/configs/experiments/scaled-yolo/detection/yolo_l_p7_1536_tpu.yaml (deflated 60%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/configs/experiments/scaled-yolo/tpu/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/configs/experiments/scaled-yolo/tpu/640.yaml (deflated 59%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/configs/experiments/darknet/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/configs/experiments/darknet/csp_darknet53.yaml (deflated 58%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/configs/experiments/darknet/csp_darknet53_tfds.yaml (deflated 61%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/configs/experiments/darknet/darknet53_tfds.yaml (deflated 61%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/configs/experiments/darknet/darknet53.yaml (deflated 58%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/configs/darknet_classification.py (deflated 57%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/configs/backbones.py (deflated 46%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/configs/yolo.py (deflated 78%)\n",
            "  adding: content/models/official/vision/beta/projects/yolo/configs/decoders.py (deflated 55%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/utils/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/utils/checkpoints/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/utils/checkpoints/config_classes.py (deflated 78%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/utils/checkpoints/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/utils/checkpoints/load_weights.py (deflated 74%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/utils/checkpoints/config_data.py (deflated 76%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/utils/checkpoints/read_checkpoints.py (deflated 59%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/utils/tf2_centernet_checkpoint_converter.py (deflated 70%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/README.md (deflated 53%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/tasks/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/tasks/centernet.py (deflated 73%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/train.py (deflated 55%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/losses/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/losses/centernet_losses.py (deflated 65%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/losses/centernet_losses_test.py (deflated 68%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/dataloaders/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/dataloaders/centernet_input.py (deflated 75%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/common/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/common/registry_imports.py (deflated 50%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/modeling/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/modeling/heads/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/modeling/heads/centernet_head_test.py (deflated 59%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/modeling/heads/centernet_head.py (deflated 58%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/modeling/centernet_model_test.py (deflated 62%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/modeling/centernet_model.py (deflated 60%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/modeling/backbones/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/modeling/backbones/hourglass.py (deflated 75%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/modeling/backbones/hourglass_test.py (deflated 50%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/modeling/layers/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/modeling/layers/detection_generator.py (deflated 71%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/modeling/layers/cn_nn_blocks_test.py (deflated 66%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/modeling/layers/cn_nn_blocks.py (deflated 74%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/ops/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/ops/box_list_ops.py (deflated 70%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/ops/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/ops/target_assigner.py (deflated 70%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/ops/preprocess_ops.py (deflated 76%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/ops/box_list.py (deflated 65%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/ops/loss_ops.py (deflated 65%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/ops/nms_ops.py (deflated 65%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/ops/target_assigner_test.py (deflated 75%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/configs/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/configs/centernet_test.py (deflated 52%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/configs/experiments/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/configs/experiments/coco-centernet-hourglass-tpu.yaml (deflated 57%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/configs/experiments/coco-centernet-hourglass-gpu.yaml (deflated 57%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/configs/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/configs/centernet.py (deflated 67%)\n",
            "  adding: content/models/official/vision/beta/projects/centernet/configs/backbones.py (deflated 45%)\n",
            "  adding: content/models/official/vision/beta/projects/video_ssl/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/video_ssl/README.md (deflated 59%)\n",
            "  adding: content/models/official/vision/beta/projects/video_ssl/tasks/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/video_ssl/tasks/pretrain_test.py (deflated 58%)\n",
            "  adding: content/models/official/vision/beta/projects/video_ssl/tasks/pretrain.py (deflated 67%)\n",
            "  adding: content/models/official/vision/beta/projects/video_ssl/tasks/__init__.py (deflated 41%)\n",
            "  adding: content/models/official/vision/beta/projects/video_ssl/tasks/linear_eval.py (deflated 57%)\n",
            "  adding: content/models/official/vision/beta/projects/video_ssl/train.py (deflated 59%)\n",
            "  adding: content/models/official/vision/beta/projects/video_ssl/losses/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/video_ssl/losses/losses.py (deflated 63%)\n",
            "  adding: content/models/official/vision/beta/projects/video_ssl/dataloaders/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/video_ssl/dataloaders/video_ssl_input_test.py (deflated 68%)\n",
            "  adding: content/models/official/vision/beta/projects/video_ssl/dataloaders/video_ssl_input.py (deflated 73%)\n",
            "  adding: content/models/official/vision/beta/projects/video_ssl/modeling/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/video_ssl/modeling/video_ssl_model.py (deflated 68%)\n",
            "  adding: content/models/official/vision/beta/projects/video_ssl/ops/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/video_ssl/ops/video_ssl_preprocess_ops_test.py (deflated 56%)\n",
            "  adding: content/models/official/vision/beta/projects/video_ssl/ops/video_ssl_preprocess_ops.py (deflated 72%)\n",
            "  adding: content/models/official/vision/beta/projects/video_ssl/configs/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/video_ssl/configs/video_ssl_test.py (deflated 64%)\n",
            "  adding: content/models/official/vision/beta/projects/video_ssl/configs/experiments/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/video_ssl/configs/experiments/cvrl_linear_eval_k600.yaml (deflated 70%)\n",
            "  adding: content/models/official/vision/beta/projects/video_ssl/configs/experiments/cvrl_pretrain_k600_200ep.yaml (deflated 70%)\n",
            "  adding: content/models/official/vision/beta/projects/video_ssl/configs/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/projects/video_ssl/configs/video_ssl.py (deflated 78%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/README.md (deflated 70%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/train.py (deflated 59%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/export_saved_model.py (deflated 64%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/movinet_tutorial.ipynb (deflated 74%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/train_test.py (deflated 59%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/tools/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/tools/convert_3d_2plus1d.py (deflated 62%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/tools/convert_3d_2plus1d_test.py (deflated 55%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/modeling/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/modeling/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/modeling/movinet_test.py (deflated 77%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/modeling/movinet_layers_test.py (deflated 85%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/modeling/movinet_layers.py (deflated 86%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/modeling/movinet_model.py (deflated 69%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/modeling/movinet_model_test.py (deflated 76%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/modeling/movinet.py (deflated 79%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/requirements.txt (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/export_saved_model_test.py (deflated 65%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/configs/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/configs/yaml/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/configs/yaml/movinet_a3_stream_k600_8x8.yaml (deflated 56%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/configs/yaml/movinet_a3_k600_8x8.yaml (deflated 56%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/configs/yaml/movinet_a2_stream_k600_8x8.yaml (deflated 56%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/configs/yaml/movinet_a4_stream_k600_8x8.yaml (deflated 57%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/configs/yaml/movinet_a2_k600_8x8.yaml (deflated 56%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/configs/yaml/movinet_t0_k600_8x8.yaml (deflated 56%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/configs/yaml/movinet_a0_k600_cpu_local.yaml (deflated 57%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/configs/yaml/movinet_a1_stream_k600_8x8.yaml (deflated 56%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/configs/yaml/movinet_a1_k600_8x8.yaml (deflated 56%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/configs/yaml/movinet_a0_k600_8x8.yaml (deflated 56%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/configs/yaml/movinet_a4_k600_8x8.yaml (deflated 56%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/configs/yaml/movinet_a5_k600_8x8.yaml (deflated 56%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/configs/yaml/movinet_t0_stream_k600_8x8.yaml (deflated 56%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/configs/yaml/movinet_a5_stream_k600_8x8.yaml (deflated 55%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/configs/yaml/movinet_a0_stream_k600_8x8.yaml (deflated 56%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/configs/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/configs/movinet_test.py (deflated 52%)\n",
            "  adding: content/models/official/vision/beta/projects/movinet/configs/movinet.py (deflated 64%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/README.md (deflated 59%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/tasks/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/tasks/panoptic_maskrcnn.py (deflated 75%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/tasks/panoptic_maskrcnn_test.py (deflated 63%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/tasks/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/train.py (deflated 47%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/__init__.py (deflated 67%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/dataloaders/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/dataloaders/panoptic_maskrcnn_input.py (deflated 75%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/modeling/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/modeling/factory_test.py (deflated 65%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/modeling/panoptic_maskrcnn_model_test.py (deflated 84%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/modeling/factory.py (deflated 74%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/modeling/layers/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/modeling/layers/paste_masks.py (deflated 68%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/modeling/layers/panoptic_segmentation_generator_test.py (deflated 65%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/modeling/layers/panoptic_segmentation_generator.py (deflated 71%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/modeling/panoptic_maskrcnn_model.py (deflated 73%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/serving/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/serving/panoptic_segmentation.py (deflated 64%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/serving/export_saved_model.py (deflated 62%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/serving/panoptic_segmentation_test.py (deflated 66%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/configs/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/configs/panoptic_maskrcnn.py (deflated 70%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/configs/panoptic_maskrcnn_test.py (deflated 51%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/configs/experiments/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/configs/experiments/r50fpn_1x_coco.yaml (deflated 46%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/configs/experiments/r50fpn_3x_coco.yaml (deflated 46%)\n",
            "  adding: content/models/official/vision/beta/projects/panoptic_maskrcnn/configs/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/projects/vit/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/vit/README.md (deflated 52%)\n",
            "  adding: content/models/official/vision/beta/projects/vit/train.py (deflated 45%)\n",
            "  adding: content/models/official/vision/beta/projects/vit/modeling/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/vit/modeling/nn_blocks.py (deflated 69%)\n",
            "  adding: content/models/official/vision/beta/projects/vit/modeling/vit.py (deflated 72%)\n",
            "  adding: content/models/official/vision/beta/projects/vit/modeling/vit_test.py (deflated 46%)\n",
            "  adding: content/models/official/vision/beta/projects/vit/configs/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/vit/configs/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/projects/vit/configs/image_classification.py (deflated 79%)\n",
            "  adding: content/models/official/vision/beta/projects/vit/configs/backbones.py (deflated 52%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/heads/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/heads/simclr_head.py (deflated 74%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/heads/simclr_head_test.py (deflated 70%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/README.md (deflated 57%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/tasks/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/tasks/simclr.py (deflated 81%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/train.py (deflated 55%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/losses/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/losses/contrastive_losses.py (deflated 64%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/losses/contrastive_losses_test.py (deflated 63%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/dataloaders/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/dataloaders/simclr_input.py (deflated 71%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/dataloaders/preprocess_ops.py (deflated 72%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/common/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/common/registry_imports.py (deflated 48%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/modeling/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/modeling/multitask_model.py (deflated 66%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/modeling/simclr_model_test.py (deflated 57%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/modeling/multitask_model_test.py (deflated 53%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/modeling/simclr_model.py (deflated 66%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/modeling/layers/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/modeling/layers/nn_blocks_test.py (deflated 51%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/modeling/layers/nn_blocks.py (deflated 65%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/multitask_train.py (deflated 58%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/configs/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/configs/simclr.py (deflated 78%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/configs/experiments/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/configs/experiments/cifar_simclr_pretrain.yaml (deflated 59%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/configs/experiments/imagenet_simclr_finetune_tpu.yaml (deflated 58%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/configs/experiments/imagenet_simclr_pretrain_gpu.yaml (deflated 59%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/configs/experiments/imagenet_simclr_multitask_tpu.yaml (deflated 70%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/configs/experiments/imagenet_simclr_finetune_gpu.yaml (deflated 58%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/configs/experiments/imagenet_simclr_pretrain_tpu.yaml (deflated 60%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/configs/multitask_config.py (deflated 62%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/configs/multitask_config_test.py (deflated 55%)\n",
            "  adding: content/models/official/vision/beta/projects/simclr/configs/simclr_test.py (deflated 55%)\n",
            "  adding: content/models/official/vision/beta/projects/assemblenet/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/assemblenet/README.md (deflated 50%)\n",
            "  adding: content/models/official/vision/beta/projects/assemblenet/train.py (deflated 63%)\n",
            "  adding: content/models/official/vision/beta/projects/assemblenet/train_test.py (deflated 60%)\n",
            "  adding: content/models/official/vision/beta/projects/assemblenet/modeling/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/assemblenet/modeling/rep_flow_2d_layer.py (deflated 75%)\n",
            "  adding: content/models/official/vision/beta/projects/assemblenet/modeling/assemblenet.py (deflated 77%)\n",
            "  adding: content/models/official/vision/beta/projects/assemblenet/configs/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/projects/assemblenet/configs/assemblenet.py (deflated 63%)\n",
            "  adding: content/models/official/vision/beta/MODEL_GARDEN.md (deflated 79%)\n",
            "  adding: content/models/official/vision/beta/README.md (deflated 8%)\n",
            "  adding: content/models/official/vision/beta/tasks/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/tasks/maskrcnn.py (deflated 73%)\n",
            "  adding: content/models/official/vision/beta/tasks/__init__.py (deflated 48%)\n",
            "  adding: content/models/official/vision/beta/tasks/retinanet.py (deflated 72%)\n",
            "  adding: content/models/official/vision/beta/tasks/image_classification.py (deflated 72%)\n",
            "  adding: content/models/official/vision/beta/tasks/video_classification.py (deflated 72%)\n",
            "  adding: content/models/official/vision/beta/tasks/semantic_segmentation.py (deflated 70%)\n",
            "  adding: content/models/official/vision/beta/train.py (deflated 56%)\n",
            "  adding: content/models/official/vision/beta/__init__.py (deflated 39%)\n",
            "  adding: content/models/official/vision/beta/train_spatial_partitioning.py (deflated 66%)\n",
            "  adding: content/models/official/vision/beta/losses/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/losses/focal_loss.py (deflated 55%)\n",
            "  adding: content/models/official/vision/beta/losses/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/losses/segmentation_losses.py (deflated 62%)\n",
            "  adding: content/models/official/vision/beta/losses/loss_utils.py (deflated 52%)\n",
            "  adding: content/models/official/vision/beta/losses/retinanet_losses.py (deflated 69%)\n",
            "  adding: content/models/official/vision/beta/losses/maskrcnn_losses.py (deflated 76%)\n",
            "  adding: content/models/official/vision/beta/evaluation/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/evaluation/wod_detection_evaluator.py (deflated 69%)\n",
            "  adding: content/models/official/vision/beta/evaluation/panoptic_quality_test.py (deflated 86%)\n",
            "  adding: content/models/official/vision/beta/evaluation/iou.py (deflated 61%)\n",
            "  adding: content/models/official/vision/beta/evaluation/coco_utils.py (deflated 73%)\n",
            "  adding: content/models/official/vision/beta/evaluation/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/evaluation/iou_test.py (deflated 73%)\n",
            "  adding: content/models/official/vision/beta/evaluation/panoptic_quality_evaluator.py (deflated 67%)\n",
            "  adding: content/models/official/vision/beta/evaluation/panoptic_quality.py (deflated 70%)\n",
            "  adding: content/models/official/vision/beta/evaluation/segmentation_metrics_test.py (deflated 63%)\n",
            "  adding: content/models/official/vision/beta/evaluation/coco_evaluator.py (deflated 74%)\n",
            "  adding: content/models/official/vision/beta/evaluation/panoptic_quality_evaluator_test.py (deflated 68%)\n",
            "  adding: content/models/official/vision/beta/evaluation/coco_utils_test.py (deflated 51%)\n",
            "  adding: content/models/official/vision/beta/evaluation/segmentation_metrics.py (deflated 81%)\n",
            "  adding: content/models/official/vision/beta/dataloaders/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/dataloaders/classification_input.py (deflated 73%)\n",
            "  adding: content/models/official/vision/beta/dataloaders/tfexample_utils.py (deflated 75%)\n",
            "  adding: content/models/official/vision/beta/dataloaders/tf_example_decoder.py (deflated 72%)\n",
            "  adding: content/models/official/vision/beta/dataloaders/parser.py (deflated 60%)\n",
            "  adding: content/models/official/vision/beta/dataloaders/retinanet_input.py (deflated 75%)\n",
            "  adding: content/models/official/vision/beta/dataloaders/decoder.py (deflated 44%)\n",
            "  adding: content/models/official/vision/beta/dataloaders/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/dataloaders/tf_example_decoder_test.py (deflated 85%)\n",
            "  adding: content/models/official/vision/beta/dataloaders/segmentation_input.py (deflated 71%)\n",
            "  adding: content/models/official/vision/beta/dataloaders/tf_example_label_map_decoder.py (deflated 56%)\n",
            "  adding: content/models/official/vision/beta/dataloaders/tfds_classification_decoders.py (deflated 48%)\n",
            "  adding: content/models/official/vision/beta/dataloaders/maskrcnn_input.py (deflated 74%)\n",
            "  adding: content/models/official/vision/beta/dataloaders/tfds_factory_test.py (deflated 72%)\n",
            "  adding: content/models/official/vision/beta/dataloaders/utils_test.py (deflated 59%)\n",
            "  adding: content/models/official/vision/beta/dataloaders/input_reader.py (deflated 71%)\n",
            "  adding: content/models/official/vision/beta/dataloaders/tfds_factory.py (deflated 70%)\n",
            "  adding: content/models/official/vision/beta/dataloaders/utils.py (deflated 58%)\n",
            "  adding: content/models/official/vision/beta/dataloaders/tf_example_label_map_decoder_test.py (deflated 78%)\n",
            "  adding: content/models/official/vision/beta/dataloaders/video_input.py (deflated 73%)\n",
            "  adding: content/models/official/vision/beta/dataloaders/tfds_segmentation_decoders.py (deflated 58%)\n",
            "  adding: content/models/official/vision/beta/dataloaders/input_reader_factory.py (deflated 53%)\n",
            "  adding: content/models/official/vision/beta/dataloaders/video_input_test.py (deflated 75%)\n",
            "  adding: content/models/official/vision/beta/dataloaders/tfds_detection_decoders.py (deflated 59%)\n",
            "  adding: content/models/official/vision/beta/modeling/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/modeling/factory_test.py (deflated 75%)\n",
            "  adding: content/models/official/vision/beta/modeling/heads/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/modeling/heads/segmentation_heads.py (deflated 72%)\n",
            "  adding: content/models/official/vision/beta/modeling/heads/instance_heads.py (deflated 82%)\n",
            "  adding: content/models/official/vision/beta/modeling/heads/__init__.py (deflated 52%)\n",
            "  adding: content/models/official/vision/beta/modeling/heads/dense_prediction_heads.py (deflated 82%)\n",
            "  adding: content/models/official/vision/beta/modeling/heads/instance_heads_test.py (deflated 72%)\n",
            "  adding: content/models/official/vision/beta/modeling/heads/dense_prediction_heads_test.py (deflated 74%)\n",
            "  adding: content/models/official/vision/beta/modeling/heads/segmentation_heads_test.py (deflated 61%)\n",
            "  adding: content/models/official/vision/beta/modeling/segmentation_model.py (deflated 56%)\n",
            "  adding: content/models/official/vision/beta/modeling/classification_model.py (deflated 64%)\n",
            "  adding: content/models/official/vision/beta/modeling/classification_model_test.py (deflated 73%)\n",
            "  adding: content/models/official/vision/beta/modeling/__init__.py (deflated 46%)\n",
            "  adding: content/models/official/vision/beta/modeling/factory_3d.py (deflated 64%)\n",
            "  adding: content/models/official/vision/beta/modeling/video_classification_model.py (deflated 65%)\n",
            "  adding: content/models/official/vision/beta/modeling/factory.py (deflated 83%)\n",
            "  adding: content/models/official/vision/beta/modeling/retinanet_model.py (deflated 70%)\n",
            "  adding: content/models/official/vision/beta/modeling/retinanet_model_test.py (deflated 78%)\n",
            "  adding: content/models/official/vision/beta/modeling/segmentation_model_test.py (deflated 61%)\n",
            "  adding: content/models/official/vision/beta/modeling/decoders/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/modeling/decoders/factory_test.py (deflated 76%)\n",
            "  adding: content/models/official/vision/beta/modeling/decoders/__init__.py (deflated 44%)\n",
            "  adding: content/models/official/vision/beta/modeling/decoders/nasfpn.py (deflated 70%)\n",
            "  adding: content/models/official/vision/beta/modeling/decoders/factory.py (deflated 62%)\n",
            "  adding: content/models/official/vision/beta/modeling/decoders/aspp_test.py (deflated 56%)\n",
            "  adding: content/models/official/vision/beta/modeling/decoders/fpn_test.py (deflated 65%)\n",
            "  adding: content/models/official/vision/beta/modeling/decoders/aspp.py (deflated 68%)\n",
            "  adding: content/models/official/vision/beta/modeling/decoders/fpn.py (deflated 69%)\n",
            "  adding: content/models/official/vision/beta/modeling/decoders/nasfpn_test.py (deflated 50%)\n",
            "  adding: content/models/official/vision/beta/modeling/backbones/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/modeling/backbones/factory_test.py (deflated 81%)\n",
            "  adding: content/models/official/vision/beta/modeling/backbones/mobilenet.py (deflated 80%)\n",
            "  adding: content/models/official/vision/beta/modeling/backbones/mobilenet_test.py (deflated 75%)\n",
            "  adding: content/models/official/vision/beta/modeling/backbones/revnet_test.py (deflated 60%)\n",
            "  adding: content/models/official/vision/beta/modeling/backbones/resnet_3d_test.py (deflated 63%)\n",
            "  adding: content/models/official/vision/beta/modeling/backbones/spinenet_mobile_test.py (deflated 64%)\n",
            "  adding: content/models/official/vision/beta/modeling/backbones/spinenet_mobile.py (deflated 74%)\n",
            "  adding: content/models/official/vision/beta/modeling/backbones/spinenet_test.py (deflated 61%)\n",
            "  adding: content/models/official/vision/beta/modeling/backbones/mobiledet_test.py (deflated 62%)\n",
            "  adding: content/models/official/vision/beta/modeling/backbones/__init__.py (deflated 59%)\n",
            "  adding: content/models/official/vision/beta/modeling/backbones/resnet_deeplab_test.py (deflated 67%)\n",
            "  adding: content/models/official/vision/beta/modeling/backbones/spinenet.py (deflated 75%)\n",
            "  adding: content/models/official/vision/beta/modeling/backbones/factory.py (deflated 59%)\n",
            "  adding: content/models/official/vision/beta/modeling/backbones/resnet_test.py (deflated 67%)\n",
            "  adding: content/models/official/vision/beta/modeling/backbones/revnet.py (deflated 65%)\n",
            "  adding: content/models/official/vision/beta/modeling/backbones/resnet_deeplab.py (deflated 73%)\n",
            "  adding: content/models/official/vision/beta/modeling/backbones/resnet_3d.py (deflated 78%)\n",
            "  adding: content/models/official/vision/beta/modeling/backbones/mobiledet.py (deflated 81%)\n",
            "  adding: content/models/official/vision/beta/modeling/backbones/efficientnet_test.py (deflated 63%)\n",
            "  adding: content/models/official/vision/beta/modeling/backbones/resnet.py (deflated 75%)\n",
            "  adding: content/models/official/vision/beta/modeling/backbones/efficientnet.py (deflated 70%)\n",
            "  adding: content/models/official/vision/beta/modeling/layers/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/modeling/layers/nn_blocks_test.py (deflated 81%)\n",
            "  adding: content/models/official/vision/beta/modeling/layers/nn_blocks.py (deflated 86%)\n",
            "  adding: content/models/official/vision/beta/modeling/layers/nn_blocks_3d_test.py (deflated 56%)\n",
            "  adding: content/models/official/vision/beta/modeling/layers/detection_generator_test.py (deflated 78%)\n",
            "  adding: content/models/official/vision/beta/modeling/layers/deeplab_test.py (deflated 55%)\n",
            "  adding: content/models/official/vision/beta/modeling/layers/__init__.py (deflated 73%)\n",
            "  adding: content/models/official/vision/beta/modeling/layers/detection_generator.py (deflated 83%)\n",
            "  adding: content/models/official/vision/beta/modeling/layers/deeplab.py (deflated 73%)\n",
            "  adding: content/models/official/vision/beta/modeling/layers/box_sampler.py (deflated 61%)\n",
            "  adding: content/models/official/vision/beta/modeling/layers/roi_sampler.py (deflated 70%)\n",
            "  adding: content/models/official/vision/beta/modeling/layers/roi_aligner_test.py (deflated 47%)\n",
            "  adding: content/models/official/vision/beta/modeling/layers/nn_layers.py (deflated 78%)\n",
            "  adding: content/models/official/vision/beta/modeling/layers/nn_layers_test.py (deflated 81%)\n",
            "  adding: content/models/official/vision/beta/modeling/layers/nn_blocks_3d.py (deflated 74%)\n",
            "  adding: content/models/official/vision/beta/modeling/layers/mask_sampler.py (deflated 76%)\n",
            "  adding: content/models/official/vision/beta/modeling/layers/roi_aligner.py (deflated 53%)\n",
            "  adding: content/models/official/vision/beta/modeling/layers/roi_generator.py (deflated 77%)\n",
            "  adding: content/models/official/vision/beta/modeling/video_classification_model_test.py (deflated 62%)\n",
            "  adding: content/models/official/vision/beta/modeling/maskrcnn_model.py (deflated 74%)\n",
            "  adding: content/models/official/vision/beta/modeling/maskrcnn_model_test.py (deflated 80%)\n",
            "  adding: content/models/official/vision/beta/data/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/data/create_coco_tf_record.py (deflated 76%)\n",
            "  adding: content/models/official/vision/beta/data/process_coco_few_shot.sh (deflated 72%)\n",
            "  adding: content/models/official/vision/beta/data/tfrecord_lib.py (deflated 65%)\n",
            "  adding: content/models/official/vision/beta/data/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/data/process_coco_panoptic.sh (deflated 73%)\n",
            "  adding: content/models/official/vision/beta/data/process_coco_few_shot_json_files.py (deflated 58%)\n",
            "  adding: content/models/official/vision/beta/data/tfrecord_lib_test.py (deflated 61%)\n",
            "  adding: content/models/official/vision/beta/serving/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/serving/video_classification_test.py (deflated 61%)\n",
            "  adding: content/models/official/vision/beta/serving/export_tflite_lib.py (deflated 63%)\n",
            "  adding: content/models/official/vision/beta/serving/semantic_segmentation_test.py (deflated 60%)\n",
            "  adding: content/models/official/vision/beta/serving/export_saved_model.py (deflated 60%)\n",
            "  adding: content/models/official/vision/beta/serving/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/serving/image_classification_test.py (deflated 61%)\n",
            "  adding: content/models/official/vision/beta/serving/image_classification.py (deflated 56%)\n",
            "  adding: content/models/official/vision/beta/serving/export_saved_model_lib_v2.py (deflated 63%)\n",
            "  adding: content/models/official/vision/beta/serving/detection_test.py (deflated 65%)\n",
            "  adding: content/models/official/vision/beta/serving/export_tflite_lib_test.py (deflated 73%)\n",
            "  adding: content/models/official/vision/beta/serving/video_classification.py (deflated 69%)\n",
            "  adding: content/models/official/vision/beta/serving/export_saved_model_lib.py (deflated 69%)\n",
            "  adding: content/models/official/vision/beta/serving/detection.py (deflated 68%)\n",
            "  adding: content/models/official/vision/beta/serving/export_module_factory.py (deflated 66%)\n",
            "  adding: content/models/official/vision/beta/serving/export_module_factory_test.py (deflated 61%)\n",
            "  adding: content/models/official/vision/beta/serving/export_base.py (deflated 70%)\n",
            "  adding: content/models/official/vision/beta/serving/semantic_segmentation.py (deflated 55%)\n",
            "  adding: content/models/official/vision/beta/serving/export_base_v2_test.py (deflated 64%)\n",
            "  adding: content/models/official/vision/beta/serving/export_utils.py (deflated 68%)\n",
            "  adding: content/models/official/vision/beta/serving/export_tflite.py (deflated 59%)\n",
            "  adding: content/models/official/vision/beta/serving/export_saved_model_lib_test.py (deflated 51%)\n",
            "  adding: content/models/official/vision/beta/serving/export_base_v2.py (deflated 59%)\n",
            "  adding: content/models/official/vision/beta/serving/export_tfhub.py (deflated 59%)\n",
            "  adding: content/models/official/vision/beta/ops/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/ops/preprocess_ops_3d.py (deflated 71%)\n",
            "  adding: content/models/official/vision/beta/ops/iou_similarity.py (deflated 69%)\n",
            "  adding: content/models/official/vision/beta/ops/mask_ops.py (deflated 68%)\n",
            "  adding: content/models/official/vision/beta/ops/augment_test.py (deflated 77%)\n",
            "  adding: content/models/official/vision/beta/ops/anchor_generator.py (deflated 70%)\n",
            "  adding: content/models/official/vision/beta/ops/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/beta/ops/mask_ops_test.py (deflated 56%)\n",
            "  adding: content/models/official/vision/beta/ops/anchor_generator_test.py (deflated 77%)\n",
            "  adding: content/models/official/vision/beta/ops/preprocess_ops.py (deflated 79%)\n",
            "  adding: content/models/official/vision/beta/ops/augment.py (deflated 76%)\n",
            "  adding: content/models/official/vision/beta/ops/target_gather_test.py (deflated 67%)\n",
            "  adding: content/models/official/vision/beta/ops/nms.py (deflated 68%)\n",
            "  adding: content/models/official/vision/beta/ops/box_matcher.py (deflated 69%)\n",
            "  adding: content/models/official/vision/beta/ops/sampling_ops.py (deflated 72%)\n",
            "  adding: content/models/official/vision/beta/ops/iou_similarity_test.py (deflated 62%)\n",
            "  adding: content/models/official/vision/beta/ops/anchor.py (deflated 75%)\n",
            "  adding: content/models/official/vision/beta/ops/box_matcher_test.py (deflated 66%)\n",
            "  adding: content/models/official/vision/beta/ops/spatial_transform_ops.py (deflated 76%)\n",
            "  adding: content/models/official/vision/beta/ops/target_gather.py (deflated 67%)\n",
            "  adding: content/models/official/vision/beta/ops/anchor_test.py (deflated 72%)\n",
            "  adding: content/models/official/vision/beta/ops/preprocess_ops_3d_test.py (deflated 72%)\n",
            "  adding: content/models/official/vision/beta/ops/box_ops.py (deflated 80%)\n",
            "  adding: content/models/official/vision/beta/ops/preprocess_ops_test.py (deflated 78%)\n",
            "  adding: content/models/official/vision/beta/configs/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/configs/video_classification_test.py (deflated 54%)\n",
            "  adding: content/models/official/vision/beta/configs/maskrcnn.py (deflated 81%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/video_classification/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/video_classification/k400_slowonly8x8_tpu.yaml (deflated 69%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/video_classification/k600_3d-resnet50g_tpu.yaml (deflated 68%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/video_classification/k600_slowonly8x8_tpu.yaml (deflated 69%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/video_classification/k600_3d-resnet50_tpu.yaml (deflated 69%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/video_classification/k400_slowonly16x4_tpu.yaml (deflated 69%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/video_classification/k400_resnet3drs_50_tpu.yaml (deflated 63%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/video_classification/k400_3d-resnet50_tpu.yaml (deflated 69%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/maskrcnn/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/maskrcnn/coco_spinenet96_casrcnn_tpu.yaml (deflated 53%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/maskrcnn/coco_spinenet143_mrcnn_tpu.yaml (deflated 49%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/maskrcnn/r50fpn_640_coco_scratch_tpu4x4.yaml (deflated 47%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/maskrcnn/coco_spinenet49_cascadercnn_tpu.yaml (deflated 52%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/maskrcnn/coco_spinenet143_cascadercnn_tpu.yaml (deflated 51%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/maskrcnn/coco_spinenet96_mrcnn_tpu.yaml (deflated 49%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/maskrcnn/coco_spinenet49_mrcnn_tpu.yaml (deflated 49%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/retinanet/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/retinanet/coco_mobiledetcpu_tpu.yaml (deflated 55%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/retinanet/coco_spinenet49xs_mobile_tpu.yaml (deflated 55%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/retinanet/coco_spinenet96_tpu.yaml (deflated 53%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/retinanet/resnet50fpn_coco_tfds_tpu.yaml (deflated 54%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/retinanet/coco_spinenet49_mobile_tpu.yaml (deflated 55%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/retinanet/coco_mobilenetv2_tpu.yaml (deflated 55%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/retinanet/resnet50fpn_coco_tpu4x4_benchmark.yaml (deflated 31%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/retinanet/coco_spinenet143_tpu.yaml (deflated 53%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/retinanet/coco_spinenet49s_mobile_tpu.yaml (deflated 55%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/retinanet/coco_spinenet190_tpu.yaml (deflated 55%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/retinanet/coco_spinenet49_tpu.yaml (deflated 53%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/image_classification/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/image_classification/imagenet_resnetrs101_i192.yaml (deflated 57%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/image_classification/imagenet_resnetrs350_i320.yaml (deflated 57%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/image_classification/imagenet_resnetrs200_i256.yaml (deflated 57%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/image_classification/imagenet_resnet101_tpu.yaml (deflated 56%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/image_classification/imagenet_resnetrs420_i320.yaml (deflated 59%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/image_classification/imagenet_resnetrs101_i160.yaml (deflated 57%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/image_classification/imagenet_mobilenetv2_gpu.yaml (deflated 55%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/image_classification/imagenet_resnet101_deeplab_tpu.yaml (deflated 56%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/image_classification/imagenet_resnetrs50_i160.yaml (deflated 57%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/image_classification/imagenet_resnet50_deeplab_tpu.yaml (deflated 58%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/image_classification/imagenet_resnetrs152_i192.yaml (deflated 57%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/image_classification/imagenet_resnet50_tpu.yaml (deflated 56%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/image_classification/imagenet_resnet152_tpu.yaml (deflated 56%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/image_classification/imagenet_resnet50_tfds_tpu.yaml (deflated 58%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/image_classification/imagenet_resnetrs152_i256.yaml (deflated 57%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/image_classification/imagenet_resnetrs152_i224.yaml (deflated 57%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/image_classification/imagenet_resnet50_gpu.yaml (deflated 56%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/image_classification/imagenet_mobilenetv2_tpu.yaml (deflated 54%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/image_classification/imagenet_resnetrs350_i256.yaml (deflated 57%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/image_classification/imagenet_resnetrs270_i256.yaml (deflated 57%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/semantic_segmentation/ (stored 0%)\n",
            "  adding: content/models/official/vision/beta/configs/experiments/semantic_segmentation/deeplabv3plus_resnet101_cityscapes_tfds_tpu.yaml (deflated 58%)\n",
            "  adding: content/models/official/vision/beta/configs/semantic_segmentation_test.py (deflated 54%)\n",
            "  adding: content/models/official/vision/beta/configs/__init__.py (deflated 48%)\n",
            "  adding: content/models/official/vision/beta/configs/image_classification_test.py (deflated 55%)\n",
            "  adding: content/models/official/vision/beta/configs/retinanet.py (deflated 80%)\n",
            "  adding: content/models/official/vision/beta/configs/image_classification.py (deflated 82%)\n",
            "  adding: content/models/official/vision/beta/configs/maskrcnn_test.py (deflated 53%)\n",
            "  adding: content/models/official/vision/beta/configs/video_classification.py (deflated 81%)\n",
            "  adding: content/models/official/vision/beta/configs/common.py (deflated 64%)\n",
            "  adding: content/models/official/vision/beta/configs/retinanet_test.py (deflated 53%)\n",
            "  adding: content/models/official/vision/beta/configs/semantic_segmentation.py (deflated 86%)\n",
            "  adding: content/models/official/vision/beta/configs/backbones_3d.py (deflated 73%)\n",
            "  adding: content/models/official/vision/beta/configs/backbones.py (deflated 66%)\n",
            "  adding: content/models/official/vision/beta/configs/decoders.py (deflated 54%)\n",
            "  adding: content/models/official/vision/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/detection/ (stored 0%)\n",
            "  adding: content/models/official/vision/detection/utils/ (stored 0%)\n",
            "  adding: content/models/official/vision/detection/utils/input_utils.py (deflated 77%)\n",
            "  adding: content/models/official/vision/detection/utils/box_utils.py (deflated 80%)\n",
            "  adding: content/models/official/vision/detection/utils/mask_utils.py (deflated 67%)\n",
            "  adding: content/models/official/vision/detection/utils/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/detection/utils/dataloader_utils.py (deflated 51%)\n",
            "  adding: content/models/official/vision/detection/utils/class_utils.py (deflated 45%)\n",
            "  adding: content/models/official/vision/detection/README.md (deflated 83%)\n",
            "  adding: content/models/official/vision/detection/main.py (deflated 71%)\n",
            "  adding: content/models/official/vision/detection/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/detection/dataloader/ (stored 0%)\n",
            "  adding: content/models/official/vision/detection/dataloader/tf_example_decoder.py (deflated 72%)\n",
            "  adding: content/models/official/vision/detection/dataloader/retinanet_parser.py (deflated 77%)\n",
            "  adding: content/models/official/vision/detection/dataloader/olnmask_parser.py (deflated 72%)\n",
            "  adding: content/models/official/vision/detection/dataloader/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/detection/dataloader/factory.py (deflated 81%)\n",
            "  adding: content/models/official/vision/detection/dataloader/mode_keys.py (deflated 44%)\n",
            "  adding: content/models/official/vision/detection/dataloader/maskrcnn_parser.py (deflated 74%)\n",
            "  adding: content/models/official/vision/detection/dataloader/input_reader.py (deflated 62%)\n",
            "  adding: content/models/official/vision/detection/dataloader/anchor.py (deflated 78%)\n",
            "  adding: content/models/official/vision/detection/dataloader/shapemask_parser.py (deflated 75%)\n",
            "  adding: content/models/official/vision/detection/evaluation/ (stored 0%)\n",
            "  adding: content/models/official/vision/detection/evaluation/coco_utils.py (deflated 72%)\n",
            "  adding: content/models/official/vision/detection/evaluation/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/detection/evaluation/factory.py (deflated 65%)\n",
            "  adding: content/models/official/vision/detection/evaluation/coco_evaluator.py (deflated 82%)\n",
            "  adding: content/models/official/vision/detection/modeling/ (stored 0%)\n",
            "  adding: content/models/official/vision/detection/modeling/shapemask_model.py (deflated 76%)\n",
            "  adding: content/models/official/vision/detection/modeling/learning_rates.py (deflated 70%)\n",
            "  adding: content/models/official/vision/detection/modeling/base_model.py (deflated 65%)\n",
            "  adding: content/models/official/vision/detection/modeling/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/detection/modeling/factory.py (deflated 55%)\n",
            "  adding: content/models/official/vision/detection/modeling/losses.py (deflated 80%)\n",
            "  adding: content/models/official/vision/detection/modeling/architecture/ (stored 0%)\n",
            "  adding: content/models/official/vision/detection/modeling/architecture/nn_blocks.py (deflated 83%)\n",
            "  adding: content/models/official/vision/detection/modeling/architecture/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/detection/modeling/architecture/spinenet.py (deflated 77%)\n",
            "  adding: content/models/official/vision/detection/modeling/architecture/nn_ops.py (deflated 61%)\n",
            "  adding: content/models/official/vision/detection/modeling/architecture/factory.py (deflated 82%)\n",
            "  adding: content/models/official/vision/detection/modeling/architecture/identity.py (deflated 46%)\n",
            "  adding: content/models/official/vision/detection/modeling/architecture/fpn.py (deflated 67%)\n",
            "  adding: content/models/official/vision/detection/modeling/architecture/resnet.py (deflated 74%)\n",
            "  adding: content/models/official/vision/detection/modeling/architecture/heads.py (deflated 86%)\n",
            "  adding: content/models/official/vision/detection/modeling/retinanet_model.py (deflated 68%)\n",
            "  adding: content/models/official/vision/detection/modeling/olnmask_model.py (deflated 78%)\n",
            "  adding: content/models/official/vision/detection/modeling/optimizers.py (deflated 56%)\n",
            "  adding: content/models/official/vision/detection/modeling/maskrcnn_model.py (deflated 76%)\n",
            "  adding: content/models/official/vision/detection/modeling/checkpoint_utils.py (deflated 63%)\n",
            "  adding: content/models/official/vision/detection/executor/ (stored 0%)\n",
            "  adding: content/models/official/vision/detection/executor/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/detection/executor/distributed_executor.py (deflated 75%)\n",
            "  adding: content/models/official/vision/detection/executor/detection_executor.py (deflated 66%)\n",
            "  adding: content/models/official/vision/detection/ops/ (stored 0%)\n",
            "  adding: content/models/official/vision/detection/ops/target_ops.py (deflated 84%)\n",
            "  adding: content/models/official/vision/detection/ops/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/detection/ops/roi_ops.py (deflated 84%)\n",
            "  adding: content/models/official/vision/detection/ops/nms.py (deflated 68%)\n",
            "  adding: content/models/official/vision/detection/ops/spatial_transform_ops.py (deflated 77%)\n",
            "  adding: content/models/official/vision/detection/ops/postprocess_ops.py (deflated 81%)\n",
            "  adding: content/models/official/vision/detection/configs/ (stored 0%)\n",
            "  adding: content/models/official/vision/detection/configs/retinanet_config.py (deflated 51%)\n",
            "  adding: content/models/official/vision/detection/configs/olnmask_config.py (deflated 66%)\n",
            "  adding: content/models/official/vision/detection/configs/base_config.py (deflated 57%)\n",
            "  adding: content/models/official/vision/detection/configs/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/detection/configs/shapemask_config.py (deflated 59%)\n",
            "  adding: content/models/official/vision/detection/configs/factory.py (deflated 58%)\n",
            "  adding: content/models/official/vision/detection/configs/maskrcnn_config.py (deflated 64%)\n",
            "  adding: content/models/official/vision/image_classification/ (stored 0%)\n",
            "  adding: content/models/official/vision/image_classification/mnist_main.py (deflated 62%)\n",
            "  adding: content/models/official/vision/image_classification/callbacks.py (deflated 69%)\n",
            "  adding: content/models/official/vision/image_classification/efficientnet/ (stored 0%)\n",
            "  adding: content/models/official/vision/image_classification/efficientnet/common_modules.py (deflated 62%)\n",
            "  adding: content/models/official/vision/image_classification/efficientnet/efficientnet_model.py (deflated 69%)\n",
            "  adding: content/models/official/vision/image_classification/efficientnet/efficientnet_config.py (deflated 57%)\n",
            "  adding: content/models/official/vision/image_classification/efficientnet/tfhub_export.py (deflated 54%)\n",
            "  adding: content/models/official/vision/image_classification/efficientnet/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/image_classification/README.md (deflated 64%)\n",
            "  adding: content/models/official/vision/image_classification/classifier_trainer_util_test.py (deflated 66%)\n",
            "  adding: content/models/official/vision/image_classification/augment_test.py (deflated 66%)\n",
            "  adding: content/models/official/vision/image_classification/learning_rate.py (deflated 67%)\n",
            "  adding: content/models/official/vision/image_classification/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/image_classification/mnist_test.py (deflated 56%)\n",
            "  adding: content/models/official/vision/image_classification/augment.py (deflated 73%)\n",
            "  adding: content/models/official/vision/image_classification/classifier_trainer_test.py (deflated 74%)\n",
            "  adding: content/models/official/vision/image_classification/learning_rate_test.py (deflated 53%)\n",
            "  adding: content/models/official/vision/image_classification/classifier_trainer.py (deflated 71%)\n",
            "  adding: content/models/official/vision/image_classification/preprocessing.py (deflated 75%)\n",
            "  adding: content/models/official/vision/image_classification/dataset_factory.py (deflated 72%)\n",
            "  adding: content/models/official/vision/image_classification/test_utils.py (deflated 47%)\n",
            "  adding: content/models/official/vision/image_classification/optimizer_factory_test.py (deflated 65%)\n",
            "  adding: content/models/official/vision/image_classification/optimizer_factory.py (deflated 69%)\n",
            "  adding: content/models/official/vision/image_classification/configs/ (stored 0%)\n",
            "  adding: content/models/official/vision/image_classification/configs/examples/ (stored 0%)\n",
            "  adding: content/models/official/vision/image_classification/configs/examples/efficientnet/ (stored 0%)\n",
            "  adding: content/models/official/vision/image_classification/configs/examples/efficientnet/imagenet/ (stored 0%)\n",
            "  adding: content/models/official/vision/image_classification/configs/examples/efficientnet/imagenet/efficientnet-b1-gpu.yaml (deflated 55%)\n",
            "  adding: content/models/official/vision/image_classification/configs/examples/efficientnet/imagenet/efficientnet-b1-tpu.yaml (deflated 55%)\n",
            "  adding: content/models/official/vision/image_classification/configs/examples/efficientnet/imagenet/efficientnet-b0-gpu.yaml (deflated 54%)\n",
            "  adding: content/models/official/vision/image_classification/configs/examples/efficientnet/imagenet/efficientnet-b0-tpu.yaml (deflated 54%)\n",
            "  adding: content/models/official/vision/image_classification/configs/examples/resnet/ (stored 0%)\n",
            "  adding: content/models/official/vision/image_classification/configs/examples/resnet/imagenet/ (stored 0%)\n",
            "  adding: content/models/official/vision/image_classification/configs/examples/resnet/imagenet/gpu.yaml (deflated 55%)\n",
            "  adding: content/models/official/vision/image_classification/configs/examples/resnet/imagenet/tpu.yaml (deflated 56%)\n",
            "  adding: content/models/official/vision/image_classification/configs/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/image_classification/configs/configs.py (deflated 72%)\n",
            "  adding: content/models/official/vision/image_classification/configs/base_configs.py (deflated 72%)\n",
            "  adding: content/models/official/vision/image_classification/resnet/ (stored 0%)\n",
            "  adding: content/models/official/vision/image_classification/resnet/resnet_config.py (deflated 52%)\n",
            "  adding: content/models/official/vision/image_classification/resnet/resnet_model.py (deflated 78%)\n",
            "  adding: content/models/official/vision/image_classification/resnet/resnet_ctl_imagenet_main.py (deflated 66%)\n",
            "  adding: content/models/official/vision/image_classification/resnet/README.md (deflated 57%)\n",
            "  adding: content/models/official/vision/image_classification/resnet/tfhub_export.py (deflated 53%)\n",
            "  adding: content/models/official/vision/image_classification/resnet/__init__.py (deflated 37%)\n",
            "  adding: content/models/official/vision/image_classification/resnet/imagenet_preprocessing.py (deflated 69%)\n",
            "  adding: content/models/official/vision/image_classification/resnet/common.py (deflated 68%)\n",
            "  adding: content/models/official/vision/image_classification/resnet/resnet_runnable.py (deflated 69%)\n",
            "  adding: content/models/.github/ (stored 0%)\n",
            "  adding: content/models/.github/PULL_REQUEST_TEMPLATE.md (deflated 55%)\n",
            "  adding: content/models/.github/ISSUE_TEMPLATE/ (stored 0%)\n",
            "  adding: content/models/.github/ISSUE_TEMPLATE/10-official-documentation-issue.md (deflated 37%)\n",
            "  adding: content/models/.github/ISSUE_TEMPLATE/00-official-bug-report-issue.md (deflated 50%)\n",
            "  adding: content/models/.github/ISSUE_TEMPLATE/20-official-feature-request-issue.md (deflated 40%)\n",
            "  adding: content/models/.github/ISSUE_TEMPLATE/50-research-feature-request-issue.md (deflated 40%)\n",
            "  adding: content/models/.github/ISSUE_TEMPLATE/config.yml (stored 0%)\n",
            "  adding: content/models/.github/ISSUE_TEMPLATE/30-research-bug-report-issue.md (deflated 50%)\n",
            "  adding: content/models/.github/ISSUE_TEMPLATE/60-questions-help-issue.md (deflated 38%)\n",
            "  adding: content/models/.github/ISSUE_TEMPLATE/40-research-documentation-issue.md (deflated 38%)\n",
            "  adding: content/models/.github/scripts/ (stored 0%)\n",
            "  adding: content/models/.github/scripts/pylint.sh (deflated 57%)\n",
            "  adding: content/models/.github/workflows/ (stored 0%)\n",
            "  adding: content/models/.github/workflows/ci.yml (deflated 54%)\n",
            "  adding: content/models/.github/README_TEMPLATE.md (deflated 60%)\n",
            "  adding: content/models/.github/bot_config.yml (deflated 43%)\n",
            "  adding: content/models/.github/stale.yml (deflated 51%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhuIBdJ0lasW"
      },
      "source": [
        "tensorflow folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2DSnSyYlfRk",
        "outputId": "eb81132a-c0fc-40e3-dec4-99b11ff2758a"
      },
      "source": [
        "!zip -r /content/tensorflow.zip /content/tensorflow-object-detection-faster-rcnn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: content/tensorflow-object-detection-faster-rcnn/ (stored 0%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/xml_to_csv.py (deflated 63%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/README.md (deflated 62%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/ (stored 0%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/index (deflated 40%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/logs/ (stored 0%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/logs/HEAD (deflated 29%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/logs/refs/ (stored 0%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/logs/refs/remotes/ (stored 0%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/logs/refs/remotes/origin/ (stored 0%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/logs/refs/remotes/origin/HEAD (deflated 29%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/logs/refs/heads/ (stored 0%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/logs/refs/heads/master (deflated 29%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/branches/ (stored 0%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/info/ (stored 0%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/info/exclude (deflated 28%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/hooks/ (stored 0%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/hooks/applypatch-msg.sample (deflated 42%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/hooks/prepare-commit-msg.sample (deflated 50%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/hooks/pre-push.sample (deflated 50%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/hooks/post-update.sample (deflated 27%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/hooks/pre-rebase.sample (deflated 59%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/hooks/commit-msg.sample (deflated 44%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/hooks/pre-commit.sample (deflated 43%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/hooks/pre-receive.sample (deflated 40%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/hooks/fsmonitor-watchman.sample (deflated 53%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/hooks/pre-applypatch.sample (deflated 38%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/hooks/update.sample (deflated 68%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/objects/ (stored 0%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/objects/info/ (stored 0%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/objects/pack/ (stored 0%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/objects/pack/pack-0536e54e7b8e87334ede7af0a03d8db3ce89f478.pack (deflated 0%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/objects/pack/pack-0536e54e7b8e87334ede7af0a03d8db3ce89f478.idx (deflated 2%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/description (deflated 14%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/HEAD (stored 0%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/packed-refs (deflated 19%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/FETCH_HEAD (deflated 13%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/config (deflated 33%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/ORIG_HEAD (deflated 2%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/refs/ (stored 0%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/refs/remotes/ (stored 0%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/refs/remotes/origin/ (stored 0%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/refs/remotes/origin/HEAD (stored 0%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/refs/heads/ (stored 0%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/refs/heads/master (deflated 2%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.git/refs/tags/ (stored 0%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/local_inference_test.ipynb (deflated 25%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/LICENSE (deflated 50%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/generate_tfrecord.py (deflated 67%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/.gitignore (deflated 3%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/deploy/ (stored 0%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/deploy/openvino_convert_tf_object_detection.ipynb (deflated 30%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/deploy/openvino_inference_benchmark.py (deflated 60%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/deploy/.gitignore (deflated 4%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/deploy/deploy_utils.py (deflated 51%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/resize_images.py (deflated 63%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/tensorflow_object_detection_training_colab.ipynb (deflated 31%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/Tutorial_Faster_RCNN.ipynb (deflated 26%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/local_inference_test.py (deflated 67%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/requirements.txt (stored 0%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/data/ (stored 0%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/data/README.roboflow.txt (deflated 41%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/data/valid/ (stored 0%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/data/valid/cysts_label_map.pbtxt (deflated 58%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/data/valid/cysts.tfrecord (deflated 20%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/data/.gitignore (stored 0%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/data/train/ (stored 0%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/data/train/cysts_label_map.pbtxt (deflated 58%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/data/train/cysts.tfrecord (deflated 22%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/data/test/ (stored 0%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/data/test/cysts_label_map.pbtxt (deflated 58%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/data/test/cysts.tfrecord (deflated 21%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/data/FYI.txt (deflated 2%)\n",
            "updating: content/tensorflow-object-detection-faster-rcnn/Tutorial_Mobilenet.ipynb (deflated 35%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p09AOThWkaQv"
      },
      "source": [
        "## Download the model `.pb` file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnDo1lonKgFr"
      },
      "source": [
        "import os\n",
        "\n",
        "pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n",
        "assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHqWkLBINYoI",
        "outputId": "4ac43326-c19f-4b0e-8a73-6b0699a5a52c"
      },
      "source": [
        "!ls -alh {pb_fname}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 19M Mar 15 05:10 /content/models/research/fine_tuned_model/frozen_inference_graph.pb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIqnjbWYsuQw"
      },
      "source": [
        "### Option1 : upload the `.pb` file to your Google Drive\n",
        "Then download it from your Google Drive to local file system.\n",
        "\n",
        "During this step, you will be prompted to enter the token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAqyASIJqjae",
        "outputId": "587ed20f-5024-471f-eb83-30910132f9ea"
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fname = os.path.basename(pb_fname)\n",
        "# Create & upload a text file.\n",
        "uploaded = drive.CreateFile({'title': fname})\n",
        "uploaded.SetContentFile(pb_fname)\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 1NBMXmcH1o7I8myOqskOlFmRmYWwerha\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FKFq8RXs6bs"
      },
      "source": [
        "### Option2 :  Download the `.pb` file directly to your local file system\n",
        "This method may not be stable when downloading large files like the model `.pb` file. Try **option 1** instead if not working."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-bP0iMMnnr77",
        "outputId": "178921a4-be2c-423e-a33c-da46b117f4b2"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(pb_fname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_bceb9ab2-47d3-4185-82b2-1110447f3ce2\", \"frozen_inference_graph.pb\", 19327821)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFyCeiBb9BbS"
      },
      "source": [
        "### OPTIONAL: Download the `label_map.pbtxt` file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "K1TbL6Ox8q6Z",
        "outputId": "37dec2ba-5a7c-42a9-fcde-d582cf8e0775"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(label_map_pbtxt_fname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_4407d073-be9d-4d1b-b308-7c1a1be40e7c\", \"cells_label_map.pbtxt\", 195)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUmAo9foa1xq"
      },
      "source": [
        "### OPTIONAL: Download the modified pipline file\n",
        "If you plan to use OpenVINO toolkit to convert the `.pb` file to inference faster on Intel's hardware (CPU/GPU, Movidius, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "pql2QpemazE1",
        "outputId": "c8d5eee2-7a8b-4831-bd2d-d9ea9f635e99"
      },
      "source": [
        "files.download(pipeline_fname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_ac4ae20d-2c81-465d-83d7-4138c48b1f25\", \"ssd_mobilenet_v2_coco.config\", 4849)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1AgBj1l0v_W"
      },
      "source": [
        "# !tar cfz fine_tuned_model.tar.gz fine_tuned_model\n",
        "# from google.colab import files\n",
        "# files.download('fine_tuned_model.tar.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz1gX19GlVW7"
      },
      "source": [
        "## Run inference test\n",
        "Test with images in repository `tensorflow-object-detection/test` directory.\n",
        "\n",
        "**To test with your own images, you need to place your images inside the `test` directory in this Colab notebook!** More on this below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pzj9A4e5mj5l",
        "outputId": "d705aa02-f1de-4878-8c80-1fb6e9c3fa9d"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = pb_fname\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = label_map_pbtxt_fname\n",
        "\n",
        "# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n",
        "PATH_TO_TEST_IMAGES_DIR =  repo_dir_path + \"/data/test/\"\n",
        "sample_img = 'https://storage.googleapis.com/roboflow-platform-transforms/Ly2DeBzbwsemGd2ReHk4BFxy8683/cf5ed147e4f2675fbabbc9b0db750ecf/transformed.jpg'\n",
        "import urllib.request\n",
        "urllib.request.urlretrieve(sample_img, \n",
        "                           PATH_TO_TEST_IMAGES_DIR + \"cell.jpg\")\n",
        "\n",
        "\n",
        "assert os.path.isfile(pb_fname)\n",
        "assert os.path.isfile(PATH_TO_LABELS)\n",
        "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n",
        "assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n",
        "print(TEST_IMAGE_PATHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['/content/tensorflow-object-detection-faster-rcnn/data/test/cells.tfrecord', '/content/tensorflow-object-detection-faster-rcnn/data/test/cells_label_map.pbtxt', '/content/tensorflow-object-detection-faster-rcnn/data/test/cell.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNFc5CM3Duav",
        "outputId": "a3946178-15db-4daf-ce62-aa1483d2b6ce"
      },
      "source": [
        "%cd /content/models/research/object_detection\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "\n",
        "# This is needed to display the images.\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "from object_detection.utils import visualization_utils as vis_util"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG5YUMdg1Po7"
      },
      "source": [
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map, max_num_classes=num_classes, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "    (im_width, im_height) = image.size\n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "\n",
        "def run_inference_for_single_image(image, graph):\n",
        "    with graph.as_default():\n",
        "        with tf.Session() as sess:\n",
        "            # Get handles to input and output tensors\n",
        "            ops = tf.get_default_graph().get_operations()\n",
        "            all_tensor_names = {\n",
        "                output.name for op in ops for output in op.outputs}\n",
        "            tensor_dict = {}\n",
        "            for key in [\n",
        "                'num_detections', 'detection_boxes', 'detection_scores',\n",
        "                'detection_classes', 'detection_masks'\n",
        "            ]:\n",
        "                tensor_name = key + ':0'\n",
        "                if tensor_name in all_tensor_names:\n",
        "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "                        tensor_name)\n",
        "            if 'detection_masks' in tensor_dict:\n",
        "                # The following processing is only for single image\n",
        "                detection_boxes = tf.squeeze(\n",
        "                    tensor_dict['detection_boxes'], [0])\n",
        "                detection_masks = tf.squeeze(\n",
        "                    tensor_dict['detection_masks'], [0])\n",
        "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "                real_num_detection = tf.cast(\n",
        "                    tensor_dict['num_detections'][0], tf.int32)\n",
        "                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n",
        "                                           real_num_detection, -1])\n",
        "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n",
        "                                           real_num_detection, -1, -1])\n",
        "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "                detection_masks_reframed = tf.cast(\n",
        "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "                # Follow the convention by adding back the batch dimension\n",
        "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "                    detection_masks_reframed, 0)\n",
        "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "            # Run inference\n",
        "            output_dict = sess.run(tensor_dict,\n",
        "                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "            output_dict['num_detections'] = int(\n",
        "                output_dict['num_detections'][0])\n",
        "            output_dict['detection_classes'] = output_dict[\n",
        "                'detection_classes'][0].astype(np.uint8)\n",
        "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "            if 'detection_masks' in output_dict:\n",
        "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "    return output_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IbKIjbY_MRk"
      },
      "source": [
        "# This is needed to display the images.\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "Ah9YKYOX9qrH",
        "outputId": "84636459-91dd-4359-8377-e7908780ca52"
      },
      "source": [
        "for image_path in TEST_IMAGE_PATHS:\n",
        "  try:\n",
        "    image = Image.open(image_path)\n",
        "    print(image_path)\n",
        "    # the array based representation of the image will be used later in order to prepare the\n",
        "    # result image with boxes and labels on it.\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Actual detection.\n",
        "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "    # Visualization of the results of a detection.\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        output_dict['detection_boxes'],\n",
        "        output_dict['detection_classes'],\n",
        "        output_dict['detection_scores'],\n",
        "        category_index,\n",
        "        instance_masks=output_dict.get('detection_masks'),\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=8)\n",
        "    plt.figure(figsize=IMAGE_SIZE)\n",
        "    plt.imshow(image_np)\n",
        "    plt.show()\n",
        "  except Exception:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/tensorflow-object-detection-faster-rcnn/data/test/cell.jpg\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5GLCOS1ZhNh"
      },
      "source": [
        "### Adding your own images to tensorflow-object-detection/data\n",
        "def upload_files():\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()\n",
        "  for k, v in uploaded.items():\n",
        "    open(k, 'wb').write(v)\n",
        "  return list(uploaded.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "3Zhw17IifBH0",
        "outputId": "2b5d256e-f601-40cd-b35d-0100e66fed5f"
      },
      "source": [
        "# navigate to correct folder\n",
        "%cd /content/tensorflow-object-detection-faster-rcnn/data/test/\n",
        "\n",
        "# call function to upload\n",
        "upload_files()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/tensorflow-object-detection-faster-rcnn/data/test\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-72825526-dc82-4335-9f3c-e7fee13c4b10\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-72825526-dc82-4335-9f3c-e7fee13c4b10\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 44,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    }
  ]
}